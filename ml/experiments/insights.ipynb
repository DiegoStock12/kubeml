{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gather insights from the experiments run on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.utils import check_missing_experiments, join_df\n",
    "from common.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the TTA Formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate time to accuracy for different accuracies\n",
    "def tta_crossbow(acc:int, df: pd.DataFrame, acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \"\"\"Computes the tta as in the crossbow paper\n",
    "    where the tta is the median of the last 5 epochs\"\"\"\n",
    "\n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done = False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "            \n",
    "            # if there are less than 5 elements behind, continue\n",
    "            if idx < 4:\n",
    "                continue\n",
    "                \n",
    "            # calculate the median of the next five elements\n",
    "            if np.median(accuracy[idx - 4:idx+1]) >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def tta(acc:int, df:pd.DataFrame,  acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \n",
    "    \n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done=False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "         \n",
    "            if a >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the best results and the parameters for them\n",
    "def get_best_combinations(ml: pd.DataFrame, column: str):\n",
    "    \"\"\"\n",
    "    Given a dataframe, return the options with the best TTA and the column to optimize\n",
    "    \"\"\"\n",
    "    \n",
    "    # get only the non object columns\n",
    "#     ml = ml[[col for col in ml.columns if ml[col].dtype != 'object']]\n",
    "\n",
    "    # get the minimum rown of each of the batch sizes\n",
    "    min_rows = ml.groupby('batch_size')[column].min()\n",
    "    best = ml.loc[ml[column].isin(min_rows.values)][['k', 'batch_size', 'parallelism']]\n",
    "\n",
    "    # get the rows with those combinations\n",
    "    return ml.merge(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KubeML Experiments\n",
    "\n",
    "How to treat the kubeml experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "glob.glob('./results/resn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join_df('./results/resnet32/128-no-momentum/')\n",
    "df = df[df.default_parallelism > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['momentum'] = False\n",
    "# df=pd.concat([df,mom], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get duplicated rows\n",
    "df[df.duplicated(['hash'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the extra variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.epoch_duration.map(lambda t: t[-1])\n",
    "\n",
    "# Set the parallelism to the first since it is constant\n",
    "df.parallelism = df.parallelism.map(lambda l:l[0])\n",
    "\n",
    "# change -1 to inf so the order is right in the plot\n",
    "df.k = df.k.map(lambda val: float('inf') if val == -1 else val)\n",
    "\n",
    "df['global_batch'] = df.batch_size * df.parallelism\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ttas\n",
    "df['tta_80'] = tta(80, df)\n",
    "df['tta_cross_80'] = tta_crossbow(80, df)\n",
    "\n",
    "# compute the ttas\n",
    "df['tta_67'] = tta(67, df)\n",
    "df['tta_cross_67'] = tta_crossbow(67, df)\n",
    "\n",
    "# compute the ttas\n",
    "df['tta_70'] = tta(70, df)\n",
    "df['tta_cross_70'] = tta_crossbow(70, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the metrics in resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = join_df('./results/resnet_sparse/metrics')\n",
    "m = metrics.rename(columns={'exp_name':'id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the metrics in the lenet\n",
    "\n",
    "The first replication does not have the proper format, so we need to reformat it and combine it with the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1 = join_df('./results/lenet/metrics/1/')\n",
    "metrics2 = join_df('./results/lenet/metrics/2/')\n",
    "metrics3 = join_df('./results/lenet/metrics/3/')\n",
    "\n",
    "cpu = metrics1.groupby('exp_name')['cpu'].apply(list)\n",
    "mem = metrics1.groupby('exp_name')['mem'].apply(list)\n",
    "exps = metrics1.groupby('exp_name')['exp_name']\n",
    "\n",
    "metrics1 = pd.DataFrame({\n",
    "    'cpu':cpu,\n",
    "    'mem':mem\n",
    "})\n",
    "metrics1['exp_name'] = metrics1.index\n",
    "\n",
    "# concat all metrics and rename the exp_name as in the train\n",
    "m = pd.concat([metrics1, metrics2, metrics3], ignore_index=True)\n",
    "m.rename(columns={'exp_name':'id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add extra summary columns to the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine and Save the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.merge(m, on='id')\n",
    "d.to_pickle('./dataframes/resnet_kubeml_sparse.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Experiments\n",
    "\n",
    "How to treat the TF experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'lenet'\n",
    "df = join_df(f'./results/tf/{folder}/train_full/1/', f'./results/tf/{folder}/train_full/2', f'./results/tf/{folder}/train_full/3')\n",
    "\n",
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.val_accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.times.map(lambda t: t[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tta_lenet\n",
    "df['tta_99'] = tta(0.99, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_99'] = tta_crossbow(0.99, df, time_column='times', acc_column='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TTA\n",
    "df['tta_67'] = tta(0.67, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_67'] = tta_crossbow(0.67, df, time_column='times', acc_column='val_accuracy')\n",
    "\n",
    "df['tta_69'] = tta(0.69, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_69'] = tta_crossbow(0.69, df, time_column='times', acc_column='val_accuracy')\n",
    "\n",
    "df['tta_70'] = tta(0.70, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_70'] = tta_crossbow(0.70, df, time_column='times', acc_column='val_accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the metrics from different  folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = join_df(f'./results/tf/{folder}/metrics_full/1/', f'./results/tf/{folder}/metrics_full/2', f'./results/tf/{folder}/metrics_full/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./dataframes/lenet_full_tensorflow.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_red_palette = ['#264653', '#2A9D8F', '#E9C46A', '#F4A261', '#E76F51']\n",
    "blue_yellow_palette=  ['#0077b6', '#d62828', '#f77f00', '#fcbf49', '#eae2b7']\n",
    "cool_p = ['#f87575', '#ffa9a3', '#b9e6ff', '#5c95ff', '#7e6c6c']\n",
    "wall_p = ['#e63946', '#f1faee', '#a8dadc', '#457b9d', '#1d3557']\n",
    "\n",
    "sns.palplot(sns.color_palette('gnuplot2'))\n",
    "\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette=blue_yellow_palette, )\n",
    "sns.set_context('talk')\n",
    "# sns.set_palette(blue_yellow_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sns.color_palette('gnuplot2').as_hex()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read the experiments file\n",
    "\n",
    "Some of the dataframes by name\n",
    "\n",
    "- resnet_new: is with extra epochs and proper preprocessing\n",
    "- resnet_sparse: only holds the tests with sparse averaging\n",
    "- folders with metrics/train_full hold the extra experiment to migrate to local batch comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the tf experiments\n",
    "resnet = pd.read_pickle('./dataframes/resnet_new_full_tensorflow.pkl')\n",
    "lenet = pd.read_pickle('./dataframes/lenet_full_tensorflow.pkl')\n",
    "\n",
    "lenet.rename(columns={\n",
    "    'loss':'train_loss',\n",
    "    'val_accuracy':'accuracy',\n",
    "    'val_loss':'validation_loss',\n",
    "    'times':'epoch_duration',\n",
    "    'accuracy':'train_accuracy',\n",
    "    'val_accuracy':'accuracy'\n",
    "}, inplace=True)\n",
    "lenet['system'] = 'tensorflow'\n",
    "lenet['acc'] = 100*lenet['acc']\n",
    "lenet['accuracy'] = lenet['accuracy'].map(lambda l: [100*n for n in l])\n",
    "\n",
    "# rename columns in the TF dataframes to adhere to the kubeml ones\n",
    "resnet.rename(columns={\n",
    "    'loss':'train_loss',\n",
    "    'val_accuracy':'accuracy',\n",
    "    'val_loss':'validation_loss',\n",
    "    'times':'epoch_duration',\n",
    "    'accuracy':'train_accuracy',\n",
    "    'val_accuracy':'accuracy'\n",
    "}, inplace=True)\n",
    "resnet['system'] = 'tensorflow'\n",
    "resnet['acc'] = 100*resnet['acc']\n",
    "resnet['accuracy'] = resnet['accuracy'].map(lambda l: [100*n for n in l])\n",
    "\n",
    "\n",
    "# set the columns of the \n",
    "\n",
    "# load the kubeml experiments\n",
    "kuberesnet = pd.read_pickle('./dataframes/resnet_kubeml.pkl')\n",
    "kuberesnet['model'] = 'resnet'\n",
    "kuberesnet['system'] = 'kubeml'\n",
    "# kuberesnet['tta_70'] = tta(70, kuberesnet)\n",
    "# kuberesnet['tta_cross_70'] = tta_crossbow(70, kuberesnet)\n",
    "\n",
    "kubelenet = pd.read_pickle('./dataframes/lenet_kubeml.pkl')\n",
    "kubelenet['model'] = 'lenet'\n",
    "kubelenet['system'] = 'kubeml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubelenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the full resnet stuff\n",
    "r.to_pickle('./dataframes/resnet_new_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.concat([resnet, kuberesnet], ignore_index=True)\n",
    "r\n",
    "# resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create new columns for representation\n",
    "\n",
    "- Final accuracy\n",
    "- Total time taken\n",
    "- Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot the Correlations between the K, Batch and Parallelism with time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df[['k', 'batch_size', 'parallelism', 'acc', 'time']].corr()\n",
    "sns.heatmap(corr,\n",
    "            annot=True,\n",
    ")\n",
    "\n",
    "# plt.savefig('./figures/resnet34/heat.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('time')\n",
    "\n",
    "mean = df.groupby('hash').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the max accuracies and times and check the parameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the max accuracies\n",
    "df[['k', 'parallelism', 'acc','batch_size','time']].sort_values(by='time', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calculate TTA with different accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s = df.sort_values('tta_cross_99')[['k', 'batch_size', 'parallelism', 'tta_cross_99', 'tta_99', 'acc', 'accuracy', 'epoch_duration']]\n",
    "\n",
    "# plot the best\n",
    "best = s.iloc[0]\n",
    "best\n",
    "\n",
    "\n",
    "x = range(1, len(best.accuracy)+1)\n",
    "plt.figure()\n",
    "plt.title(f'Best tta_99 (B={best.batch_size}, k={best.k}, P={best.parallelism})')\n",
    "sns.lineplot(x=best.epoch_duration, y = best.accuracy)\n",
    "sns.lineplot(x=best.epoch_duration, y= 99)\n",
    "plt.scatter(best.tta_cross_99, 99, marker='X', s=60, c='r')\n",
    "plt.xlabel('Time (s)', fontsize=15)\n",
    "plt.ylabel('Accuracy (%)', fontsize=15)\n",
    "\n",
    "# plt.savefig('./figures/gpu/best.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the resnet results KubeML vs Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the colors used\n",
    "tf_color = '#FF6F00'\n",
    "kubecolor = '#316CE6'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.read_pickle('./dataframes/lenet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l[l.system=='tensorflow'].iloc[0].accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the best result from Lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = l[l.system=='tensorflow']\n",
    "\n",
    "tf['train_accuracy'] = tf.train_accuracy.map(lambda l: [100*n for n in l])\n",
    "\n",
    "\n",
    "best = tf.sort_values('tta_99').head(1).iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_acc = np.max(best.accuracy)\n",
    "max_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# before it was 10,5\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.lineplot(x=best.epoch_duration,\n",
    "            y=99,\n",
    "            color='red',\n",
    "            )\n",
    "\n",
    "# 1) plot the validation accuracy of TF\n",
    "sns.lineplot(x=best.epoch_duration,\n",
    "             y=best.accuracy,\n",
    "             data=best,  \n",
    "            label='Test Accuracy',\n",
    "#              color=tf_color\n",
    "            )\n",
    "\n",
    "line = sns.lineplot(x=best.epoch_duration,\n",
    "             y=best.train_accuracy,\n",
    "             data=best,  \n",
    "            label='Train Accuracy',\n",
    "            color='gray',\n",
    "            alpha=.6\n",
    "            )\n",
    "\n",
    "\n",
    "# plt.ylim([30, 80])\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "\n",
    "line.lines[2].set_linestyle((0, (15, 6)))\n",
    "\n",
    "# sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/lenet-baseline.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Accuracy and Train Loss Progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, figsize=(20, 6))\n",
    "\n",
    "# get the best results\n",
    "tf = l[l.system=='tensorflow']\n",
    "ml = l[l.system =='kubeml']\n",
    "sample = tf.iloc[5]\n",
    "kubesample = ml.iloc[87]\n",
    "\n",
    "# sort for tta69 and show\n",
    "\n",
    "# 1) plot the validation accuracy of TF\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.accuracy[:30],\n",
    "             data=sample, \n",
    "            ax=ax1, \n",
    "            label='TensorFlow',\n",
    "            color='#FF6F00')\n",
    "\n",
    "# 2) plot the validation accuracy of KubeML\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='accuracy',\n",
    "             data=kubesample, \n",
    "            ax=ax1, \n",
    "            label='KubeML',\n",
    "            color='#316CE6')\n",
    "\n",
    "ax1.set_ylim([97, 100])\n",
    "ax1.set_xlabel('Time (sec)')\n",
    "\n",
    "\n",
    "\n",
    "# plot the line at 69%\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "            y=99,\n",
    "            ax=ax1,\n",
    "            color='red')\n",
    "\n",
    "# 3) Plot the train loss\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.train_loss[:30],\n",
    "             data=sample, \n",
    "            ax=ax2, \n",
    "            label='TensorFlow',\n",
    "            color='#FF6F00')\n",
    "\n",
    "# 3) Plot the train loss\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='train_loss',\n",
    "             data=kubesample, \n",
    "            ax=ax2, \n",
    "            label='KubeML',\n",
    "            color='#316CE6')\n",
    "\n",
    "ax2.set_xlabel('Time (sec)')\n",
    "\n",
    "\n",
    "\n",
    "# 4) Plot the val loss\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.validation_loss[:30],\n",
    "             data=sample, \n",
    "            ax=ax3, \n",
    "            label='TensorFlow',\n",
    "            color='#FF6F00')\n",
    "\n",
    "# 4) Plot the val loss\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='validation_loss',\n",
    "             data=kubesample, \n",
    "            ax=ax3, \n",
    "            label='KubeML',\n",
    "            color='#316CE6')\n",
    "\n",
    "ax3.set_ylim([0, 0.3])\n",
    "\n",
    "# plt.savefig('./figures/ppt/lenet_line.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the whole comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get only the results with k=-1 and \n",
    "# _l = l[((l.parallelism==4) | (l.parallelism.isna())) & ((l.k==float('inf')) | (l.k.isna())) ]\n",
    "\n",
    "tf = l[l.system=='tensorflow']\n",
    "ml = l[l.system=='kubeml']\n",
    "\n",
    "tf['local_batch'] = (tf.batch_size/2).astype('int')\n",
    "\n",
    "# get the best results\n",
    "ml = get_best_combinations(ml, 'tta_99')\n",
    "display(ml)\n",
    "ml['local_batch'] = ml.batch_size\n",
    "# print(ml.groupby('batch_size').median())\n",
    "\n",
    "# combine them again\n",
    "_l = pd.concat([tf, ml])\n",
    "_l.system = _l.system.map(lambda val: 'KubeML' if val=='kubeml' else 'TensorFlow')\n",
    "_l = _l[_l.local_batch >8]\n",
    "\n",
    "# set the palette\n",
    "sns.set_palette([tf_color, kubecolor], desat=0.7)\n",
    "# sns.set_palette('gnuplot2')\n",
    "\n",
    "\n",
    "# COMPARE THE LOSSES, THE VAL LOSS OF KUBEML SHOULD BE HIGHER (DO NOT KNOW THE TRAIN LOSS, BECAUSE OF EXPLORATION,\n",
    "# WHILE STILL GIVING BEST ACCURACY (BETTER GENERALIZATION))\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# 1) Plot the comparison of tta between both\n",
    "sns.barplot(x='local_batch', \n",
    "            y='tta_99', \n",
    "            data=_l, \n",
    "            hue='system', \n",
    "            errwidth=2.5,\n",
    "#             ax=ax[0][0],\n",
    "           capsize=.05)\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('TTA (99%) (sec)')\n",
    "sns.despine(left=True)\n",
    "plt.ylim([0, 150])\n",
    "# plt.setp(ax.get_legend().get_texts(), fontsize='15') \n",
    "# plt.setp(ax.get_legend().get_title(), fontsize='15')  \n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/lenet/tta99.pdf')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3) Plot the difference train_loss\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "_l['t_loss'] = _l['train_loss'].map(lambda l:l[-1])\n",
    "sns.barplot(x='local_batch', \n",
    "            y='t_loss', \n",
    "            data=_l, \n",
    "            hue='system',\n",
    "            errwidth=2.5,\n",
    "#             ax=ax[1][0],\n",
    "            capsize=.05,\n",
    "               )\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Train Loss')\n",
    "# plt.ylim([0, 0.8])\n",
    "sns.despine(left=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/lenet/train-loss.pdf')\n",
    "\n",
    "\n",
    "# 4) Plot the val loss of both compared\n",
    "# calculate the loss\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "_l['loss'] = _l['validation_loss'].map(lambda l:l[-1])\n",
    "sns.barplot(x='local_batch', \n",
    "            y='loss', \n",
    "            data=_l ,\n",
    "            hue='system',\n",
    "            errwidth=2.5,\n",
    "#             ax=ax[1][1],\n",
    "            capsize=.05)\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.ylim([0, 0.08])\n",
    "sns.despine(left=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/lenet/val-loss.pdf')\n",
    "\n",
    "\n",
    "## Plot the difference in cpu and gpu utilization\n",
    "# CPU util\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "sns.barplot(x='local_batch', \n",
    "            y='cpu_mean', \n",
    "            data=_l ,\n",
    "            capsize=.05,\n",
    "            errwidth=2.5,\n",
    "            hue='system',\n",
    "#             ax=ax[2][0]\n",
    "           )\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('CPU Utilization (%)')\n",
    "sns.despine(left=True)\n",
    "plt.ylim([0, 15])\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/lenet/cpu.pdf')\n",
    "\n",
    "# Global Batch Size relationship with tta\n",
    "# _ml = r[r.system=='kubeml']\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "sns.barplot(x='local_batch', \n",
    "            y='gpu_usage', \n",
    "            data=_l ,\n",
    "            capsize=.05,\n",
    "            errwidth=2.5,\n",
    "            hue='system',\n",
    "#             ax=ax[2][1]\n",
    "           )\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('GPU Usage')\n",
    "plt.ylim([0, 1.15])\n",
    "sns.despine(left=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/lenet/gpu.pdf')\n",
    "# plt.savefig('./figures/ppt/lenet-performance.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of accuracy and time between K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "sns.set_palette('gnuplot2', desat=0.8)\n",
    "\n",
    "\n",
    "\n",
    "_kubelenet = l[(l.system == 'kubeml')]\n",
    "# 1) plot the accuracy reached with different k\n",
    "sns.barplot(x='batch_size',\n",
    "           y='time',\n",
    "           data=_kubelenet, \n",
    "           hue='parallelism',\n",
    "           ax=ax[0],\n",
    "           errcolor='gray',\n",
    "           capsize=.05,\n",
    "           errwidth=2.5)\n",
    "ax[0].set_xlabel('Batch Size')\n",
    "ax[0].set_ylabel('Time (sec)')\n",
    "\n",
    "\n",
    "_kubelenet = l[(l.system == 'kubeml') & (l.parallelism==4)]\n",
    "# 2) plot the time reached with different k\n",
    "sns.barplot(x='batch_size',\n",
    "           y='acc',\n",
    "           data=_kubelenet, \n",
    "           hue='parallelism',\n",
    "           ax=ax[1],\n",
    "           errcolor='gray',\n",
    "           capsize=.05,\n",
    "           errwidth=2.5)\n",
    "ax[1].set_xlabel('Batch Size')\n",
    "ax[1].set_ylabel('Time (sec)')\n",
    "\n",
    "plt.suptitle('Evolution of Time with Parallelism and K')\n",
    "\n",
    "plt.savefig('./figures/ppt/lenet-time.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Train Loss and Val Accuracy of Tensorflow and KubeML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the colors used\n",
    "tf_color = '#FF6F00'\n",
    "kubecolor = '#316CE6'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the palette\n",
    "sns.set_palette([tf_color, kubecolor], desat=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.read_pickle('./dataframes/resnet_sparse.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the best result plot from Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = r[r.system=='tensorflow']\n",
    "\n",
    "tf['train_accuracy'] = tf.train_accuracy.map(lambda l: [100*n for n in l])\n",
    "\n",
    "\n",
    "best = tf.sort_values('tta_70').head(1).iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_acc = np.max(best.accuracy)\n",
    "max_acc\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "# 1) plot the validation accuracy of TF\n",
    "sns.lineplot(x=best.epoch_duration,\n",
    "             y=best.accuracy,\n",
    "             data=best,  \n",
    "            label='Test Accuracy',\n",
    "#              color=tf_color\n",
    "            )\n",
    "\n",
    "l = sns.lineplot(x=best.epoch_duration,\n",
    "             y=best.train_accuracy,\n",
    "             data=best,  \n",
    "            label='Train Accuracy',\n",
    "            color='gray',\n",
    "            alpha=.6\n",
    "            )\n",
    "\n",
    "\n",
    "sns.lineplot(x=best.epoch_duration,\n",
    "            y=70,\n",
    "            color='red',\n",
    "            )\n",
    "# plt.ylim([30, 80])\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "\n",
    "l.lines[1].set_linestyle((0, (15, 6)))\n",
    "\n",
    "# sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet-baseline.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[(r.batch_size==32) & (r.system=='kubeml') & (r.k == float('inf')) & (r.parallelism ==4)].iloc[0].epoch_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sns.color_palette('gnuplot2').as_hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, figsize=(20, 6))\n",
    "\n",
    "# get the best results\n",
    "tf = r[r.system=='tensorflow']\n",
    "ml = r[r.system =='kubeml']\n",
    "sample = r.iloc[tf.sort_values('tta_70').head(1).index[0]]\n",
    "kubesample = r.iloc[ml.sort_values('tta_70').head(3).index[0]]\n",
    "\n",
    "# kubesample =ml.iloc[2]\n",
    "# sample = tf.iloc[3]\n",
    "\n",
    "# sort for tta69 and show\n",
    "\n",
    "# 1) plot the validation accuracy of TF\n",
    "sns.lineplot(x=sample.epoch_duration[:50],\n",
    "             y=sample.accuracy[:50],\n",
    "             data=sample, \n",
    "            ax=ax1, \n",
    "            label='TensorFlow')\n",
    "\n",
    "# 2) plot the validation accuracy of KubeML\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='accuracy',\n",
    "             data=kubesample, \n",
    "            ax=ax1, \n",
    "            label='KubeML')\n",
    "\n",
    "ax1.set_ylim([40, 80])\n",
    "\n",
    "\n",
    "\n",
    "# plot the line at 70%\n",
    "sns.lineplot(x=range(int(kubesample.time)),\n",
    "            y=70,\n",
    "            ax=ax1,\n",
    "            color='red')\n",
    "\n",
    "\n",
    "# 3) Plot the train loss\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.train_loss[:30],\n",
    "             data=sample, \n",
    "            ax=ax2, \n",
    "            label='TensorFlow')\n",
    "\n",
    "# 3) Plot the train loss\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='train_loss',\n",
    "             data=kubesample, \n",
    "            ax=ax2, \n",
    "            label='KubeML')\n",
    "\n",
    "\n",
    "# 4) Plot the val loss\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.validation_loss[:30],\n",
    "             data=sample, \n",
    "            ax=ax3, \n",
    "            label='TensorFlow')\n",
    "\n",
    "# 4) Plot the val loss\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='validation_loss',\n",
    "             data=kubesample, \n",
    "            ax=ax3, \n",
    "            label='KubeML')\n",
    "\n",
    "# plt.savefig('./figures/ppt/resnet_line.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the GPU, CPU and MEM usage based on k, batch and parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, figsize=(20, 6))\n",
    "sns.set_palette('deep')\n",
    "\n",
    "# 1) Plot the cpu usage\n",
    "sns.barplot(x='batch_size', \n",
    "            y='cpu_mean', \n",
    "            data=ml, \n",
    "            hue='k', \n",
    "            errwidth=2.5,\n",
    "            ax=ax1,\n",
    "            capsize=.05)\n",
    "# ax1.set_ylim([40, 100])\n",
    "ax1.set_xlabel('Batch Size')\n",
    "ax1.set_ylabel('CPU Usage (%)')\n",
    "\n",
    "\n",
    "# 2) Plot the memory usage\n",
    "sns.barplot(x='batch_size', \n",
    "            y='mem_mean', \n",
    "            data=ml, \n",
    "            hue='parallelism',\n",
    "            errwidth=2.5,\n",
    "            ax=ax2,\n",
    "            capsize=.05,\n",
    "               )\n",
    "ax2.set_xlabel('Batch Size')\n",
    "ax2.set_ylabel('Memory Usage (%)')\n",
    "\n",
    "\n",
    "# 3) Plot the gpu usage\n",
    "sns.barplot(x='batch_size', \n",
    "            y='gpu_usage', \n",
    "            data=ml ,\n",
    "            hue='k',\n",
    "            errwidth=2.5,\n",
    "            ax=ax3,\n",
    "            capsize=.05)\n",
    "\n",
    "ax3.set_xlabel('Batch Size')\n",
    "ax3.set_ylabel('GPU Usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml[(ml.parallelism==4) & (ml.k==float('inf')) & (ml.batch_size==128)].time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ml.groupby('batch_size')['tta_70'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the metrics of both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_s['parallelism'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ml[['batch_size', 'k', 'parallelism', 'epochs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_pickle('./dataframes/resnet_new_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get only the results with k=-1 and \n",
    "# _r = r[((r.parallelism==4) | (r.parallelism.isna())) & ((r.k==float('inf')) | (r.k.isna())) ]\n",
    "# _r['t30'] = _r['time']\n",
    "\n",
    "sns.set_palette([tf_color, kubecolor], desat=0.7)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rc('font', size=22)\n",
    "\n",
    "_r = pd.read_pickle('./dataframes/resnet_new_full.pkl')\n",
    "_sp = pd.read_pickle('./dataframes/resnet_sparse.pkl')\n",
    "_sp = _sp[_sp.system=='kubeml']\n",
    "\n",
    "_s = pd.concat([_r,_sp])\n",
    "_tf = _s[_s.system=='tensorflow']\n",
    "_tf['local_batch'] = (_tf.batch_size/2).astype('int')\n",
    "\n",
    "_ml = _s[_s.system=='kubeml']\n",
    "_ml['local_batch'] = _ml['batch_size']\n",
    "_ml = get_best_combinations(_ml, 'tta_70')\n",
    "\n",
    "\n",
    "_r = pd.concat([_tf,_ml])\n",
    "_r.system = _r.system.map(lambda val: 'KubeML' if val=='kubeml' else 'TensorFlow')\n",
    "_r = _r[_r['local_batch'] >16]\n",
    "\n",
    "# display(_ml)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# COMPARE THE LOSSES, THE VAL LOSS OF KUBEML SHOULD BE HIGHER (DO NOT KNOW THE TRAIN LOSS, BECAUSE OF EXPLORATION,\n",
    "# WHILE STILL GIVING BEST ACCURACY (BETTER GENERALIZATION))\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# 1) Plot the comparison of tta between both\n",
    "sns.barplot(x='local_batch', \n",
    "            y='tta_70', \n",
    "            data=_r, \n",
    "            hue='system', \n",
    "            errwidth=2.5,\n",
    "#             ax=ax[0][0],\n",
    "           capsize=.05)\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('TTA (70%) (sec)')\n",
    "sns.despine(left=True)\n",
    "# plt.setp(ax.get_legend().get_texts(), fontsize='15') \n",
    "# plt.setp(ax.get_legend().get_title(), fontsize='15')  \n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet34/tta70.pdf')\n",
    "\n",
    "# # create a function\n",
    "# for (i, row), p in zip(parals.iterrows(), [p for p in ax[0][0].patches[1::2]]):\n",
    "#     print(row, p)\n",
    "#     ax[0][0].annotate(\n",
    "#         str(int(row.parallelism)),\n",
    "#         xy = ( p.get_x() + p.get_width(),  p.get_height() + 10))\n",
    "\n",
    "\n",
    "# 3) Plot the difference train_loss\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "_r['t_loss'] = _r['train_loss'].map(lambda l:l[-1])\n",
    "sns.barplot(x='local_batch', \n",
    "            y='t_loss', \n",
    "            data=_r, \n",
    "            hue='system',\n",
    "            errwidth=2.5,\n",
    "#             ax=ax[1][0],\n",
    "            capsize=.05,\n",
    "               )\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.ylim([0, 0.65])\n",
    "sns.despine(left=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet34/train-loss.pdf')\n",
    "\n",
    "\n",
    "# 4) Plot the val loss of both compared\n",
    "# calculate the loss\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "_r['loss'] = _r['validation_loss'].map(lambda l:l[-1])\n",
    "sns.barplot(x='local_batch', \n",
    "            y='loss', \n",
    "            data=_r ,\n",
    "            hue='system',\n",
    "            errwidth=2.5,\n",
    "#             ax=ax[1][1],\n",
    "            capsize=.05)\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.ylim([0, 3.25])\n",
    "sns.despine(left=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet34/val-loss.pdf')\n",
    "\n",
    "\n",
    "## Plot the difference in cpu and gpu utilization\n",
    "# CPU util\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "sns.barplot(x='local_batch', \n",
    "            y='cpu_mean', \n",
    "            data=_r ,\n",
    "            capsize=.05,\n",
    "            errwidth=2.5,\n",
    "            hue='system',\n",
    "#             ax=ax[2][0]\n",
    "           )\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('CPU Utilization (%)')\n",
    "sns.despine(left=True)\n",
    "plt.ylim([0, 15])\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet34/cpu.pdf')\n",
    "\n",
    "# Global Batch Size relationship with tta\n",
    "# _ml = r[r.system=='kubeml']\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "sns.barplot(x='local_batch', \n",
    "            y='gpu_usage', \n",
    "            data=_r ,\n",
    "            capsize=.05,\n",
    "            errwidth=2.5,\n",
    "            hue='system',\n",
    "#             ax=ax[2][1]\n",
    "           )\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('GPU Usage')\n",
    "plt.ylim([0, 1.15])\n",
    "sns.despine(left=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet34/gpu.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ax.annotate(str(int(p)), \n",
    "                xy=(patch.get_x()+patch.get_width()/1.3, patch.get_height()+ 10), \n",
    "                ha='center', \n",
    "                fontsize=20, \n",
    "                color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_rectangles(df:pd.DataFrame):\n",
    "    \"\"\"Do the stuff\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parals = ml.groupby('batch_size').mean()[['parallelism', 'tta_70']]\n",
    "# parals\n",
    "for (i, row), p in zip(parals.iterrows(), [p for p in ax[0][0].patches[1::2]]):\n",
    "    print(row, p)\n",
    "    ax[0][0].annotate(\n",
    "        str(int(row.parallelism)),\n",
    "        xy = ( p.get_x() + p.get_width(),  p.get_height() + 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best results of KubeML by  Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml[ml.batch_size.eq(256) & ~ml.tta_70.isna()]['tta_70']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ml = r[r.system=='kubeml']\n",
    "ml = get_best_combinations(ml)\n",
    "ml\n",
    "_r = pd.concat([tf, ml], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_palette('deep', 10)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def get_best_combinations(ml: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Given a dataframe, return the options with the best TTA\n",
    "    \"\"\"\n",
    "    \n",
    "    # get only the non object columns\n",
    "#     ml = ml[[col for col in ml.columns if ml[col].dtype != 'object']]\n",
    "\n",
    "    # get the minimum rown of each of the batch sizes\n",
    "    min_rows = ml.groupby('batch_size')['tta_70'].min()\n",
    "    best = ml.loc[ml.tta_70.isin(min_rows.values)][['k', 'batch_size', 'parallelism']]\n",
    "\n",
    "    # get the rows with those combinations\n",
    "    return ml.merge(best)\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ml = r[r.system=='kubeml']\n",
    "ml = get_best_combinations(ml)\n",
    "\n",
    "sns.barplot(x='batch_size',\n",
    "           y='tta_70', \n",
    "            data=ml,\n",
    "           errwidth=2.5,\n",
    "            capsize=.05, \n",
    "           )\n",
    "\n",
    "ps = ml.groupby('batch_size').mean()[['parallelism', 'tta_70']]\n",
    "for i, ((_, p, tta), patch) in enumerate(zip(ps.itertuples(), ax.patches)):\n",
    "    print(patch)\n",
    "    \n",
    "    ax.annotate(str(int(p)), \n",
    "                xy=(patch.get_x()+patch.get_width()/1.3, patch.get_height()+ 10), \n",
    "                ha='center', \n",
    "                fontsize=20, \n",
    "                color='red')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Time with Parallelism and K \n",
    "\n",
    "(include these in paper!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f, (ax1, ax2) = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "# sns.set_palette('muted',10)\n",
    "sns.set_palette('gnuplot2', desat=0.8)\n",
    "\n",
    "\n",
    "\n",
    "_kuberesnet = _s[(_s.system == 'kubeml')]\n",
    "_kuberesnet['parallelism'] = _kuberesnet.parallelism.astype('int')\n",
    "_kuberesnet['global_batch'] = _kuberesnet.global_batch.astype('int')\n",
    "_kuberesnet['k'] = _kuberesnet.k.map(lambda v: int(v) if v != float('inf') else v)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,7))\n",
    "print(_kuberesnet.parallelism.value_counts())\n",
    "# 1) plot the accuracy reached with different k\n",
    "sns.barplot(x='batch_size',\n",
    "           y='time',\n",
    "           data=_kuberesnet, \n",
    "            errwidth=2.5,\n",
    "            capsize=.05,\n",
    "            errcolor='gray',\n",
    "           hue='parallelism',\n",
    "           )\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Time (sec)')\n",
    "sns.despine(left=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet34/batch-vs-time-by-parallelism.pdf')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# _kuberesnet = r[(r.system == 'kubeml') & (r.parallelism==4)]\n",
    "# 2) plot the time reached with different k\n",
    "f, ax = plt.subplots(figsize=(10,7))\n",
    "sns.barplot(x='batch_size',\n",
    "           y='time',\n",
    "           data=_kuberesnet, \n",
    "            capsize=.05,\n",
    "           hue='k',\n",
    "            errcolor='gray',\n",
    "        errwidth=2.5)\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Time (sec)')\n",
    "sns.despine(left=True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet34/batch-vs-time-by-k.pdf')\n",
    "\n",
    "\n",
    "\n",
    "# _kuberesnet = r[(r.system == 'kubeml')]\n",
    "# 1) plot the accuracy reached with different k\n",
    "# sns.barplot(x='batch_size',\n",
    "#            y='acc',\n",
    "#            data=_kuberesnet, \n",
    "#            hue='parallelism',\n",
    "#             errcolor='gray',\n",
    "#             capsize=.05,\n",
    "#             errwidth=2.5,\n",
    "#            ax=ax2[0])\n",
    "# ax2[0].set_xlabel('Batch Size')\n",
    "# ax2[0].set_ylabel('Accuracy (%)')\n",
    "# ax2[0].set_ylim([55, 73])\n",
    "\n",
    "\n",
    "# _kuberesnet = r[(r.system == 'kubeml')]\n",
    "# 1) plot the accuracy reached with different k\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,7))\n",
    "sns.barplot(x='global_batch',\n",
    "           y='acc',\n",
    "            errwidth=2.5,\n",
    "            capsize=.05,\n",
    "            errcolor='gray',\n",
    "           data=_kuberesnet, \n",
    "           hue='parallelism')\n",
    "plt.xlabel('Global Batch Size')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.ylim([55, 80])\n",
    "sns.despine(left=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet34/global-batch-vs-acc.pdf')\n",
    "\n",
    "# plt.suptitle('Evolution of Time with Parallelism and K (Resnet34)')\n",
    "\n",
    "# plt.savefig('./figures/ppt/resnet-time.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = _r.loc[(_r.batch_size==32) & (_r.system=='kubeml')]\n",
    "for a, t in zip(g.iloc[0].accuracy, g.iloc[0].epoch_duration):\n",
    "    print(t, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analize results using ResNet32 for 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframes\n",
    "r32 = pd.read_pickle('./dataframes/resnet32-200.pkl')\n",
    "r128 = pd.read_pickle('./dataframes/resnet32-200-128.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the batch 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_palette('gnuplot2')\n",
    "\n",
    "# get an intuition of the comparison with and without momentum by plotting the accuracy progression\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14,10))\n",
    "\n",
    "# plot all the lines\n",
    "for _, row in r32.sort_values('k').iterrows():\n",
    "    if not row.momentum:\n",
    "        sns.lineplot(\n",
    "            x=row.epoch_duration,\n",
    "            y=row.accuracy,\n",
    "            label=f'{int(row.k) if row.k != float(\"inf\") else row.k}'\n",
    "        )\n",
    "        \n",
    "# set the axes names\n",
    "ax.set_xlabel('Time (sec)')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_ylim([30, 94])\n",
    "        \n",
    "axins = zoomed_inset_axes(ax, zoom= 3, bbox_to_anchor=(700, 500))\n",
    "for i, row in r32.sort_values('k').iterrows():\n",
    "    if not row.momentum:\n",
    "        axins.plot(\n",
    "            row.epoch_duration,\n",
    "            row.accuracy\n",
    "        )\n",
    "        \n",
    "ax.get_legend().set_title('K')\n",
    "ax.get_legend()._set_loc(4)\n",
    "        \n",
    "axins.set_ylim([84, 91])\n",
    "axins.set_xlim([1200, 2200])\n",
    "\n",
    "# plt.xticks(visible=False)\n",
    "# plt.yticks(visible=False)\n",
    "\n",
    "\n",
    "mark_inset(ax, axins, loc1=2, loc2=1, ec=\"0.5\");\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet32/resnet32-32-comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same with 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('gnuplot2')\n",
    "\n",
    "# get an intuition of the comparison with and without momentum by plotting the accuracy progression\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14,10))\n",
    "\n",
    "# plot all the lines\n",
    "for _, row in r128.sort_values('k').iterrows():\n",
    "    if not row.momentum:\n",
    "        sns.lineplot(\n",
    "            x=row.epoch_duration,\n",
    "            y=row.accuracy,\n",
    "            label=f'{int(row.k) if row.k != float(\"inf\") else row.k}'\n",
    "        )\n",
    "        \n",
    "# set the axes names\n",
    "ax.set_xlabel('Time (sec)')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_ylim([30, 94])\n",
    "        \n",
    "axins = zoomed_inset_axes(ax, zoom= 2, bbox_to_anchor=(700, 500))\n",
    "for i, row in r128.sort_values('k').iterrows():\n",
    "    if not row.momentum:\n",
    "        axins.plot(\n",
    "            row.epoch_duration,\n",
    "            row.accuracy\n",
    "        )\n",
    "        \n",
    "ax.get_legend().set_title('K')\n",
    "ax.get_legend()._set_loc(4)\n",
    "        \n",
    "axins.set_ylim([79, 86])\n",
    "axins.set_xlim([700, 1100])\n",
    "\n",
    "# plt.xticks(visible=False)\n",
    "# plt.yticks(visible=False)\n",
    "\n",
    "\n",
    "mark_inset(ax, axins, loc1=2, loc2=1, ec=\"0.5\");\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/paper/resnet32/resnet32-32-comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sns.color_palette('gnuplot2').as_hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get both of the entries with K = inf\n",
    "\n",
    "sns.set_palette('gnuplot2')\n",
    "\n",
    "inf = r32[r32.k==float('inf')]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,7))\n",
    "# plot all the lines\n",
    "for _, row in inf.sort_values('k').iterrows():\n",
    "\n",
    "    color='#000090' if row.momentum else '#ff9669'\n",
    "    label = 'SGD w/ Momentum' if row.momentum else 'SGD'\n",
    "    \n",
    "    sns.lineplot(\n",
    "        x=row.epoch_duration,\n",
    "        y=row.accuracy,\n",
    "        label=label,\n",
    "        color=color\n",
    "    )\n",
    "    \n",
    "# set the axes names\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel('Accuracy [%]')\n",
    "ax.set_ylim([30, 92])\n",
    "    \n",
    "        \n",
    "# ax.get_legend().set_title('Momentum')\n",
    "ax.get_legend()._set_loc(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/paper/resnet32/resnet32-momentum-comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do ANOVA Linear Model to calculate the influence of the parameters\n",
    "\n",
    "Using ANOVA we can get an idea of how the different parameters interact with each other and their influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ANOVA test\n",
    "import researchpy as rp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA(df: pd.DataFrame, y: str, use_all = False,verbose=False):\n",
    "    \"\"\"Run the ANOVA analysis with the batch, k and parallelism columns for the \n",
    "    given output variable\"\"\"\n",
    "    \n",
    "    # If use all is true we use all the variables to check either accuracy and time\n",
    "    # including also the iowait and the cpu to see what fully influences the stuff\n",
    "    \n",
    "    \n",
    "    if not use_all:\n",
    "        # Plot the summary dataframe\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ batch_size*k*parallelism', df).fit()\n",
    "        \n",
    "    else:\n",
    "        if y not in ['acc', 'time']:\n",
    "            raise ValueError('When use_all = True we predict either final_accuracy or time, not', y)\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ cpu*batch*njobs*cpu_mean*iowait_mean', df).fit()\n",
    "        \n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "        display(model.summary())\n",
    "    \n",
    "    res = sm.stats.anova_lm(model, typ=2)\n",
    "    \n",
    "    return res, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.k = df.k.map(lambda val: -1 if val == float('inf') else val)\n",
    "\n",
    "__r = r[r.system=='kubeml']\n",
    "__r['k'] = __r['k'].map(lambda v: -1 if v == float('inf') else v)\n",
    "res, model = ANOVA(__r, y='gpu_usage', verbose=True)\n",
    "\n",
    "res\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
