{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gather insights from the experiments run on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.utils import check_missing_experiments, join_df\n",
    "from common.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the TTA Formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate time to accuracy for different accuracies\n",
    "def tta_crossbow(acc:int, df: pd.DataFrame, acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \"\"\"Computes the tta as in the crossbow paper\n",
    "    where the tta is the median of the last 5 epochs\"\"\"\n",
    "\n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done = False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "            \n",
    "            # if there are less than 5 elements behind, continue\n",
    "            if idx < 4:\n",
    "                continue\n",
    "                \n",
    "            # calculate the median of the next five elements\n",
    "            if np.median(accuracy[idx - 4:idx+1]) >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def tta(acc:int, df:pd.DataFrame,  acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \n",
    "    \n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done=False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "         \n",
    "            if a >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KubeML Experiments\n",
    "\n",
    "How to treat the kubeml experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join_df('./results/lenet/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get duplicated rows\n",
    "df[df.duplicated(['hash'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the extra variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.epoch_duration.map(lambda t: t[-1])\n",
    "\n",
    "# Set the parallelism to the first since it is constant\n",
    "df.parallelism = df.parallelism.map(lambda l:l[0])\n",
    "\n",
    "# change -1 to inf so the order is right in the plot\n",
    "df.k = df.k.map(lambda val: float('inf') if val == -1 else val)\n",
    "\n",
    "df['global_batch'] = df.batch_size * df.parallelism\n",
    "\n",
    "# compute the ttas\n",
    "df['tta_99'] = tta(99, df)\n",
    "df['tta_cross_99'] = tta_crossbow(99, df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the metrics in the lenet\n",
    "\n",
    "The first replication does not have the proper format, so we need to reformat it and combine it with the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1 = join_df('./results/lenet/metrics/1/')\n",
    "metrics2 = join_df('./results/lenet/metrics/2/')\n",
    "metrics3 = join_df('./results/lenet/metrics/3/')\n",
    "\n",
    "cpu = metrics1.groupby('exp_name')['cpu'].apply(list)\n",
    "mem = metrics1.groupby('exp_name')['mem'].apply(list)\n",
    "exps = metrics1.groupby('exp_name')['exp_name']\n",
    "\n",
    "metrics1 = pd.DataFrame({\n",
    "    'cpu':cpu,\n",
    "    'mem':mem\n",
    "})\n",
    "metrics1['exp_name'] = metrics1.index\n",
    "\n",
    "# concat all metrics and rename the exp_name as in the train\n",
    "m = pd.concat([metrics1, metrics2, metrics3], ignore_index=True)\n",
    "m.rename(columns={'exp_name':'id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add extra summary columns to the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine and Save the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.merge(m, on='id')\n",
    "d.to_pickle('./dataframes/lenet_kubeml.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Experiments\n",
    "\n",
    "How to treat the TF experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join_df('./results/tf/lenet/train/1/', './results/tf/lenet/train/2', './results/tf/lenet/train/3')\n",
    "\n",
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.val_accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.times.map(lambda t: t[-1])\n",
    "\n",
    "# Define the TTA\n",
    "df['tta_99'] = tta(0.99, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_99'] = tta_crossbow(0.99, df, time_column='times', acc_column='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the metrics from different  folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = join_df('./results/tf/lenet/metrics/1/', './results/tf/lenet/metrics/2', './results/tf/lenet/metrics/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./dataframes/lenet_tensorflow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_red_palette = ['#264653', '#2A9D8F', '#E9C46A', '#F4A261', '#E76F51']\n",
    "blue_yellow_palette=  ['#0077b6', '#d62828', '#f77f00', '#fcbf49', '#eae2b7']\n",
    "cool_p = ['#f87575', '#ffa9a3', '#b9e6ff', '#5c95ff', '#7e6c6c']\n",
    "wall_p = ['#e63946', '#f1faee', '#a8dadc', '#457b9d', '#1d3557']\n",
    "\n",
    "sns.palplot(sns.color_palette(blue_yellow_palette))\n",
    "\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette=blue_yellow_palette, )\n",
    "# sns.set_palette(blue_yellow_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Read the experiments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_file = './resnet_36exp.pkl'\n",
    "df = pd.read_pickle(experiment_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create new columns for representation\n",
    "\n",
    "- Final accuracy\n",
    "- Total time taken\n",
    "- Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot the Correlations between the K, Batch and Parallelism with time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df[['k', 'batch_size', 'parallelism', 'acc', 'time']].corr()\n",
    "sns.heatmap(corr,\n",
    "            annot=True,\n",
    ")\n",
    "\n",
    "# plt.savefig('./figures/resnet34/heat.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the max accuracies and times and check the parameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the max accuracies\n",
    "df[['k', 'parallelism', 'acc','batch_size','time']].sort_values(by='time', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calculate TTA with different accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['parallelism', 'epoch_duration', 'k'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-221-c71518940d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tta_cross_99'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'parallelism'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tta_cross_99'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tta_99'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch_duration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# plot the best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\qpe\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2906\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\qpe\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\qpe\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['parallelism', 'epoch_duration', 'k'] not in index\""
     ]
    }
   ],
   "source": [
    "s = df.sort_values('tta_cross_99')[['k', 'batch_size', 'parallelism', 'tta_cross_99', 'tta_99', 'acc', 'accuracy', 'epoch_duration']]\n",
    "\n",
    "# plot the best\n",
    "best = s.iloc[0]\n",
    "best\n",
    "\n",
    "\n",
    "x = range(1, len(best.accuracy)+1)\n",
    "plt.figure()\n",
    "plt.title(f'Best tta_99 (B={best.batch_size}, k={best.k}, P={best.parallelism})')\n",
    "sns.lineplot(x=best.epoch_duration, y = best.accuracy)\n",
    "sns.lineplot(x=best.epoch_duration, y= 99)\n",
    "plt.scatter(best.tta_cross_99, 99, marker='X', s=60, c='r')\n",
    "plt.xlabel('Time (s)', fontsize=15)\n",
    "plt.ylabel('Accuracy (%)', fontsize=15)\n",
    "\n",
    "# plt.savefig('./figures/gpu/best.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.tta_cross_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "sns.barplot(x='batch_size', y='tta_cross_99', data=df, ax=ax[0])\n",
    "sns.barplot(x='k', y='tta_cross_99', data=df, ax=ax[1])\n",
    "sns.barplot(x='parallelism', y='tta_cross_99', data=df ,ax=ax[2])\n",
    "sns.despine()\n",
    "\n",
    "# plt.savefig('./figures/gpu/tta_99.png', dpi=300)\n",
    "\n",
    "# sns.barplot(x='k', y='tta_99', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do ANOVA Linear Model to calculate the influence of the parameters\n",
    "\n",
    "Using ANOVA we can get an idea of how the different parameters interact with each other and their influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ANOVA test\n",
    "import researchpy as rp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA(df: pd.DataFrame, y: str, use_all = False,verbose=False):\n",
    "    \"\"\"Run the ANOVA analysis with the batch, k and parallelism columns for the \n",
    "    given output variable\"\"\"\n",
    "    \n",
    "    # If use all is true we use all the variables to check either accuracy and time\n",
    "    # including also the iowait and the cpu to see what fully influences the stuff\n",
    "    \n",
    "    \n",
    "    if not use_all:\n",
    "        # Plot the summary dataframe\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ batch_size*k*parallelism', df).fit()\n",
    "        \n",
    "    else:\n",
    "        if y not in ['acc', 'time']:\n",
    "            raise ValueError('When use_all = True we predict either final_accuracy or time, not', y)\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ cpu*batch*njobs*cpu_mean*iowait_mean', df).fit()\n",
    "        \n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "        display(model.summary())\n",
    "    \n",
    "    res = sm.stats.anova_lm(model, typ=2)\n",
    "    \n",
    "    return res, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.k = df.k.map(lambda val: -1 if val == float('inf') else val)\n",
    "\n",
    "res, model = ANOVA(d, y='gpu_usage', verbose=True)\n",
    "\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the distributions of time and accuracy as a function of K, Batch and parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the accuracy as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "sns.barplot(x='batch_size', y='acc', hue='k', data=df, ax=ax[0], capsize=.05)\n",
    "sns.barplot(x='k', y='acc', data=df, ax=ax[1], capsize=.05, hue='parallelism')\n",
    "sns.barplot(x='parallelism', y='acc', data=df, hue='k' ,ax=ax[2] ,capsize=.05)\n",
    "sns.despine()\n",
    "plt.legend(title='k', ncol=4, bbox_to_anchor=(0.075,1))\n",
    "\n",
    "for a in ax:\n",
    "    a.set_ylim([75, 100])\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/resnet34/accuracy.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='parallelism', y='tta_cross_99', data=df, capsize=.02, hue='batch_size')\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/resnet34/acc_per_k_and_parallelism.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the time as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "sns.barplot(x='batch_size', y='gpu_usage', hue='parallelism', data=d, ax=ax[0])\n",
    "sns.barplot(x='k', y='time', data=df, ax=ax[1])\n",
    "sns.barplot(x='parallelism', y='time', data=df, ax=ax[2], hue='k')\n",
    "\n",
    "# plt.savefig('./figures/resnet34/time.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = d[['batch_size', 'k', 'parallelism', 'gpu_usage', 'gpu_1', 'gpu_0_mean_usage', 'gpu_1_mean_usage']].sort_values('gpu_usage')\n",
    "\n",
    "d.loc[(d.batch_size == 128) & (d.parallelism == 8) & (d.k == float('inf'))]\n",
    "s.iloc[27]['gpu_0_mean_usage']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "f, ax = plt.subplots(1, 3, figsize=(20,8), sharey=True)\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==32], capsize=.05, hue='parallelism', ax=ax[0])\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==64], capsize=.05, hue='parallelism', ax=ax[1])\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==128], capsize=.05, hue='parallelism', ax=ax[2])\n",
    "\n",
    "plt.savefig('./figures/resnet34/time_per_all.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_k_and_batch(k: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.k==k) & (df.batch_size==batch)].sort_values(by='parallelism', ascending=False)\n",
    "\n",
    "    plt.rc('font', size=13)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, k={k}')\n",
    "        ax.legend(title='parallelism')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=32, ax=axes[0][2])\n",
    "    \n",
    "plot_loss_with_k_and_batch(k=8, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/accuracy_study.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep Parallelism and batch set, vary K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep K and Batch set, vary parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_k_and_batch(k: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.k==k) & (df.batch_size==batch)].sort_values(by='parallelism', ascending=False)\n",
    "\n",
    "    plt.rc('font', size=13)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, k={k}')\n",
    "        ax.legend(title='parallelism')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=32, ax=axes[0][2])\n",
    "    \n",
    "plot_loss_with_k_and_batch(k=8, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/accuracy_study.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep Parallelism and batch set, vary K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_parallelism_and_batch(p: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.parallelism==p) & (df.batch_size==batch)].sort_values(by='k', ascending=False)\n",
    "    \n",
    "    approx_k = (60000/p)/batch\n",
    "\n",
    "    plt.rc('font', size=16)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.k))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "            label = str(row.k) if row.k != float('inf') else f'{row.k} ({int(approx_k)})'\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=label)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, Parallelism={p}')\n",
    "        ax.legend(title='k')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(30, 20), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=32, ax=axes[0][2])\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "plt.savefig('./figures/accuracy_study_varying_k.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot 3d dependencies between K and parallelism on time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 2, projection='3d')\n",
    "\n",
    "f = plt.figure()\n",
    "ax = f.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "X, Y = np.meshgrid(df.k.map(lambda v: 500 if v == float('inf') else v), df.parallelism)\n",
    "Z = griddata((df.k.map(lambda v: 500 if v == float('inf') else v),\n",
    "              df.parallelism),\n",
    "              df.acc, (X, Y), method='cubic')\n",
    "\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='coolwarm',\n",
    "                       linewidth=0, antialiased=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = df.loc[df.batch==64]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
