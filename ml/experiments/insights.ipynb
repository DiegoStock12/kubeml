{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gather insights from the experiments run on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.utils import check_missing_experiments, join_df\n",
    "from common.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the TTA Formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate time to accuracy for different accuracies\n",
    "def tta_crossbow(acc:int, df: pd.DataFrame, acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \"\"\"Computes the tta as in the crossbow paper\n",
    "    where the tta is the median of the last 5 epochs\"\"\"\n",
    "\n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done = False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "            \n",
    "            # if there are less than 5 elements behind, continue\n",
    "            if idx < 4:\n",
    "                continue\n",
    "                \n",
    "            # calculate the median of the next five elements\n",
    "            if np.median(accuracy[idx - 4:idx+1]) >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def tta(acc:int, df:pd.DataFrame,  acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \n",
    "    \n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done=False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "         \n",
    "            if a >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KubeML Experiments\n",
    "\n",
    "How to treat the kubeml experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join_df('./results/lenet/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get duplicated rows\n",
    "df[df.duplicated(['hash'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the extra variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.epoch_duration.map(lambda t: t[-1])\n",
    "\n",
    "# Set the parallelism to the first since it is constant\n",
    "df.parallelism = df.parallelism.map(lambda l:l[0])\n",
    "\n",
    "# change -1 to inf so the order is right in the plot\n",
    "df.k = df.k.map(lambda val: float('inf') if val == -1 else val)\n",
    "\n",
    "df['global_batch'] = df.batch_size * df.parallelism\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ttas\n",
    "df['tta_99'] = tta(99, df)\n",
    "df['tta_cross_99'] = tta_crossbow(99, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the metrics in the lenet\n",
    "\n",
    "The first replication does not have the proper format, so we need to reformat it and combine it with the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1 = join_df('./results/lenet/metrics/1/')\n",
    "metrics2 = join_df('./results/lenet/metrics/2/')\n",
    "metrics3 = join_df('./results/lenet/metrics/3/')\n",
    "\n",
    "cpu = metrics1.groupby('exp_name')['cpu'].apply(list)\n",
    "mem = metrics1.groupby('exp_name')['mem'].apply(list)\n",
    "exps = metrics1.groupby('exp_name')['exp_name']\n",
    "\n",
    "metrics1 = pd.DataFrame({\n",
    "    'cpu':cpu,\n",
    "    'mem':mem\n",
    "})\n",
    "metrics1['exp_name'] = metrics1.index\n",
    "\n",
    "# concat all metrics and rename the exp_name as in the train\n",
    "m = pd.concat([metrics1, metrics2, metrics3], ignore_index=True)\n",
    "m.rename(columns={'exp_name':'id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add extra summary columns to the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine and Save the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.merge(m, on='id')\n",
    "d.to_pickle('./dataframes/lenet_kubeml.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Experiments\n",
    "\n",
    "How to treat the TF experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join_df('./results/tf/lenet/train/1/', './results/tf/lenet/train/2', './results/tf/lenet/train/3')\n",
    "\n",
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.val_accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.times.map(lambda t: t[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TTA\n",
    "df['tta_69'] = tta(0.69, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_69'] = tta_crossbow(0.69, df, time_column='times', acc_column='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the metrics from different  folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = join_df('./results/tf/lenet/metrics/1/', './results/tf/lenet/metrics/2', './results/tf/lenet/metrics/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./dataframes/lenet_kubeml.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASgAAABICAYAAABFhGj3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB20lEQVR4nO3YMWoVURiG4f9IJCDEi5BcuwSxtLWzsXUFKbODFFmKpVuwyj7SiI3BSrAMIWBjIRz7oJCBnJwvw/OUw3D5/uaFua33XgCJnsweAPA/AgXEEigglkABsQQKiCVQQKydJS+3Z5tem+2oLdO9ufk5e8JQuy9+z54wTNt7PnvCUH92X86eMNSXr9+veu8Ht58vClRttlUnH+9tVJrP52ezJwz16vjb7AnDPH3/bvaEoa5fn86eMNT28MOPfz33iQfEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiNV673d/ubVfVXU5bs50+1V1NXvEIGu+rcp9j91R7/3g9sOdhT9y2Xt/e0+D4rTWLtZ635pvq3LfWvnEA2IJFBBraaA+DVmRY833rfm2Kvet0qI/yQEekk88IJZAAbEECoglUEAsgQJi/QVCLj0ovT6UxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "green_red_palette = ['#264653', '#2A9D8F', '#E9C46A', '#F4A261', '#E76F51']\n",
    "blue_yellow_palette=  ['#0077b6', '#d62828', '#f77f00', '#fcbf49', '#eae2b7']\n",
    "cool_p = ['#f87575', '#ffa9a3', '#b9e6ff', '#5c95ff', '#7e6c6c']\n",
    "wall_p = ['#e63946', '#f1faee', '#a8dadc', '#457b9d', '#1d3557']\n",
    "\n",
    "sns.palplot(sns.color_palette(blue_yellow_palette))\n",
    "\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette=blue_yellow_palette, )\n",
    "# sns.set_palette(blue_yellow_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read the experiments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hash</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>times</th>\n",
       "      <th>acc</th>\n",
       "      <th>...</th>\n",
       "      <th>mem</th>\n",
       "      <th>gpu_0</th>\n",
       "      <th>gpu_1</th>\n",
       "      <th>cpu_mean</th>\n",
       "      <th>gpu_0_mean_usage</th>\n",
       "      <th>gpu_1_mean_usage</th>\n",
       "      <th>gpu_0_mean_memory</th>\n",
       "      <th>gpu_1_mean_memory</th>\n",
       "      <th>gpu_usage</th>\n",
       "      <th>mem_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet</td>\n",
       "      <td>3b64b0be38fb8e94</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.17032000422477722, 0.2808600068092346, 0.35...</td>\n",
       "      <td>[2.386634588241577, 1.8890058994293213, 1.7486...</td>\n",
       "      <td>[0.2615000009536743, 0.3276999890804291, 0.395...</td>\n",
       "      <td>[1.8862396478652954, 1.725894570350647, 1.6532...</td>\n",
       "      <td>[86.82871699333191, 161.10458970069885, 235.44...</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=195649....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.481411</td>\n",
       "      <td>0.690529</td>\n",
       "      <td>0.692117</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.691323</td>\n",
       "      <td>5.612619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet</td>\n",
       "      <td>9848e15a8cb9456b</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.20927999913692474, 0.35989999771118164, 0.4...</td>\n",
       "      <td>[2.9395194053649902, 1.7702909708023071, 1.570...</td>\n",
       "      <td>[0.14980000257492065, 0.17270000278949738, 0.3...</td>\n",
       "      <td>[2.747114896774292, 2.5870492458343506, 1.9928...</td>\n",
       "      <td>[26.537360668182373, 38.13520431518555, 49.665...</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=200833....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.831624</td>\n",
       "      <td>0.688376</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>10896.752137</td>\n",
       "      <td>10896.478632</td>\n",
       "      <td>0.687137</td>\n",
       "      <td>5.124786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet</td>\n",
       "      <td>e551b774a7b5ccc0</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.21724000573158264, 0.33597999811172485, 0.4...</td>\n",
       "      <td>[2.6788625717163086, 1.7895755767822266, 1.611...</td>\n",
       "      <td>[0.23649999499320984, 0.2770000100135803, 0.44...</td>\n",
       "      <td>[2.0208323001861572, 1.976898431777954, 1.5212...</td>\n",
       "      <td>[33.218318939208984, 53.329391956329346, 73.47...</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=194600....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.474020</td>\n",
       "      <td>0.705098</td>\n",
       "      <td>0.702794</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.703946</td>\n",
       "      <td>5.612255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet</td>\n",
       "      <td>eeaea0a56be5c6c9</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.21930000185966492, 0.346560001373291, 0.435...</td>\n",
       "      <td>[2.442678451538086, 1.7620742321014404, 1.5449...</td>\n",
       "      <td>[0.20569999516010284, 0.38609999418258667, 0.4...</td>\n",
       "      <td>[2.4119229316711426, 1.6152931451797485, 1.422...</td>\n",
       "      <td>[51.08732867240906, 89.5283989906311, 127.9574...</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=195794....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.461558</td>\n",
       "      <td>0.694571</td>\n",
       "      <td>0.694883</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.694727</td>\n",
       "      <td>5.626494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet</td>\n",
       "      <td>3b64b0be38fb8e94</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.17776000499725342, 0.25637999176979065, 0.3...</td>\n",
       "      <td>[2.443981170654297, 1.9975420236587524, 1.8435...</td>\n",
       "      <td>[0.2281000018119812, 0.31769999861717224, 0.39...</td>\n",
       "      <td>[2.1482324600219727, 1.9316531419754028, 1.673...</td>\n",
       "      <td>[91.24218130111694, 167.12129759788513, 242.37...</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=193895....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.543989</td>\n",
       "      <td>0.685997</td>\n",
       "      <td>0.692999</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.689498</td>\n",
       "      <td>5.696301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet</td>\n",
       "      <td>9848e15a8cb9456b</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.2289399951696396, 0.3654800057411194, 0.430...</td>\n",
       "      <td>[2.9462780952453613, 1.74190092086792, 1.57160...</td>\n",
       "      <td>[0.1525000035762787, 0.31060001254081726, 0.30...</td>\n",
       "      <td>[9.569252967834473, 1.8199352025985718, 1.9944...</td>\n",
       "      <td>[28.763103485107422, 40.597825050354004, 52.13...</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=200769....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.790083</td>\n",
       "      <td>0.673802</td>\n",
       "      <td>0.674545</td>\n",
       "      <td>10896.942149</td>\n",
       "      <td>10896.545455</td>\n",
       "      <td>0.674174</td>\n",
       "      <td>5.247934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet</td>\n",
       "      <td>e551b774a7b5ccc0</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.18846000730991364, 0.30963999032974243, 0.4...</td>\n",
       "      <td>[2.8464584350585938, 1.8502916097640991, 1.623...</td>\n",
       "      <td>[0.2199999988079071, 0.28279998898506165, 0.38...</td>\n",
       "      <td>[2.0936760902404785, 2.0967390537261963, 1.697...</td>\n",
       "      <td>[35.912309885025024, 56.74307084083557, 77.750...</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=194188....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.576887</td>\n",
       "      <td>0.680755</td>\n",
       "      <td>0.690613</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.685684</td>\n",
       "      <td>5.627358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet</td>\n",
       "      <td>eeaea0a56be5c6c9</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.16877999901771545, 0.31738001108169556, 0.4...</td>\n",
       "      <td>[2.5261449813842773, 1.8163659572601318, 1.648...</td>\n",
       "      <td>[0.2387000024318695, 0.34369999170303345, 0.43...</td>\n",
       "      <td>[2.001915693283081, 1.765451192855835, 1.73678...</td>\n",
       "      <td>[54.50707030296326, 93.83418011665344, 133.832...</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=194010....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.542065</td>\n",
       "      <td>0.681788</td>\n",
       "      <td>0.690705</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.686247</td>\n",
       "      <td>5.648866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet</td>\n",
       "      <td>3b64b0be38fb8e94</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.194240003824234, 0.3152199983596802, 0.3870...</td>\n",
       "      <td>[2.36903977394104, 1.8614556789398193, 1.71788...</td>\n",
       "      <td>[0.22830000519752502, 0.35499998927116394, 0.4...</td>\n",
       "      <td>[1.996896505355835, 1.8208531141281128, 1.6707...</td>\n",
       "      <td>[91.85955429077148, 168.55097484588623, 245.45...</td>\n",
       "      <td>0.6482</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=193835....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.559844</td>\n",
       "      <td>0.675593</td>\n",
       "      <td>0.678110</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.676851</td>\n",
       "      <td>5.707171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet</td>\n",
       "      <td>9848e15a8cb9456b</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.17047999799251556, 0.28755998611450195, 0.3...</td>\n",
       "      <td>[3.061053514480591, 2.008331775665283, 1.72609...</td>\n",
       "      <td>[0.10949999839067459, 0.15289999544620514, 0.3...</td>\n",
       "      <td>[2.5662691593170166, 2.3880715370178223, 1.798...</td>\n",
       "      <td>[29.048789501190186, 41.015719413757324, 52.65...</td>\n",
       "      <td>0.6254</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=200785....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.671074</td>\n",
       "      <td>0.675124</td>\n",
       "      <td>0.679174</td>\n",
       "      <td>10896.942149</td>\n",
       "      <td>10896.528926</td>\n",
       "      <td>0.677149</td>\n",
       "      <td>5.276860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet</td>\n",
       "      <td>e551b774a7b5ccc0</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.25071999430656433, 0.40685999393463135, 0.4...</td>\n",
       "      <td>[2.636397123336792, 1.6303213834762573, 1.4578...</td>\n",
       "      <td>[0.25859999656677246, 0.4004000127315521, 0.46...</td>\n",
       "      <td>[1.9681475162506104, 1.703709363937378, 1.5188...</td>\n",
       "      <td>[36.018375873565674, 57.17633390426636, 78.124...</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=194070....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.588732</td>\n",
       "      <td>0.682254</td>\n",
       "      <td>0.686761</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.684507</td>\n",
       "      <td>5.649296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet</td>\n",
       "      <td>eeaea0a56be5c6c9</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.19458000361919403, 0.36792001128196716, 0.4...</td>\n",
       "      <td>[2.4999794960021973, 1.7349265813827515, 1.561...</td>\n",
       "      <td>[0.2529999911785126, 0.38280001282691956, 0.46...</td>\n",
       "      <td>[2.0103321075439453, 1.7002928256988525, 1.548...</td>\n",
       "      <td>[55.50187683105469, 95.9315071105957, 136.0994...</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=193943....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>2.570968</td>\n",
       "      <td>0.675955</td>\n",
       "      <td>0.681663</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>10914.000000</td>\n",
       "      <td>0.678809</td>\n",
       "      <td>5.668734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model              hash  batch_size  epochs  \\\n",
       "0   resnet  3b64b0be38fb8e94          32      30   \n",
       "1   resnet  9848e15a8cb9456b         256      30   \n",
       "2   resnet  e551b774a7b5ccc0         128      30   \n",
       "3   resnet  eeaea0a56be5c6c9          64      30   \n",
       "4   resnet  3b64b0be38fb8e94          32      30   \n",
       "5   resnet  9848e15a8cb9456b         256      30   \n",
       "6   resnet  e551b774a7b5ccc0         128      30   \n",
       "7   resnet  eeaea0a56be5c6c9          64      30   \n",
       "8   resnet  3b64b0be38fb8e94          32      30   \n",
       "9   resnet  9848e15a8cb9456b         256      30   \n",
       "10  resnet  e551b774a7b5ccc0         128      30   \n",
       "11  resnet  eeaea0a56be5c6c9          64      30   \n",
       "\n",
       "                                             accuracy  \\\n",
       "0   [0.17032000422477722, 0.2808600068092346, 0.35...   \n",
       "1   [0.20927999913692474, 0.35989999771118164, 0.4...   \n",
       "2   [0.21724000573158264, 0.33597999811172485, 0.4...   \n",
       "3   [0.21930000185966492, 0.346560001373291, 0.435...   \n",
       "4   [0.17776000499725342, 0.25637999176979065, 0.3...   \n",
       "5   [0.2289399951696396, 0.3654800057411194, 0.430...   \n",
       "6   [0.18846000730991364, 0.30963999032974243, 0.4...   \n",
       "7   [0.16877999901771545, 0.31738001108169556, 0.4...   \n",
       "8   [0.194240003824234, 0.3152199983596802, 0.3870...   \n",
       "9   [0.17047999799251556, 0.28755998611450195, 0.3...   \n",
       "10  [0.25071999430656433, 0.40685999393463135, 0.4...   \n",
       "11  [0.19458000361919403, 0.36792001128196716, 0.4...   \n",
       "\n",
       "                                                 loss  \\\n",
       "0   [2.386634588241577, 1.8890058994293213, 1.7486...   \n",
       "1   [2.9395194053649902, 1.7702909708023071, 1.570...   \n",
       "2   [2.6788625717163086, 1.7895755767822266, 1.611...   \n",
       "3   [2.442678451538086, 1.7620742321014404, 1.5449...   \n",
       "4   [2.443981170654297, 1.9975420236587524, 1.8435...   \n",
       "5   [2.9462780952453613, 1.74190092086792, 1.57160...   \n",
       "6   [2.8464584350585938, 1.8502916097640991, 1.623...   \n",
       "7   [2.5261449813842773, 1.8163659572601318, 1.648...   \n",
       "8   [2.36903977394104, 1.8614556789398193, 1.71788...   \n",
       "9   [3.061053514480591, 2.008331775665283, 1.72609...   \n",
       "10  [2.636397123336792, 1.6303213834762573, 1.4578...   \n",
       "11  [2.4999794960021973, 1.7349265813827515, 1.561...   \n",
       "\n",
       "                                         val_accuracy  \\\n",
       "0   [0.2615000009536743, 0.3276999890804291, 0.395...   \n",
       "1   [0.14980000257492065, 0.17270000278949738, 0.3...   \n",
       "2   [0.23649999499320984, 0.2770000100135803, 0.44...   \n",
       "3   [0.20569999516010284, 0.38609999418258667, 0.4...   \n",
       "4   [0.2281000018119812, 0.31769999861717224, 0.39...   \n",
       "5   [0.1525000035762787, 0.31060001254081726, 0.30...   \n",
       "6   [0.2199999988079071, 0.28279998898506165, 0.38...   \n",
       "7   [0.2387000024318695, 0.34369999170303345, 0.43...   \n",
       "8   [0.22830000519752502, 0.35499998927116394, 0.4...   \n",
       "9   [0.10949999839067459, 0.15289999544620514, 0.3...   \n",
       "10  [0.25859999656677246, 0.4004000127315521, 0.46...   \n",
       "11  [0.2529999911785126, 0.38280001282691956, 0.46...   \n",
       "\n",
       "                                             val_loss  \\\n",
       "0   [1.8862396478652954, 1.725894570350647, 1.6532...   \n",
       "1   [2.747114896774292, 2.5870492458343506, 1.9928...   \n",
       "2   [2.0208323001861572, 1.976898431777954, 1.5212...   \n",
       "3   [2.4119229316711426, 1.6152931451797485, 1.422...   \n",
       "4   [2.1482324600219727, 1.9316531419754028, 1.673...   \n",
       "5   [9.569252967834473, 1.8199352025985718, 1.9944...   \n",
       "6   [2.0936760902404785, 2.0967390537261963, 1.697...   \n",
       "7   [2.001915693283081, 1.765451192855835, 1.73678...   \n",
       "8   [1.996896505355835, 1.8208531141281128, 1.6707...   \n",
       "9   [2.5662691593170166, 2.3880715370178223, 1.798...   \n",
       "10  [1.9681475162506104, 1.703709363937378, 1.5188...   \n",
       "11  [2.0103321075439453, 1.7002928256988525, 1.548...   \n",
       "\n",
       "                                                times     acc  ...  \\\n",
       "0   [86.82871699333191, 161.10458970069885, 235.44...  0.6542  ...   \n",
       "1   [26.537360668182373, 38.13520431518555, 49.665...  0.6561  ...   \n",
       "2   [33.218318939208984, 53.329391956329346, 73.47...  0.6531  ...   \n",
       "3   [51.08732867240906, 89.5283989906311, 127.9574...  0.6581  ...   \n",
       "4   [91.24218130111694, 167.12129759788513, 242.37...  0.6825  ...   \n",
       "5   [28.763103485107422, 40.597825050354004, 52.13...  0.6531  ...   \n",
       "6   [35.912309885025024, 56.74307084083557, 77.750...  0.6798  ...   \n",
       "7   [54.50707030296326, 93.83418011665344, 133.832...  0.6773  ...   \n",
       "8   [91.85955429077148, 168.55097484588623, 245.45...  0.6482  ...   \n",
       "9   [29.048789501190186, 41.015719413757324, 52.65...  0.6254  ...   \n",
       "10  [36.018375873565674, 57.17633390426636, 78.124...  0.6885  ...   \n",
       "11  [55.50187683105469, 95.9315071105957, 136.0994...  0.6880  ...   \n",
       "\n",
       "                                                  mem  \\\n",
       "0   [MemoryStats(total=270332.669952, free=195649....   \n",
       "1   [MemoryStats(total=270332.669952, free=200833....   \n",
       "2   [MemoryStats(total=270332.669952, free=194600....   \n",
       "3   [MemoryStats(total=270332.669952, free=195794....   \n",
       "4   [MemoryStats(total=270332.669952, free=193895....   \n",
       "5   [MemoryStats(total=270332.669952, free=200769....   \n",
       "6   [MemoryStats(total=270332.669952, free=194188....   \n",
       "7   [MemoryStats(total=270332.669952, free=194010....   \n",
       "8   [MemoryStats(total=270332.669952, free=193835....   \n",
       "9   [MemoryStats(total=270332.669952, free=200785....   \n",
       "10  [MemoryStats(total=270332.669952, free=194070....   \n",
       "11  [MemoryStats(total=270332.669952, free=193943....   \n",
       "\n",
       "                                                gpu_0  \\\n",
       "0   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "1   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "2   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "3   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "4   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "5   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "6   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "7   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "8   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "9   [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "10  [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "11  [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "\n",
       "                                                gpu_1  cpu_mean  \\\n",
       "0   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.481411   \n",
       "1   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.831624   \n",
       "2   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.474020   \n",
       "3   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.461558   \n",
       "4   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.543989   \n",
       "5   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.790083   \n",
       "6   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.576887   \n",
       "7   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.542065   \n",
       "8   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.559844   \n",
       "9   [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.671074   \n",
       "10  [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.588732   \n",
       "11  [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  2.570968   \n",
       "\n",
       "   gpu_0_mean_usage gpu_1_mean_usage gpu_0_mean_memory gpu_1_mean_memory  \\\n",
       "0          0.690529         0.692117      10914.000000      10914.000000   \n",
       "1          0.688376         0.685897      10896.752137      10896.478632   \n",
       "2          0.705098         0.702794      10914.000000      10914.000000   \n",
       "3          0.694571         0.694883      10914.000000      10914.000000   \n",
       "4          0.685997         0.692999      10914.000000      10914.000000   \n",
       "5          0.673802         0.674545      10896.942149      10896.545455   \n",
       "6          0.680755         0.690613      10914.000000      10914.000000   \n",
       "7          0.681788         0.690705      10914.000000      10914.000000   \n",
       "8          0.675593         0.678110      10914.000000      10914.000000   \n",
       "9          0.675124         0.679174      10896.942149      10896.528926   \n",
       "10         0.682254         0.686761      10914.000000      10914.000000   \n",
       "11         0.675955         0.681663      10914.000000      10914.000000   \n",
       "\n",
       "    gpu_usage  mem_mean  \n",
       "0    0.691323  5.612619  \n",
       "1    0.687137  5.124786  \n",
       "2    0.703946  5.612255  \n",
       "3    0.694727  5.626494  \n",
       "4    0.689498  5.696301  \n",
       "5    0.674174  5.247934  \n",
       "6    0.685684  5.627358  \n",
       "7    0.686247  5.648866  \n",
       "8    0.676851  5.707171  \n",
       "9    0.677149  5.276860  \n",
       "10   0.684507  5.649296  \n",
       "11   0.678809  5.668734  \n",
       "\n",
       "[12 rows x 25 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_file = './dataframes/resnet_tensorflow.pkl'\n",
    "df = pd.read_pickle(experiment_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create new columns for representation\n",
    "\n",
    "- Final accuracy\n",
    "- Total time taken\n",
    "- Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot the Correlations between the K, Batch and Parallelism with time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df[['k', 'batch_size', 'parallelism', 'acc', 'time']].corr()\n",
    "sns.heatmap(corr,\n",
    "            annot=True,\n",
    ")\n",
    "\n",
    "# plt.savefig('./figures/resnet34/heat.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('time')\n",
    "\n",
    "mean = df.groupby('hash').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the max accuracies and times and check the parameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the max accuracies\n",
    "df[['k', 'parallelism', 'acc','batch_size','time']].sort_values(by='time', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calculate TTA with different accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tta_cross_99'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-629721411f00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tta_cross_99'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'parallelism'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tta_cross_99'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tta_99'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch_duration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# plot the best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\qpe\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   5292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5293\u001b[0m             \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5294\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5296\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\qpe\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1563\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tta_cross_99'"
     ]
    }
   ],
   "source": [
    "s = df.sort_values('tta_cross_99')[['k', 'batch_size', 'parallelism', 'tta_cross_99', 'tta_99', 'acc', 'accuracy', 'epoch_duration']]\n",
    "\n",
    "# plot the best\n",
    "best = s.iloc[0]\n",
    "best\n",
    "\n",
    "\n",
    "x = range(1, len(best.accuracy)+1)\n",
    "plt.figure()\n",
    "plt.title(f'Best tta_99 (B={best.batch_size}, k={best.k}, P={best.parallelism})')\n",
    "sns.lineplot(x=best.epoch_duration, y = best.accuracy)\n",
    "sns.lineplot(x=best.epoch_duration, y= 99)\n",
    "plt.scatter(best.tta_cross_99, 99, marker='X', s=60, c='r')\n",
    "plt.xlabel('Time (s)', fontsize=15)\n",
    "plt.ylabel('Accuracy (%)', fontsize=15)\n",
    "\n",
    "# plt.savefig('./figures/gpu/best.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.tta_cross_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 3, sharey=False, figsize=(20, 5))\n",
    "sns.barplot(x='batch_size', y='time', data=df,  ax=ax[0])\n",
    "sns.barplot(x='batch_size', y='tta_cross_67', data=df, ax=ax[1])\n",
    "sns.barplot(x='batch_size', y='gpu_usage', data=df ,ax=ax[2])\n",
    "sns.despine()\n",
    "\n",
    "# plt.savefig('./figures/gpu/tta_99.png', dpi=300)\n",
    "\n",
    "# sns.barplot(x='k', y='tta_99', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do ANOVA Linear Model to calculate the influence of the parameters\n",
    "\n",
    "Using ANOVA we can get an idea of how the different parameters interact with each other and their influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ANOVA test\n",
    "import researchpy as rp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA(df: pd.DataFrame, y: str, use_all = False,verbose=False):\n",
    "    \"\"\"Run the ANOVA analysis with the batch, k and parallelism columns for the \n",
    "    given output variable\"\"\"\n",
    "    \n",
    "    # If use all is true we use all the variables to check either accuracy and time\n",
    "    # including also the iowait and the cpu to see what fully influences the stuff\n",
    "    \n",
    "    \n",
    "    if not use_all:\n",
    "        # Plot the summary dataframe\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ batch_size*k*parallelism', df).fit()\n",
    "        \n",
    "    else:\n",
    "        if y not in ['acc', 'time']:\n",
    "            raise ValueError('When use_all = True we predict either final_accuracy or time, not', y)\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ cpu*batch*njobs*cpu_mean*iowait_mean', df).fit()\n",
    "        \n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "        display(model.summary())\n",
    "    \n",
    "    res = sm.stats.anova_lm(model, typ=2)\n",
    "    \n",
    "    return res, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.k = df.k.map(lambda val: -1 if val == float('inf') else val)\n",
    "\n",
    "res, model = ANOVA(d, y='gpu_usage', verbose=True)\n",
    "\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the distributions of time and accuracy as a function of K, Batch and parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the accuracy as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "sns.barplot(x='batch_size', y='acc', hue='k', data=df, ax=ax[0], capsize=.05)\n",
    "sns.barplot(x='k', y='acc', data=df, ax=ax[1], capsize=.05, hue='parallelism')\n",
    "sns.barplot(x='parallelism', y='acc', data=df, hue='k' ,ax=ax[2] ,capsize=.05)\n",
    "sns.despine()\n",
    "plt.legend(title='k', ncol=4, bbox_to_anchor=(0.075,1))\n",
    "\n",
    "for a in ax:\n",
    "    a.set_ylim([75, 100])\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/resnet34/accuracy.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='parallelism', y='tta_cross_99', data=df, capsize=.02, hue='batch_size')\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/resnet34/acc_per_k_and_parallelism.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_pickle('./dataframes/lenet_tensorflow.pkl')\n",
    "d = pd.read_pickle('./dataframes/lenet_kubeml.pkl')\n",
    "d = d.loc[d.parallelism==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>tta_cross_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>32</td>\n",
       "      <td>82.370374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>83.256948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>32</td>\n",
       "      <td>84.316683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>16</td>\n",
       "      <td>92.441923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>16</td>\n",
       "      <td>101.195969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16</td>\n",
       "      <td>125.816565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>64</td>\n",
       "      <td>138.775395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64</td>\n",
       "      <td>140.742009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>64</td>\n",
       "      <td>140.943138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>142.674177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>64</td>\n",
       "      <td>143.598086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>16</td>\n",
       "      <td>144.182310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>64</td>\n",
       "      <td>145.785317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>16</td>\n",
       "      <td>148.940941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>32</td>\n",
       "      <td>159.049880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>32</td>\n",
       "      <td>161.446891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>32</td>\n",
       "      <td>162.843089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>16</td>\n",
       "      <td>272.334462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>306.976264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>364.546680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>16</td>\n",
       "      <td>370.926736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>376.359481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size  tta_cross_99\n",
       "128          32     82.370374\n",
       "23           32     83.256948\n",
       "160          32     84.316683\n",
       "162          16     92.441923\n",
       "79           16    101.195969\n",
       "43           16    125.816565\n",
       "154          64    138.775395\n",
       "45           64    140.742009\n",
       "144          64    140.943138\n",
       "8            64    142.674177\n",
       "136          64    143.598086\n",
       "118          16    144.182310\n",
       "192          64    145.785317\n",
       "112          16    148.940941\n",
       "103          32    159.049880\n",
       "169          32    161.446891\n",
       "129          32    162.843089\n",
       "73           16    272.334462\n",
       "4            16    306.976264\n",
       "42           16    364.546680\n",
       "122          16    370.926736\n",
       "6            16    376.359481\n",
       "10          128           NaN\n",
       "17           32           NaN\n",
       "50           32           NaN\n",
       "57          128           NaN\n",
       "61          128           NaN\n",
       "63          128           NaN\n",
       "64          128           NaN\n",
       "67           64           NaN\n",
       "82          128           NaN\n",
       "88           16           NaN\n",
       "90           32           NaN\n",
       "92           32           NaN\n",
       "109         128           NaN\n",
       "115         128           NaN\n",
       "127         128           NaN\n",
       "134         128           NaN\n",
       "147          32           NaN\n",
       "152          64           NaN\n",
       "158          64           NaN\n",
       "161          64           NaN\n",
       "170          32           NaN\n",
       "173         128           NaN\n",
       "175          64           NaN\n",
       "176          16           NaN\n",
       "178          64           NaN\n",
       "184         128           NaN"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sort_values('tta_cross_99')[['batch_size', 'tta_cross_99']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the time as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='batch_size', ylabel='tta_cross_99'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAAE/CAYAAADhQsJCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAApzUlEQVR4nO3de5iVdb0+/ntkYAixrAQsNbvSkG2Elu4ENNim4AFGVMzwhF7bUvOU4OURynOyzbIsLd3b1Mrakpfi4TLQNN25ES0yDdPwq4KpyEE8cRqGYf3+4MdsUQ6D86xZa5jX65/lOs265+Naz3txz/OsVVMqlUoBAAAAgAJsVukAAAAAAGw6lE0AAAAAFEbZBAAAAEBhlE0AAAAAFEbZBAAAAEBhaisdoLVWrlyZxYsXp3Pnzqmpqal0HICqUSqV0tjYmM033zybbdZx/7ZgTgCsnTmxijkBsHatmRPtvmxavHhxZs6cWekYAFWrd+/e2WKLLSodo2LMCYD1MyfMCYD1+SBzot2XTZ07d06y6pfv0qVLhdMAVI/ly5dn5syZzdvJjsqcAFg7c2IVc2KVGTNmpG/fvpWOUXHWYRXrYA2S1s2Jdl82rd7VtUuXLqmrq6twGoDq09EPCTAnANbPnDAnVuvov/9q1mEV62ANVvsgc6LjHpwNAAAAQOGUTQAAAAAURtkEAAAAQGGUTQAAAAAURtkEAAAAQGGUTQAAAAAURtkEAAAAQGGUTQAAAAAURtkEAAAAQGGUTQB0eMsaV1Q6QlWwDgAAFKG20gEAoNK6dq7N1mNuqnSMinvtquMqHQEAgE2APZsAAAAAKIyyCQDYJEybNi1jx47NtGnTKh0FAKBDcxgdALBJuOmmm/Lcc89lyZIl6d+/f6XjAAB0WPZsAgA2CUuWLFnjFACAylA2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFCYspZNP/nJTzJs2LAMGzYsV1xxRZJk6tSpqa+vz9ChQ3PVVVc13/aZZ57JyJEjs99++2XcuHFZsWJFOaMBAAAAUAZlK5umTp2aRx55JHfccUcmTZqUp59+Ovfcc0/OP//8XHvttbn33nszY8aMPPzww0mSs846K9/+9rczZcqUlEqlTJw4sVzRAAAAACiTspVNPXr0yLnnnpsuXbqkc+fO2WGHHTJr1qxsv/322W677VJbW5v6+vpMnjw5r7zySpYtW5Zdd901SXLooYdm8uTJ5YoGAAAAQJmUrWz67Gc/21wezZo1K/fee29qamrSo0eP5tv07Nkzc+fOzbx589a4vEePHpk7d265ogEAAABQJrXlfoDnnnsuJ554Ys4555zU1tbmxRdfXOP6mpqalEql992vpqZmox5nxowZrcoJwKZtfXNit912a8Mk1W369OmVjvCBNTQ0NJ+2598DqAz/nmjfM6BI1mEV62ANWqOsZdP06dNz+umn5/zzz8+wYcPy+OOPZ8GCBc3Xz5s3Lz179kyvXr3WuHz+/Pnp2bPnRj1W3759U1dXV1h2gPauoaHBG+d3MSdapj0Xb6v//9bV1bXr3wPaijmxpo4+J6ZPn27bGeuwmnWwBknr5kTZDqObM2dOTjnllFx55ZUZNmxYkmSXXXbJiy++mNmzZ6epqSn33HNPBg0alG222SZ1dXXNreGkSZMyaNCgckUDAAAAoEzKtmfTDTfckIaGhkyYMKH5slGjRmXChAk57bTT0tDQkMGDB2f//fdPklx55ZUZP358Fi9enJ133jmjR48uVzQAAAAAyqRsZdP48eMzfvz4tV531113ve+yPn365LbbbitXHAAAAADaQNkOowMAAACg41E2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhSl72bRo0aIMHz48L7/8cpLkvPPOy9ChQzNixIiMGDEi999/f5Jk6tSpqa+vz9ChQ3PVVVeVOxYAAAAAZVBbzh/+5JNPZvz48Zk1a1bzZTNmzMivfvWr9OzZs/myZcuW5fzzz88vf/nLfOITn8iJJ56Yhx9+OIMHDy5nPAAAAAAKVtY9myZOnJgLLriguVhasmRJXn311Xz7299OfX19rr766qxcuTJPPfVUtt9++2y33Xapra1NfX19Jk+eXM5oAAAAAJRBWfdsuuyyy9Y4//rrr6d///65+OKL061bt5x44om57bbb0q1bt/To0aP5dj179szcuXM36rFmzJhRSGYANk3rmxO77bZbGyapbtOnT690hA+soaGh+bQ9/x5AZfj3RPueAUWyDqtYB2vQGmUtm95ru+22yzXXXNN8/phjjsmkSZOy//77v++2NTU1G/Wz+/btm7q6ulZnBNhUNDQ0eOP8LuZEy7Tn4m31/9+6urp2/XtAWzEn1tTR58T06dNtO2MdVrMO1iBp3Zxo02+j+8c//pEpU6Y0ny+VSqmtrU2vXr2yYMGC5svnzZu3xmc6AQAAANA+tGnZVCqV8t3vfjdvvfVWGhsbc+utt2bIkCHZZZdd8uKLL2b27NlpamrKPffck0GDBrVlNAAAAAAK0KaH0fXp0ycnnHBCjjjiiKxYsSJDhw7N8OHDkyQTJkzIaaedloaGhgwePHith9YBAAAAUN3apGx68MEHm//7qKOOylFHHfW+2wwYMCB33XVXW8QBAAAAoEza9DC6jmratGkZO3Zspk2bVukoAAAAAGXVpofRdVQ33XRTnnvuuSxZsiT9+/evdBwAAACAsrFnUxtYsmTJGqcAAAAAmyplEwAAAACFWe9hdMuXL89VV12VKVOmZMGCBencuXO233771NfX57jjjktNTU1b5QQKMm3atEycODGHH364wzppd8wlAACofustmyZMmJCtttoq119/fSZNmpQddtghO+ywQ6677rq88cYbGTt2bFvlBAriM8Roz8wlAACofus9jO6JJ57IySefnB133DFnnnlmbr311vTr1y8/+tGPcv/997dVRqBAPkOM9sxcAgCA6rfesmnJkiVZtGhRkuTNN99c4x+nDlWAD2Zl47KKPn63bt3WOK2USq8D7ZO5BAAA1W+9h9Htv//+OeaYY7LPPvvkwQcfzPDhw/Pqq6/m1FNPzdChQ9sqI2xSNuvcNf+44NMVe/x9O3dLPrJl9u38PxXNsdNFsyr22LRf5hIAAFS/9ZZNY8aMyac+9an8/e9/z7HHHpsRI0bkrbfeyplnnpk999yzrTICBfr8x5bk8x9zCB3tk7kEAADVb72H0SXJQQcdlP333z+dO3fO/fffn9dee80begAqxlyC8po2bVrGjh2badOmVToKANBOrXfPpmeffTZnnHFGunfvnueffz577LFHXnrppXTu3DnXXHNNtt1227bKCQDmErQB31oKALTWevdsuvzyy3Pttdfmtttuy80335xtt9029957b0466aR85zvfaauMAJDEXIK24FtLAYDWWm/Z9Oabb+Yzn/lMkqRfv37585//nCQ54IADMn/+/PKnA4B3MZcAAKD6rbds6tSpUx577LEkydSpU7PFFlskSWbMmJHa2vUegQcAhTOXAACg+q33nfnZZ5+d0047LVtssUWWLFmSa6+9Ns8++2xOPvnk/OAHP2irjACQxFwCAID2YL1lU//+/fPggw9m1qxZ+fSnP53u3bunVCrlf/7nf5pvc88992T48OFlDwoA5hIAAFS/9R5GlyTdu3dP375907179yRJTU3NGtffcMMN5UkGAGthLgEAQHXbYNm0IaVSqYgcAFAIcwkAACqr1WXTe/+iDACVZC4BAEBltbpsAgAAAIDVlE0AAAAAFMZnNgGwSTGXAACgsja6bFq0aFFeffXV5vP19fWFBgKAjWEuAQBAdWlR2XT//ffnkksuyaJFi3LQQQdlxIgRufnmm5Mkxx9/fFkDAsB7mUsAAFC9WlQ2XXfddTn88MNz3333Zdddd80f/vCH3HXXXeXOBgBrZS4BAED1alHZVCqVstNOO2Xq1KkZNGhQunfv7jMxAKgYcwkAAKpXi8qmzTbbLPfee28eeeSR7Lnnnnn44YfLnQsA1slcAgCA6tWisumcc87JxIkTM3bs2PTo0SM//elPM378+HJnA4C1MpcAAKB61bbkRrvvvntuuummJKu+9ecHP/hBPvnJT5YzFwCsk7kEAADVq9XfRgcAbc1cAgCA6uXb6ABod8wlAACoXr6NDoB2x1wCAIDqtVHfRvfHP/7Rt/4AUHHmEgAAVK+N+ja6M88807f+AFBx5hIAAFSvjfo2uldeeSWzZ8/Of//3f5c7FwCsk7kEAADVq0Vl06xZs3LKKadk3rx5WblyZT760Y/muuuuyw477FDufADwPuYSAABUrxYdRnfJJZfk61//ev70pz9l+vTp+eY3v5mLLrqo3NkAYK3MJQAAqF4tKptef/31HHLIIc3nR44cmTfeeKNsoQBgfcwlAACoXi0qm5qamvLmm282n1+4cGG58gDABplLAABQvVr0mU1HH310vva1r+WAAw5Ikvzud7/LscceW9ZgALAu5hIAAFSvFpVNhx56aLbffvv88Y9/zMqVK3PBBRdk4MCB5c4GAGtlLgEAQPVqUdn01a9+NZMmTUr//v3LnQcANshcAgCA6tWiz2zq2rVrXnvttXJnAYAWMZcAAKB6tWjPpqVLl2afffbJ1ltvnW7dujVffvfdd5ctGACsi7kEAADVq0Vl07hx48qdAwBazFyqTisbGrJZXV3FHn918fjuArISKr0OAACV1qKy6VOf+lR+9rOf5cILL8wLL7yQK6+8MhdddFG5swHAWplL1Wmzuro8PHhwxR5/t5qaLK+pyW7PPlvRHIMffrhijw0AUA1a9JlN5557bj7zmc8kSbbZZpt86Utfyvnnn1/WYACwLuYSa9O7VMqxK1emd6lU6SgAAB1ai8qmN954I6NHj06S1NXV5bjjjsv8+fPLGgwA1sVcAgCA6tWisqmpqSlz585tPr9gwYKU/NUQgAoxlwAAoHq16DObjjvuuBx88MH58pe/nJqamkydOjVnn332Bu+3aNGijBo1Kj/72c+y7bbbZurUqbn88svT0NCQAw44IGPGjEmSPPPMMxk/fnwWLVqU3XffPRdddFFqa1sUDYAO6IPOJQAAoPxatGfTYYcdlhtvvDE777xz+vbtmxtuuCH19fVJklmzZq31Pk8++WSOOOKI5uuXLVuW888/P9dee23uvffezJgxIw///x+gedZZZ+Xb3/52pkyZklKplIkTJ7b+NwNgk/VB5hIAANA2WlQ2JUmfPn1y3HHH5Zhjjknv3r2bL1+9d9J7TZw4MRdccEF69uyZJHnqqaey/fbbZ7vttkttbW3q6+szefLkvPLKK1m2bFl23XXXJMmhhx6ayZMnt+JXAqAj2Ni5BAAAtI1WH6u2rs/IuOyyy9Y4P2/evPTo0aP5fM+ePTN37tz3Xd6jR481PoejpWbMmLHR92krDQ0NzafTp0+vcBoqbbfddqt0hKrh9UA5rGsurW9OeF3+n9a8Lq3j/2nP2zfvW+ioqvnfE23Fa34V67CKdbAGrdHqsqmmpqZFt1vbm/+ampp1Xr6x+vbtm7q6uo2+X1tYnauurs4bcXgXr4fyamho6JBvnNc1Q6p5TlQTr8titOd19L6l4+ioc2JdOvqcmD59utd8rMNq1sEaJK2bEy0+jK61evXqlQULFjSfnzdvXnr27Pm+y+fPn9986B0AAAAA7UublU277LJLXnzxxcyePTtNTU255557MmjQoGyzzTapq6tr3j1t0qRJGTRoUFvFAgAAAKBArT6MrqXq6uoyYcKEnHbaaWloaMjgwYOz//77J0muvPLKjB8/PosXL87OO++c0aNHt1UsAAAAAArU6rLp05/+9Hqvf/DBB5v/e8CAAbnrrrved5s+ffrktttua20UANjgXAIAAMqrRWXTwoULc9ddd2Xx4sUplUpZuXJlZs+ene9///u56qqryp0RANZgLgEAQPVqUdl0xhlnpGvXrvl//+//ZeDAgZk6dWqH/1R2ACrHXAIAgOrVog8If/XVV3P99ddn0KBBOfroo/Ob3/wmL730UrmzAcBamUsAAFC9WlQ2bbXVVklWfQ7GzJkz06tXr6xYsaKswYq0rLGyWbt167bGaaVUeh0AitLe5xIAAGzKWnQY3cc//vH813/9V3bdddf8+Mc/Tvfu3bNo0aJyZytM18612XrMTRV7/O6N22arzd/O7xu3rWiO1646rmKPDVCk9j6XAABgU9aiPZsuvvjidOnSJbvvvnv69u2bq6++OmeddVa5s20yFn1428zaYWgWfXjbSkcB2CSYSwAAUL1aVDZNmTIlo0ePTpKcddZZmTRpUl544YWyBgOAdTGXAACgeq33MLrf/OY3WbZsWW666aY0NDQ0X97Y2Jhf/vKXOeGEE8oeEABWM5cAAKD6rbdsqq2tzcyZMzN37tzMnDmz+fJOnTpl1KhRZQ8HAO9mLgEAQPVbb9k0ZMiQ7Lvvvnn66adzzjnnNF/e2NiYo446KqecckrZAwLAauYSAABUv/WWTWeeeWamTp2aJBkwYEDz5Z06dcqQIUPKmwwA3sNcAgCA6rfesumGG25Ikpx33nm5/PLL2yQQAKyLuQQAANWvRd9G5w091WDatGkZO3Zspk2bVukoQIWZSwAAUL3Wu2cTVJObbropzz33XJYsWZL+/ftXOg4AAACwFi3aswmqwZIlS9Y4BQAAAKqPsokWW9nQUNHH79at2xqnlVLpdQAAAIBq5jA6Wmyzuro8PHhwxR5/t5qaLK+pyW7PPlvRHIMffrhijw0AAADVTtlEu9G7VErvUqnSMQAAAID1cBgdAAAAAIVRNgEAAABQGGUTAAAAAIVRNgEAAABQGGUTAAAAAIVRNgEAAABQGGUTAAAAAIVRNgEAVJGVjcsq+vjdunVb47RSKr0OAMAHV1vpAAAA/J/NOnfNPy74dMUef9/O3ZKPbJl9O/9PRXPsdNGsij02ANA6yiYAAJp9/mNL8vmPLal0DACgHXMYHQAAAACFUTYBAAAAUBhlEwAAAACFUTYBAAAAUBhlEwAAAACFUTYBAAAAUBhlEwAAAACFUTYBAAAAUBhlEwAAAACFUTYBAAAAUBhlEwAAAACFUTYBAAAAUBhlEwAAAACFUTYBAAAAUBhlEwAAm5xS0/JKR6gK1gGASqitdAAAAChaTacumTPluErHqLhP7HdTpSMA0AHZswkAAACAwiibAAAAACiMsgkAAACAwiibAAAAACiMsgkAAACAwiibAAAAAChMbSUedPTo0Xn99ddTW7vq4S+++OK89NJL+elPf5rGxsYcd9xxOeqooyoRDQAAAIBWaPOyqVQq5YUXXshDDz3UXDbNnTs3Y8aMye23354uXbpk1KhR2WOPPbLjjju2dTwAAAAAWqHNy6YXXnghNTU1+cY3vpHXX389hx9+eDbffPP0798/W265ZZJkv/32y+TJk3Pqqae2dTwAAAAAWqHNy6a33347AwYMyIUXXphly5Zl9OjROeCAA9KjR4/m2/Ts2TNPPfXURv3cGTNmrPO63Xbb7QPn3dRMnz79A9/XOv4f61iM1qwjbCxzomVs34phHYthHYth3rbM+uZER+G5sop1WMU6WIPWaPOy6Qtf+EK+8IUvJEm6deuWww47LJdffnlOOumkNW5XU1OzUT+3b9++qaurKyznpsobr2JYx2JYx/JqaGjwxvldzImW8boshnUshnUsxrrW0ZxYU0efE9OnT/eai3VYzTpYg6R1c6LNv43uz3/+cx599NHm86VSKdtss00WLFjQfNm8efPSs2fPto4GAAAAQCu1edn0zjvv5IorrkhDQ0MWLVqUO+64I9/73vfy6KOPZuHChVm6dGnuu+++DBo0qK2jAQAAANBKbX4Y3d57750nn3wyBx98cFauXJkjjzwyu+22W8aMGZPRo0ensbExhx12WPr169fW0QAAAABopTYvm5LkjDPOyBlnnLHGZfX19amvr69EHAAAAAAK0uaH0QEAAACw6VI2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFCYqiqb7r777hx44IEZMmRIbrnllkrHAQAAAGAj1VY6wGpz587NVVddldtvvz1dunTJqFGjsscee2THHXesdDQAAAAAWqhqyqapU6emf//+2XLLLZMk++23XyZPnpxTTz11vfcrlUpJkuXLl6/3dj0371xIzvasoaGh1T+j5qMfLSBJ+1bEOq78UI8CkrRvRawj67d6u7h6O9lRmRMtZ04Uw5woRhHruGKzLQpI0r6tbx3NiVVaOic6Au/PVrEOq1gHa9CaOVFTqpLpct1112XJkiUZM2ZMkuS3v/1tnnrqqVxyySXrvd8777yTmTNntkVEgHapd+/e2WKLjvsPLnMCYP3MCXMCYH0+yJyomj2b1tZ51dTUbPB+m2++eXr37p3OnTu36PYAHUWpVEpjY2M233zzSkepKHMCYO3MiVXMCYC1a82cqJqyqVevXvnzn//cfH7evHnp2bPnBu+32Wabdei/xACsT9euXSsdoeLMCYB1MyfMCYD1+aBzomq+jW7gwIF59NFHs3DhwixdujT33XdfBg0aVOlYAAAAAGyEqtqzacyYMRk9enQaGxtz2GGHpV+/fpWOBQAAAMBGqJoPCAcAAACg/auaw+gAAAAAaP+UTQAAAAAURtkEAAAAQGGUTQAAAAAURtkEAAAAQGGUTWWyaNGiDB8+PC+//HKS5Iknnsjhhx+eYcOGZezYsVm+fHmFE7YPP/rRj3LggQdm2LBhufHGG5Mkt956a4YPH576+vqcd9551nIDHnzwwRx66KHZf//9c+mll65x3S233JJjjjmmQsnah/e+ltf1/Hv66aczcuTIHHTQQTnxxBPz9ttvVzI27YA50XpmRDHMidYxJ9qXu+++OwceeGCGDBmSW2655X3XP/PMMxk5cmT222+/jBs3LitWrKhAyvLa0Br8/ve/z4gRI3LQQQfl5JNPzltvvVWBlOW3oXVY7aGHHspXvvKVNkzWtja0Di+88EKOOeaYHHTQQTn++OM3yefDhtagI22/3zvT3m2jt48lCvfXv/61NHz48NLnPve50j//+c/SO++8U9pzzz1LzzzzTKlUKpXGjBlTuuWWWyqcsvo99thjpVGjRpUaGxtLS5cuLe29996l559/vjRkyJDSO++8U1q5cmXp7LPPLt14442Vjlq1XnrppdJee+1VmjNnTmn58uWlI444ovTQQw+VSqVS6bnnnit9+ctfLh199NEVTlm93vtafuGFF9b5/Hv32l5++eWlH/zgBxVMTrUzJ1rPjCiGOdE65kT78tprr5X23nvv0htvvFFavHhxqb6+vvTcc8+tcZthw4aVnnjiiVKpVCqdd955m9y2eENrsHoevfbaa6VSqVT64Q9/WLrkkksqFbdsWvJcKJVKpfnz55f233//0t57712BlOW3oXVYuXJlaejQoaWHH364VCqVSt/73vdKV1xxRaXilkVLngsdZfv93pn2Xhu7fbRnUxlMnDgxF1xwQXr27Jkk+d///d/suuuu6dOnT5Jk/PjxGTJkSCUjtgtf+tKX8otf/CK1tbV5/fXX09TUlLq6ulx44YXp3r17ampq0rt377z66quVjlq17r///hx44IHZeuut07lz51x11VXZZZddsnz58nznO9/Jt771rUpHrGrvfS136dJlnc+/lStXZvHixUmSpUuXpmvXrhXLTfUzJ1rPjCiGOdE65kT7MnXq1PTv3z9bbrllunXrlv322y+TJ09uvv6VV17JsmXLsuuuuyZJDj300DWu3xRsaA0aGxtz4YUXplevXkmSnXbaKXPmzKlU3LLZ0DqsNn78+Jx66qkVSNg2NrQOTz/9dLp165ZBgwYlSU466aQcddRRlYpbFi15LnSU7fd7Z9q7fZDto7KpDC677LLsvvvuzednz56dbt265ZRTTkl9fX1+/OMf58Mf/nAFE7YfnTt3ztVXX51hw4ZlwIAB+eQnP5mBAwcmSRYuXJhbbrkl++yzT4VTVq/Zs2enqakpxx9/fA466KD8+te/zkc+8pF8//vfz8iRI7PttttWOmJVe+9reZtttlnn8+/cc8/NuHHjstdee2Xq1KkZNWpURTLTPpgTxTAjWs+caB1zon2ZN29eevTo0Xy+Z8+emTt37jqv79GjxxrXbwo2tAYf/ehHs++++yZJli1bluuvv775/KZkQ+uQJL/4xS+y8847Z5dddmnreG1mQ+vw0ksvZauttso555yT+vr6XHDBBenWrVslopZNS54LHWX7/d6Z9m4fZPuobGoDTU1NeeSRR3Luuedm0qRJWbp0aa6//vpKx2o3Tj/99Dz66KOZM2dOJk6cmCSZO3dujj322IwcOTJ77LFHhRNWr6ampjz66KP53ve+l4kTJ+Zvf/tbfvvb32bOnDkZOXJkpeO1W+99/i1btizjxo3LzTffnEceeSRHHnlkzjnnnErHpB0xJz44M6J1zInyMCeqU6lUet9lNTU1Lb5+U9DS3/Gdd97JN77xjfTp0yeHHHJIW0RrUxtah5kzZ+a+++7LySef3Jax2tyG1mHFihV5/PHHc/TRR+fuu+/OdtttlwkTJrRlxLLb0BrYfq/yQbaPyqY2sNVWW2WXXXbJdtttl06dOuWAAw7IU089VelYVe/555/PM888kyT50Ic+lKFDh+Yf//hHnn/++RxxxBE55JBDcsopp1Q4ZXXbaqutMmDAgHzsYx9L165ds88+++SJJ57Ic889lxEjRmT8+PGZMWNGzjjjjEpHbTfW9vybOXNm6urq0q9fvyTJ1772tTz++OOVjEk7Y05sPDOiGOZE8cyJ6tWrV68sWLCg+fy8efPWOFzkvdfPnz9/rYeTtGcbWoPVlx155JHp06dPLrvssraO2CY2tA6TJ0/O/PnzM3LkyJxwwgnNa7Kp2dA69OjRI9tvv30+//nPJ0mGDx++yb0/2dAa2H6v8kG2j8qmNrDXXnvl6aefbj7e+Q9/+EM+97nPVThV9Xv55Zczfvz4LF++PMuXL88DDzyQfv365fjjj8+3vvWt/Pu//3ulI1a9vffeO4888kjefvvtNDU15Y9//GO++MUv5ne/+13uvPPOXHrppenbt29++MMfVjpqu7Bo0aK1Pv+23377vPbaa3nhhReSJA888EDzUIaWMCc2nhlRDHOiWOZEdRs4cGAeffTRLFy4MEuXLs19993X/Fk0yarDIOvq6jJ9+vQkyaRJk9a4flOwoTVoamrKSSedlAMOOCDjxo3b5PbsWm1D63D66adnypQpufPOO3P99denZ8+e+fWvf13BxOWxoXX4whe+kIULF+bZZ59NsurbSze19ycbWgPb71U+yPaxti2CdXSf+MQncvHFF+ekk05KQ0ND/uVf/qVD7nq3sQYPHpwnn3wyBx98cDp16pShQ4fmzTffzIIFC/Lzn/88P//5z5MkX/nKV3yA6Trssssu+frXv54jjzwyjY2N2XPPPR0W0Qq33XbbOp9/l19+ec4444yUSqV8/OMfz3e/+90Kp6U9MSc2nhlRDHOiWOZEdevVq1fGjBmT0aNHp7GxMYcddlj69euXb3zjGzn99NPz+c9/PldeeWXGjx+fxYsXZ+edd87o0aMrHbtQG1qD1157LX//+9/T1NSUKVOmJEn69u27ye3h1JLnQkfQknW45pprMn78+CxdujRbb711rrjiikrHLlRL1qAjb79bs32sKa3t4DsAAAAA+AAcRgcAAABAYZRNAAAAABRG2QQAAABAYZRNAAAAABRG2QQAAABAYZRNbPIee+yxDB8+fKPu85Of/CS///3v13ubc889NzfccENrojV74IEHcumllxbyswDYOOYEAECxaisdAKrRY489lh133LHNHm+fffbJPvvs02aPB0DrmBMAAOumbKJDWLJkSU4//fTMnj07H/7wh3PxxRcnSS6++OIsWbIk8+bNS58+ffLDH/4wt912W2bMmJErrrginTp1ysCBA3PppZfmL3/5Szp16pR99903Y8aMSZI88cQTGTVqVBYsWJDPfvaz+f73v59u3bqtM8f8+fNzzjnn5I033kiSDB48OGeccUZuv/32TJkyJddee20OPfTQ5tu/9dZbef311/PYY4+lqakpl112WWbOnJnGxsYMGDAgZ599dmprvYwBWsucAAAojsPo6BDmzJmT4447LnfeeWeGDx+es88+OxMnTszBBx+cW2+9Nffdd19efvnlPPTQQznqqKPSt2/fnH322RkyZEiuvvrqNDQ05N57782kSZPyl7/8JY8//niSZO7cubnxxhszZcqUzJ07N/fdd996c0ycODHbbrtt7rjjjtxyyy2ZPXt23nnnnebrO3XqlDvvvDN33nlnbr755my++eaZMGFCunXrlu9+97v53Oc+l9tvvz2TJk3KG2+8kRtvvLGs6wbQUZgTAADF8acuOoSddtopX/ziF5MkhxxySC688ML8/Oc/z1//+tf853/+Z2bNmpV58+ZlyZIl77vv1KlTc95556VTp07p1KlTfvWrXyVJ7rjjjuy777750Ic+lCT57Gc/m4ULF643x5e//OWccMIJmTNnTgYOHJgzzzwzW2yxxftut2zZspx00kkZMWJEhg0bliR56KGH8re//S233XZb820AKIY5AQBQHGUTHcJmm625E19NTU3GjRuXUqmUAw44IP/2b/+WOXPmpFQqve++tbW1qampaT4/Z86cdO3atfm6d//Mtd3/3fr165cHHnggjz76aKZNm5avfvWrueaaa9a4TVNTU8aOHZvevXvnhBNOaL585cqV+dGPfpQddtghSfL222+vkQuAD86cAAAojsPo6BD+8Y9/5JlnnkmS3Hrrrdltt90yderUnHLKKTnwwANTU1OTJ598Mk1NTUlWHaawYsWKJMmAAQNyxx13ZOXKlVm+fHlOP/30/OlPf/pAOa688spce+212XfffTNu3LjsuOOOmTVr1hq3ueiii7JixYp85zvfWePyvfbaKzfddFNKpVKWL1+eb37zm81/PQegdcwJAIDi2LOJDuEzn/lMfvKTn+Sf//xnPv7xj2fChAl56KGHcsopp+QjH/lIPvShD+Vf//Vf89JLLyVJ9t577/zHf/xHGhsbc+qpp+ayyy7LiBEj0tTUlAMPPDBDhw7Ngw8+uNE5jj322Jx77rkZPnx4unTpkp122inDhw/PPffck2TVB8neeuut2WmnnXLYYYc1/wX80ksvzbhx43LZZZelvr4+jY2NGThwYL7+9a8Xt0gAHZg5AQBQnJrShvbnBgAAAIAWsmcTFOzII4/M4sWL13rdLbfcku7du7dxIgCqiTkBAGzq7NkEAAAAQGF8QDgAAAAAhVE2AQAAAFAYZRMAAAAAhVE2AQAAAFAYZRMAAAAAhfn/AMq9+61ZXavtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "\n",
    "\n",
    "sns.barplot(x='batch_size', \n",
    "            y='tta_cross_99', \n",
    "            data=d ,\n",
    "            ax=ax[0],\n",
    "            estimator=np.min)\n",
    "\n",
    "sns.barplot(x='batch_size', y='tta_cross_99', data=df, ax=ax[1], estimator=np.min)\n",
    "# sns.barplot(x='parallelism', y='time', data=df, ax=ax[2], hue='k')\n",
    "\n",
    "# plt.savefig('./figures/resnet34/time.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "f, ax = plt.subplots(1, 3, figsize=(20,8), sharey=True)\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==32], capsize=.05, hue='parallelism', ax=ax[0])\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==64], capsize=.05, hue='parallelism', ax=ax[1])\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==128], capsize=.05, hue='parallelism', ax=ax[2])\n",
    "\n",
    "plt.savefig('./figures/resnet34/time_per_all.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_k_and_batch(k: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.k==k) & (df.batch_size==batch)].sort_values(by='parallelism', ascending=False)\n",
    "\n",
    "    plt.rc('font', size=13)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, k={k}')\n",
    "        ax.legend(title='parallelism')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=32, ax=axes[0][2])\n",
    "    \n",
    "plot_loss_with_k_and_batch(k=8, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/accuracy_study.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep K and Batch set, vary parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_k_and_batch(k: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.k==k) & (df.batch_size==batch)].sort_values(by='parallelism', ascending=False)\n",
    "\n",
    "    plt.rc('font', size=13)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, k={k}')\n",
    "        ax.legend(title='parallelism')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=32, ax=axes[0][2])\n",
    "    \n",
    "plot_loss_with_k_and_batch(k=8, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/accuracy_study.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep Parallelism and batch set, vary K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_parallelism_and_batch(p: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.parallelism==p) & (df.batch_size==batch)].sort_values(by='k', ascending=False)\n",
    "    \n",
    "    approx_k = (60000/p)/batch\n",
    "\n",
    "    plt.rc('font', size=16)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.k))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "            label = str(row.k) if row.k != float('inf') else f'{row.k} ({int(approx_k)})'\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=label)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, Parallelism={p}')\n",
    "        ax.legend(title='k')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(30, 20), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=32, ax=axes[0][2])\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "plt.savefig('./figures/accuracy_study_varying_k.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot 3d dependencies between K and parallelism on time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 2, projection='3d')\n",
    "\n",
    "f = plt.figure()\n",
    "ax = f.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "X, Y = np.meshgrid(df.k.map(lambda v: 500 if v == float('inf') else v), df.parallelism)\n",
    "Z = griddata((df.k.map(lambda v: 500 if v == float('inf') else v),\n",
    "              df.parallelism),\n",
    "              df.acc, (X, Y), method='cubic')\n",
    "\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='coolwarm',\n",
    "                       linewidth=0, antialiased=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = df.loc[df.batch==64]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
