{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gather insights from the experiments run on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.utils import check_missing_experiments, join_df\n",
    "from common.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the TTA Formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate time to accuracy for different accuracies\n",
    "def tta_crossbow(acc:int, df: pd.DataFrame, acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \"\"\"Computes the tta as in the crossbow paper\n",
    "    where the tta is the median of the last 5 epochs\"\"\"\n",
    "\n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done = False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "            \n",
    "            # if there are less than 5 elements behind, continue\n",
    "            if idx < 4:\n",
    "                continue\n",
    "                \n",
    "            # calculate the median of the next five elements\n",
    "            if np.median(accuracy[idx - 4:idx+1]) >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def tta(acc:int, df:pd.DataFrame,  acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \n",
    "    \n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done=False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "         \n",
    "            if a >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KubeML Experiments\n",
    "\n",
    "How to treat the kubeml experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join_df('./results/resnet/train')\n",
    "df = df[df.default_parallelism > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get duplicated rows\n",
    "df[df.duplicated(['hash'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the extra variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.epoch_duration.map(lambda t: t[-1])\n",
    "\n",
    "# Set the parallelism to the first since it is constant\n",
    "df.parallelism = df.parallelism.map(lambda l:l[0])\n",
    "\n",
    "# change -1 to inf so the order is right in the plot\n",
    "df.k = df.k.map(lambda val: float('inf') if val == -1 else val)\n",
    "\n",
    "df['global_batch'] = df.batch_size * df.parallelism\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ttas\n",
    "df['tta_69'] = tta(69, df)\n",
    "df['tta_cross_69'] = tta_crossbow(69, df)\n",
    "\n",
    "# compute the ttas\n",
    "df['tta_67'] = tta(67, df)\n",
    "df['tta_cross_67'] = tta_crossbow(67, df)\n",
    "\n",
    "# compute the ttas\n",
    "df['tta_70'] = tta(70, df)\n",
    "df['tta_cross_70'] = tta_crossbow(70, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the metrics in resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = join_df('./results/resnet/metrics')\n",
    "m = metrics.rename(columns={'exp_name':'id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the metrics in the lenet\n",
    "\n",
    "The first replication does not have the proper format, so we need to reformat it and combine it with the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1 = join_df('./results/lenet/metrics/1/')\n",
    "metrics2 = join_df('./results/lenet/metrics/2/')\n",
    "metrics3 = join_df('./results/lenet/metrics/3/')\n",
    "\n",
    "cpu = metrics1.groupby('exp_name')['cpu'].apply(list)\n",
    "mem = metrics1.groupby('exp_name')['mem'].apply(list)\n",
    "exps = metrics1.groupby('exp_name')['exp_name']\n",
    "\n",
    "metrics1 = pd.DataFrame({\n",
    "    'cpu':cpu,\n",
    "    'mem':mem\n",
    "})\n",
    "metrics1['exp_name'] = metrics1.index\n",
    "\n",
    "# concat all metrics and rename the exp_name as in the train\n",
    "m = pd.concat([metrics1, metrics2, metrics3], ignore_index=True)\n",
    "m.rename(columns={'exp_name':'id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add extra summary columns to the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine and Save the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.merge(m, on='id')\n",
    "d.to_pickle('./dataframes/resnet_kubeml.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Experiments\n",
    "\n",
    "How to treat the TF experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'resnet_new'\n",
    "df = join_df(f'./results/tf/{folder}/train/1/', f'./results/tf/{folder}/train/2', f'./results/tf/{folder}/train/3')\n",
    "\n",
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.val_accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.times.map(lambda t: t[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TTA\n",
    "df['tta_67'] = tta(0.67, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_67'] = tta_crossbow(0.67, df, time_column='times', acc_column='val_accuracy')\n",
    "\n",
    "df['tta_69'] = tta(0.69, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_69'] = tta_crossbow(0.69, df, time_column='times', acc_column='val_accuracy')\n",
    "\n",
    "df['tta_70'] = tta(0.70, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_70'] = tta_crossbow(0.70, df, time_column='times', acc_column='val_accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the metrics from different  folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = join_df(f'./results/tf/{folder}/metrics/1/', f'./results/tf/{folder}/metrics/2', f'./results/tf/{folder}/metrics/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./dataframes/resnet_new_tensorflow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_red_palette = ['#264653', '#2A9D8F', '#E9C46A', '#F4A261', '#E76F51']\n",
    "blue_yellow_palette=  ['#0077b6', '#d62828', '#f77f00', '#fcbf49', '#eae2b7']\n",
    "cool_p = ['#f87575', '#ffa9a3', '#b9e6ff', '#5c95ff', '#7e6c6c']\n",
    "wall_p = ['#e63946', '#f1faee', '#a8dadc', '#457b9d', '#1d3557']\n",
    "\n",
    "sns.palplot(sns.color_palette(blue_yellow_palette))\n",
    "\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette=blue_yellow_palette, )\n",
    "sns.set_context('talk')\n",
    "# sns.set_palette(blue_yellow_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read the experiments file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the tf experiments\n",
    "resnet = pd.read_pickle('./dataframes/resnet_new_tensorflow.pkl')\n",
    "lenet = pd.read_pickle('./dataframes/lenet_tensorflow.pkl')\n",
    "\n",
    "lenet.rename(columns={\n",
    "    'loss':'train_loss',\n",
    "    'val_accuracy':'accuracy',\n",
    "    'val_loss':'validation_loss',\n",
    "    'times':'epoch_duration',\n",
    "    'accuracy':'train_accuracy',\n",
    "    'val_accuracy':'accuracy'\n",
    "}, inplace=True)\n",
    "lenet['system'] = 'tensorflow'\n",
    "lenet['acc'] = 100*lenet['acc']\n",
    "lenet['accuracy'] = lenet['accuracy'].map(lambda l: [100*n for n in l])\n",
    "\n",
    "# rename columns in the TF dataframes to adhere to the kubeml ones\n",
    "resnet.rename(columns={\n",
    "    'loss':'train_loss',\n",
    "    'val_accuracy':'accuracy',\n",
    "    'val_loss':'validation_loss',\n",
    "    'times':'epoch_duration',\n",
    "    'accuracy':'train_accuracy',\n",
    "    'val_accuracy':'accuracy'\n",
    "}, inplace=True)\n",
    "resnet['system'] = 'tensorflow'\n",
    "resnet['acc'] = 100*resnet['acc']\n",
    "resnet['accuracy'] = resnet['accuracy'].map(lambda l: [100*n for n in l])\n",
    "\n",
    "\n",
    "# set the columns of the \n",
    "\n",
    "# load the kubeml experiments\n",
    "kuberesnet = pd.read_pickle('./dataframes/resnet_kubeml.pkl')\n",
    "kuberesnet['model'] = 'resnet'\n",
    "kuberesnet['system'] = 'kubeml'\n",
    "# kuberesnet['tta_70'] = tta(70, kuberesnet)\n",
    "# kuberesnet['tta_cross_70'] = tta_crossbow(70, kuberesnet)\n",
    "\n",
    "kubelenet = pd.read_pickle('./dataframes/lenet_kubeml.pkl')\n",
    "kubelenet['model'] = 'lenet'\n",
    "kubelenet['system'] = 'kubeml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the full resnet stuff\n",
    "r.to_pickle('./dataframes/resnet_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.concat([resnet, kuberesnet], ignore_index=True)\n",
    "r\n",
    "# resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create new columns for representation\n",
    "\n",
    "- Final accuracy\n",
    "- Total time taken\n",
    "- Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot the Correlations between the K, Batch and Parallelism with time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df[['k', 'batch_size', 'parallelism', 'acc', 'time']].corr()\n",
    "sns.heatmap(corr,\n",
    "            annot=True,\n",
    ")\n",
    "\n",
    "# plt.savefig('./figures/resnet34/heat.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('time')\n",
    "\n",
    "mean = df.groupby('hash').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the max accuracies and times and check the parameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the max accuracies\n",
    "df[['k', 'parallelism', 'acc','batch_size','time']].sort_values(by='time', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calculate TTA with different accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s = df.sort_values('tta_cross_99')[['k', 'batch_size', 'parallelism', 'tta_cross_99', 'tta_99', 'acc', 'accuracy', 'epoch_duration']]\n",
    "\n",
    "# plot the best\n",
    "best = s.iloc[0]\n",
    "best\n",
    "\n",
    "\n",
    "x = range(1, len(best.accuracy)+1)\n",
    "plt.figure()\n",
    "plt.title(f'Best tta_99 (B={best.batch_size}, k={best.k}, P={best.parallelism})')\n",
    "sns.lineplot(x=best.epoch_duration, y = best.accuracy)\n",
    "sns.lineplot(x=best.epoch_duration, y= 99)\n",
    "plt.scatter(best.tta_cross_99, 99, marker='X', s=60, c='r')\n",
    "plt.xlabel('Time (s)', fontsize=15)\n",
    "plt.ylabel('Accuracy (%)', fontsize=15)\n",
    "\n",
    "# plt.savefig('./figures/gpu/best.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the resnet results KubeML vs Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the colors used\n",
    "tf_color = '#FF6F00'\n",
    "kubecolor = '#316CE6'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.read_pickle('./dataframes/lenet.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Accuracy and Train Loss Progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=False, figsize=(20, 6))\n",
    "\n",
    "# get the best results\n",
    "tf = l[l.system=='tensorflow']\n",
    "ml = l[l.system =='kubeml']\n",
    "sample = tf.iloc[5]\n",
    "kubesample = ml.iloc[87]\n",
    "\n",
    "# sort for tta69 and show\n",
    "\n",
    "# 1) plot the validation accuracy of TF\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.accuracy[:30],\n",
    "             data=sample, \n",
    "            ax=ax1, \n",
    "            label='TensorFlow',\n",
    "            color='#FF6F00')\n",
    "\n",
    "# 2) plot the validation accuracy of KubeML\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='accuracy',\n",
    "             data=kubesample, \n",
    "            ax=ax1, \n",
    "            label='KubeML',\n",
    "            color='#316CE6')\n",
    "\n",
    "ax1.set_ylim([97, 100])\n",
    "ax1.set_xlabel('Time (sec)')\n",
    "\n",
    "\n",
    "\n",
    "# plot the line at 69%\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "            y=99,\n",
    "            ax=ax1,\n",
    "            color='red')\n",
    "\n",
    "# 3) Plot the train loss\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.train_loss[:30],\n",
    "             data=sample, \n",
    "            ax=ax2, \n",
    "            label='TensorFlow',\n",
    "            color='#FF6F00')\n",
    "\n",
    "# 3) Plot the train loss\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='train_loss',\n",
    "             data=kubesample, \n",
    "            ax=ax2, \n",
    "            label='KubeML',\n",
    "            color='#316CE6')\n",
    "\n",
    "ax2.set_xlabel('Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the whole comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the results with k=-1 and \n",
    "_l = l[((l.parallelism==4) | (l.parallelism.isna())) & ((l.k==float('inf')) | (l.k.isna())) ]\n",
    "\n",
    "# set the palette\n",
    "sns.set_palette([tf_color, kubecolor], desat=0.8)\n",
    "\n",
    "\n",
    "# COMPARE THE LOSSES, THE VAL LOSS OF KUBEML SHOULD BE HIGHER (DO NOT KNOW THE TRAIN LOSS, BECAUSE OF EXPLORATION,\n",
    "# WHILE STILL GIVING BEST ACCURACY (BETTER GENERALIZATION))\n",
    "f, ax = plt.subplots(3, 2, sharex=True, figsize=(20, 17))\n",
    "\n",
    "# 1) Plot the comparison of tta between both\n",
    "sns.barplot(x='batch_size', \n",
    "            y='tta_99', \n",
    "            data=_l, \n",
    "            hue='system',\n",
    "            capsize=.05,\n",
    "            ax=ax[0][0])\n",
    "ax[0][0].set_xlabel('Batch Size')\n",
    "ax[0][0].set_ylabel('TTA(99%) (sec)')\n",
    "\n",
    "\n",
    "# 2) Plot the max accuracy\n",
    "sns.barplot(x='batch_size', \n",
    "            y='acc', \n",
    "            data=_l, \n",
    "            hue='system', \n",
    "            capsize=.05,\n",
    "            ax=ax[0][1])\n",
    "ax[0][1].set_ylim([97, 100])\n",
    "ax[0][1].set_xlabel('Batch Size')\n",
    "ax[0][1].set_ylabel('Accuracy after 30 epochs (%)')\n",
    "\n",
    "\n",
    "# 3) Plot the difference in GPU utilzation\n",
    "sns.barplot(x='batch_size', \n",
    "            y='time', \n",
    "            data=_l, \n",
    "            hue='system', \n",
    "            capsize=.05,\n",
    "            ax=ax[1][0])\n",
    "ax[1][0].set_xlabel('Batch Size')\n",
    "ax[1][0].set_ylabel('Time (sec)')\n",
    "\n",
    "\n",
    "# 4) Plot the val loss of both compared\n",
    "# calculate the loss\n",
    "_l['loss'] = _l['validation_loss'].map(lambda l:l[-1])\n",
    "sns.barplot(x='batch_size', \n",
    "            y='loss', \n",
    "            data=_l ,\n",
    "            capsize=.05,\n",
    "            hue='system',\n",
    "            ax=ax[1][1])\n",
    "\n",
    "ax[1][1].set_xlabel('Batch Size')\n",
    "ax[1][1].set_ylabel('Validation Loss')\n",
    "\n",
    "plt.suptitle('Performance TF vs KubeML on LeNet')\n",
    "\n",
    "\n",
    "## Plot the difference in cpu and gpu utilization\n",
    "# CPU util\n",
    "sns.barplot(x='batch_size', \n",
    "            y='cpu_mean', \n",
    "            data=_l ,\n",
    "            capsize=.05,\n",
    "            hue='system',\n",
    "            ax=ax[2][0])\n",
    "\n",
    "ax[2][0].set_xlabel('Batch Size')\n",
    "ax[2][0].set_ylabel('CPU Utilization (%)')\n",
    "\n",
    "# GPu Util\n",
    "sns.barplot(x='batch_size', \n",
    "            y='gpu_usage', \n",
    "            data=_l ,\n",
    "            capsize=.05,\n",
    "            hue='system',\n",
    "            ax=ax[2][1])\n",
    "\n",
    "ax[2][1].set_xlabel('Batch Size')\n",
    "ax[2][1].set_ylabel('GPU Utilization')\n",
    "\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "# plt.savefig('./figures/ppt/lenet-performance.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of accuracy and time between K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, sharex=True, figsize=(20, 10))\n",
    "\n",
    "\n",
    "\n",
    "_kubelenet = l[(l.system == 'kubeml')]\n",
    "# 1) plot the accuracy reached with different k\n",
    "sns.barplot(x='batch_size',\n",
    "           y='time',\n",
    "           data=_kubelenet, \n",
    "           hue='parallelism',\n",
    "           ax=ax[0])\n",
    "ax[0].set_xlabel('Batch Size')\n",
    "ax[0].set_ylabel('Time (sec)')\n",
    "\n",
    "\n",
    "_kubelenet = l[(l.system == 'kubeml') & (l.parallelism==4)]\n",
    "# 2) plot the time reached with different k\n",
    "sns.barplot(x='batch_size',\n",
    "           y='time',\n",
    "           data=_kubelenet, \n",
    "           hue='k',\n",
    "           ax=ax[1])\n",
    "ax[1].set_xlabel('Batch Size')\n",
    "ax[1].set_ylabel('Time (sec)')\n",
    "\n",
    "plt.suptitle('Evolution of Time with Parallelism and K')\n",
    "\n",
    "plt.savefig('./figures/ppt/lenet-time.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Train Loss and Val Accuracy of Tensorflow and KubeML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the palette\n",
    "sns.set_palette([tf_color, kubecolor], desat=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.read_pickle('./dataframes/resnet_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[(r.batch_size==32) & (r.system=='kubeml') & (r.k == float('inf')) & (r.parallelism ==4)].iloc[0].epoch_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=False, figsize=(20, 6))\n",
    "\n",
    "# get the best results\n",
    "tf = r[r.system=='tensorflow']\n",
    "ml = r[r.system =='kubeml']\n",
    "sample = r.iloc[2]\n",
    "kubesample = r.iloc[61]\n",
    "\n",
    "# sort for tta69 and show\n",
    "\n",
    "# 1) plot the validation accuracy of TF\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.accuracy[:30],\n",
    "             data=sample, \n",
    "            ax=ax1, \n",
    "            label='TensorFlow',\n",
    "            color='#FF6F00')\n",
    "\n",
    "# 2) plot the validation accuracy of KubeML\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='accuracy',\n",
    "             data=kubesample, \n",
    "            ax=ax1, \n",
    "            label='Kubeml',\n",
    "            color='#316CE6')\n",
    "\n",
    "ax1.set_ylim([40, 73])\n",
    "\n",
    "\n",
    "\n",
    "# plot the line at 69%\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "            y=69,\n",
    "            ax=ax1,\n",
    "            color='red')\n",
    "\n",
    "# 3) Plot the train loss\n",
    "sns.lineplot(x=sample.epoch_duration[:30],\n",
    "             y=sample.train_loss[:30],\n",
    "             data=sample, \n",
    "            ax=ax2, \n",
    "            label='TensorFlow',\n",
    "            color='#FF6F00')\n",
    "\n",
    "# 3) Plot the train loss\n",
    "sns.lineplot(x=kubesample.epoch_duration,\n",
    "             y='train_loss',\n",
    "             data=kubesample, \n",
    "            ax=ax2, \n",
    "            label='KubeML',\n",
    "            color='#316CE6')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the metrics of both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get only the results with k=-1 and \n",
    "_r = r[((r.parallelism==4) | (r.parallelism.isna())) & ((r.k==float('inf')) | (r.k.isna())) ]\n",
    "_r['t30'] = _r['time']\n",
    "\n",
    "\n",
    "# COMPARE THE LOSSES, THE VAL LOSS OF KUBEML SHOULD BE HIGHER (DO NOT KNOW THE TRAIN LOSS, BECAUSE OF EXPLORATION,\n",
    "# WHILE STILL GIVING BEST ACCURACY (BETTER GENERALIZATION))\n",
    "f, ax = plt.subplots(3, 2, sharex=True, figsize=(20, 17))\n",
    "\n",
    "# 1) Plot the comparison of tta between both\n",
    "sns.barplot(x='batch_size', \n",
    "            y='tta_70', \n",
    "            data=_r, \n",
    "            hue='system', \n",
    "            ax=ax[0][0],\n",
    "           capsize=.05)\n",
    "ax[0][0].set_xlabel('Batch Size')\n",
    "ax[0][0].set_ylabel('TTA (70%) (sec)')\n",
    "\n",
    "\n",
    "# 2) Plot the max accuracy\n",
    "sns.barplot(x='batch_size', \n",
    "            y='acc', \n",
    "            data=_r, \n",
    "            hue='system', \n",
    "            ax=ax[0][1],\n",
    "            capsize=.05)\n",
    "ax[0][1].set_ylim([40, 100])\n",
    "ax[0][1].set_xlabel('Batch Size')\n",
    "ax[0][1].set_ylabel('Accuracy after 30 epochs (%)')\n",
    "\n",
    "\n",
    "# 3) Plot the difference in GPU utilzation\n",
    "_r['t_loss'] = _r['train_loss'].map(lambda l:l[-1])\n",
    "sns.barplot(x='batch_size', \n",
    "            y='t_loss', \n",
    "            data=_r, \n",
    "            hue='system', \n",
    "            ax=ax[1][0],\n",
    "            capsize=.05,\n",
    "               )\n",
    "ax[1][0].set_xlabel('Batch Size')\n",
    "ax[1][0].set_ylabel('Train Loss')\n",
    "\n",
    "\n",
    "# 4) Plot the val loss of both compared\n",
    "# calculate the loss\n",
    "_r['loss'] = _r['validation_loss'].map(lambda l:l[-1])\n",
    "sns.barplot(x='batch_size', \n",
    "            y='loss', \n",
    "            data=_r ,\n",
    "            hue='system',\n",
    "            ax=ax[1][1],\n",
    "            capsize=.05)\n",
    "\n",
    "ax[1][1].set_xlabel('Batch Size')\n",
    "ax[1][1].set_ylabel('Validation Loss')\n",
    "\n",
    "\n",
    "## Plot the difference in cpu and gpu utilization\n",
    "# CPU util\n",
    "sns.barplot(x='batch_size', \n",
    "            y='cpu_mean', \n",
    "            data=_r ,\n",
    "            capsize=.05,\n",
    "            hue='system',\n",
    "            ax=ax[2][0])\n",
    "\n",
    "ax[2][0].set_xlabel('Batch Size')\n",
    "ax[2][0].set_ylabel('CPU Utilization (%)')\n",
    "\n",
    "# GPu Util\n",
    "sns.barplot(x='batch_size', \n",
    "            y='gpu_usage', \n",
    "            data=_r ,\n",
    "            capsize=.05,\n",
    "            hue='system',\n",
    "            ax=ax[2][1])\n",
    "\n",
    "ax[2][1].set_xlabel('Batch Size')\n",
    "ax[2][1].set_ylabel('GPU Utilization')\n",
    "\n",
    "\n",
    "sns.despine()\n",
    "plt.suptitle('Performance TF vs KubeML on Resnet34')\n",
    "\n",
    "# plt.savefig('./figures/ppt/resnet-performance.png', dpi=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Time with Parallelism and K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, sharex=True, figsize=(20, 10))\n",
    "\n",
    "sns.set_palette('muted',10)\n",
    "\n",
    "_kuberesnet = r[(r.system == 'kubeml')]\n",
    "# 1) plot the accuracy reached with different k\n",
    "sns.barplot(x='batch_size',\n",
    "           y='time',\n",
    "           data=_kuberesnet, \n",
    "           hue='parallelism',\n",
    "           ax=ax[0])\n",
    "ax[0].set_xlabel('Batch Size')\n",
    "ax[0].set_ylabel('Time (sec)')\n",
    "\n",
    "\n",
    "_kuberesnet = r[(r.system == 'kubeml') & (r.parallelism==4)]\n",
    "# 2) plot the time reached with different k\n",
    "sns.barplot(x='batch_size',\n",
    "           y='time',\n",
    "           data=_kuberesnet, \n",
    "           hue='k',\n",
    "           ax=ax[1])\n",
    "ax[1].set_xlabel('Batch Size')\n",
    "ax[1].set_ylabel('Time (sec)')\n",
    "\n",
    "plt.suptitle('Evolution of Time with Parallelism and K (Resnet34)')\n",
    "\n",
    "plt.savefig('./figures/ppt/resnet-time.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = _r.loc[(_r.batch_size==32) & (_r.system=='kubeml')]\n",
    "for a, t in zip(g.iloc[0].accuracy, g.iloc[0].epoch_duration):\n",
    "    print(t, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do ANOVA Linear Model to calculate the influence of the parameters\n",
    "\n",
    "Using ANOVA we can get an idea of how the different parameters interact with each other and their influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ANOVA test\n",
    "import researchpy as rp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA(df: pd.DataFrame, y: str, use_all = False,verbose=False):\n",
    "    \"\"\"Run the ANOVA analysis with the batch, k and parallelism columns for the \n",
    "    given output variable\"\"\"\n",
    "    \n",
    "    # If use all is true we use all the variables to check either accuracy and time\n",
    "    # including also the iowait and the cpu to see what fully influences the stuff\n",
    "    \n",
    "    \n",
    "    if not use_all:\n",
    "        # Plot the summary dataframe\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ batch_size*k*parallelism', df).fit()\n",
    "        \n",
    "    else:\n",
    "        if y not in ['acc', 'time']:\n",
    "            raise ValueError('When use_all = True we predict either final_accuracy or time, not', y)\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ cpu*batch*njobs*cpu_mean*iowait_mean', df).fit()\n",
    "        \n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "        display(model.summary())\n",
    "    \n",
    "    res = sm.stats.anova_lm(model, typ=2)\n",
    "    \n",
    "    return res, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.k = df.k.map(lambda val: -1 if val == float('inf') else val)\n",
    "\n",
    "res, model = ANOVA(d, y='gpu_usage', verbose=True)\n",
    "\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the distributions of time and accuracy as a function of K, Batch and parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the accuracy as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "sns.barplot(x='batch_size', y='acc', hue='k', data=df, ax=ax[0], capsize=.05)\n",
    "sns.barplot(x='k', y='acc', data=df, ax=ax[1], capsize=.05, hue='parallelism')\n",
    "sns.barplot(x='parallelism', y='acc', data=df, hue='k' ,ax=ax[2] ,capsize=.05)\n",
    "sns.despine()\n",
    "plt.legend(title='k', ncol=4, bbox_to_anchor=(0.075,1))\n",
    "\n",
    "for a in ax:\n",
    "    a.set_ylim([75, 100])\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/resnet34/accuracy.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='parallelism', y='tta_cross_99', data=df, capsize=.02, hue='batch_size')\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/resnet34/acc_per_k_and_parallelism.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_pickle('./dataframes/lenet_tensorflow.pkl')\n",
    "d = pd.read_pickle('./dataframes/lenet_kubeml.pkl')\n",
    "d = d.loc[d.parallelism==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sort_values('tta_cross_99')[['batch_size', 'tta_cross_99']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the time as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "\n",
    "\n",
    "sns.barplot(x='batch_size', \n",
    "            y='tta_cross_99', \n",
    "            data=d ,\n",
    "            ax=ax[0],\n",
    "            estimator=np.min)\n",
    "\n",
    "sns.barplot(x='batch_size', y='tta_cross_99', data=df, ax=ax[1], estimator=np.min)\n",
    "# sns.barplot(x='parallelism', y='time', data=df, ax=ax[2], hue='k')\n",
    "\n",
    "# plt.savefig('./figures/resnet34/time.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "f, ax = plt.subplots(1, 3, figsize=(20,8), sharey=True)\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==32], capsize=.05, hue='parallelism', ax=ax[0])\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==64], capsize=.05, hue='parallelism', ax=ax[1])\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==128], capsize=.05, hue='parallelism', ax=ax[2])\n",
    "\n",
    "plt.savefig('./figures/resnet34/time_per_all.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_k_and_batch(k: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.k==k) & (df.batch_size==batch)].sort_values(by='parallelism', ascending=False)\n",
    "\n",
    "    plt.rc('font', size=13)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, k={k}')\n",
    "        ax.legend(title='parallelism')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=32, ax=axes[0][2])\n",
    "    \n",
    "plot_loss_with_k_and_batch(k=8, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/accuracy_study.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep K and Batch set, vary parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_k_and_batch(k: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.k==k) & (df.batch_size==batch)].sort_values(by='parallelism', ascending=False)\n",
    "\n",
    "    plt.rc('font', size=13)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, k={k}')\n",
    "        ax.legend(title='parallelism')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=32, ax=axes[0][2])\n",
    "    \n",
    "plot_loss_with_k_and_batch(k=8, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/accuracy_study.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep Parallelism and batch set, vary K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_parallelism_and_batch(p: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.parallelism==p) & (df.batch_size==batch)].sort_values(by='k', ascending=False)\n",
    "    \n",
    "    approx_k = (60000/p)/batch\n",
    "\n",
    "    plt.rc('font', size=16)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.k))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "            label = str(row.k) if row.k != float('inf') else f'{row.k} ({int(approx_k)})'\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=label)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, Parallelism={p}')\n",
    "        ax.legend(title='k')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(30, 20), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=32, ax=axes[0][2])\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "plt.savefig('./figures/accuracy_study_varying_k.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot 3d dependencies between K and parallelism on time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 2, projection='3d')\n",
    "\n",
    "f = plt.figure()\n",
    "ax = f.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "X, Y = np.meshgrid(df.k.map(lambda v: 500 if v == float('inf') else v), df.parallelism)\n",
    "Z = griddata((df.k.map(lambda v: 500 if v == float('inf') else v),\n",
    "              df.parallelism),\n",
    "              df.acc, (X, Y), method='cubic')\n",
    "\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='coolwarm',\n",
    "                       linewidth=0, antialiased=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = df.loc[df.batch==64]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
