{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gather insights from the experiments run on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.utils import check_missing_experiments, join_df\n",
    "from common.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the TTA Formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate time to accuracy for different accuracies\n",
    "def tta_crossbow(acc:int, df: pd.DataFrame, acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \"\"\"Computes the tta as in the crossbow paper\n",
    "    where the tta is the median of the last 5 epochs\"\"\"\n",
    "\n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done = False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "            \n",
    "            # if there are less than 5 elements behind, continue\n",
    "            if idx < 4:\n",
    "                continue\n",
    "                \n",
    "            # calculate the median of the next five elements\n",
    "            if np.median(accuracy[idx - 4:idx+1]) >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def tta(acc:int, df:pd.DataFrame,  acc_column='accuracy', time_column='epoch_duration'):\n",
    "    \n",
    "    \n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        done=False\n",
    "        dur, accuracy = row[time_column], row[acc_column]\n",
    "        \n",
    "        for idx, (t, a) in enumerate(zip(dur, accuracy[:len(dur)])):\n",
    "         \n",
    "            if a >= acc:\n",
    "                res.append(t)\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            res.append(np.nan)\n",
    "\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KubeML Experiments\n",
    "\n",
    "How to treat the kubeml experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join_df('./results/lenet/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get duplicated rows\n",
    "df[df.duplicated(['hash'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the extra variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.epoch_duration.map(lambda t: t[-1])\n",
    "\n",
    "# Set the parallelism to the first since it is constant\n",
    "df.parallelism = df.parallelism.map(lambda l:l[0])\n",
    "\n",
    "# change -1 to inf so the order is right in the plot\n",
    "df.k = df.k.map(lambda val: float('inf') if val == -1 else val)\n",
    "\n",
    "df['global_batch'] = df.batch_size * df.parallelism\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ttas\n",
    "df['tta_99'] = tta(99, df)\n",
    "df['tta_cross_99'] = tta_crossbow(99, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the metrics in the lenet\n",
    "\n",
    "The first replication does not have the proper format, so we need to reformat it and combine it with the train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1 = join_df('./results/lenet/metrics/1/')\n",
    "metrics2 = join_df('./results/lenet/metrics/2/')\n",
    "metrics3 = join_df('./results/lenet/metrics/3/')\n",
    "\n",
    "cpu = metrics1.groupby('exp_name')['cpu'].apply(list)\n",
    "mem = metrics1.groupby('exp_name')['mem'].apply(list)\n",
    "exps = metrics1.groupby('exp_name')['exp_name']\n",
    "\n",
    "metrics1 = pd.DataFrame({\n",
    "    'cpu':cpu,\n",
    "    'mem':mem\n",
    "})\n",
    "metrics1['exp_name'] = metrics1.index\n",
    "\n",
    "# concat all metrics and rename the exp_name as in the train\n",
    "m = pd.concat([metrics1, metrics2, metrics3], ignore_index=True)\n",
    "m.rename(columns={'exp_name':'id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add extra summary columns to the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine and Save the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.merge(m, on='id')\n",
    "d.to_pickle('./dataframes/lenet_kubeml.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Experiments\n",
    "\n",
    "How to treat the TF experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join_df('./results/tf/lenet/train/1/', './results/tf/lenet/train/2', './results/tf/lenet/train/3')\n",
    "\n",
    "# Set the acc to the final accuracy\n",
    "df['acc'] = df.val_accuracy.map(lambda a: a[-1])\n",
    "\n",
    "# Set the time to the sum of the epoch durations\n",
    "df['time'] = df.times.map(lambda t: t[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TTA\n",
    "df['tta_69'] = tta(0.69, df, time_column='times', acc_column='val_accuracy')\n",
    "df['tta_cross_69'] = tta_crossbow(0.69, df, time_column='times', acc_column='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the metrics from different  folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = join_df('./results/tf/lenet/metrics/1/', './results/tf/lenet/metrics/2', './results/tf/lenet/metrics/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute the mean of each and add columns\n",
    "m['mem'] = m['mem'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "m['cpu'] = m['cpu'].map(lambda l: l[0] if isinstance(l[0], list) else l)\n",
    "\n",
    "# cpu util\n",
    "m['cpu_mean'] = m['cpu'].map(lambda l: np.mean([s.percent for s in l]))\n",
    "\n",
    "# gpu mean mem and util\n",
    "m['gpu_0_mean_usage'] = m['gpu_0'].map(lambda l: np.mean([s.load for s in l if s.mem_used != 0]) if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_usage'] = m['gpu_1'].map(lambda l: np.mean([s.load for s in l if s.mem_used !=0]) if not isinstance(l, float) else l)\n",
    "m['gpu_0_mean_memory'] = m['gpu_0'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_1_mean_memory'] = m['gpu_1'].map(lambda l: np.mean([s.mem_used for s in l if s.mem_used != 0])if not isinstance(l, float) else l)\n",
    "m['gpu_usage'] = (m['gpu_0_mean_usage'] + m['gpu_1_mean_usage']) /2\n",
    "\n",
    "# memory mean util\n",
    "m['mem_mean'] = m['mem'].map(lambda l: np.mean([s.percent for s in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./dataframes/lenet_kubeml.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASgAAABICAYAAABFhGj3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB20lEQVR4nO3YMWoVURiG4f9IJCDEi5BcuwSxtLWzsXUFKbODFFmKpVuwyj7SiI3BSrAMIWBjIRz7oJCBnJwvw/OUw3D5/uaFua33XgCJnsweAPA/AgXEEigglkABsQQKiCVQQKydJS+3Z5tem+2oLdO9ufk5e8JQuy9+z54wTNt7PnvCUH92X86eMNSXr9+veu8Ht58vClRttlUnH+9tVJrP52ezJwz16vjb7AnDPH3/bvaEoa5fn86eMNT28MOPfz33iQfEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiCVQQCyBAmIJFBBLoIBYAgXEEigglkABsQQKiNV673d/ubVfVXU5bs50+1V1NXvEIGu+rcp9j91R7/3g9sOdhT9y2Xt/e0+D4rTWLtZ635pvq3LfWvnEA2IJFBBraaA+DVmRY833rfm2Kvet0qI/yQEekk88IJZAAbEECoglUEAsgQJi/QVCLj0ovT6UxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "green_red_palette = ['#264653', '#2A9D8F', '#E9C46A', '#F4A261', '#E76F51']\n",
    "blue_yellow_palette=  ['#0077b6', '#d62828', '#f77f00', '#fcbf49', '#eae2b7']\n",
    "cool_p = ['#f87575', '#ffa9a3', '#b9e6ff', '#5c95ff', '#7e6c6c']\n",
    "wall_p = ['#e63946', '#f1faee', '#a8dadc', '#457b9d', '#1d3557']\n",
    "\n",
    "sns.palplot(sns.color_palette(blue_yellow_palette))\n",
    "\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette=blue_yellow_palette, )\n",
    "# sns.set_palette(blue_yellow_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Read the experiments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hash</th>\n",
       "      <th>model_type</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>dataset</th>\n",
       "      <th>lr</th>\n",
       "      <th>function_name</th>\n",
       "      <th>default_parallelism</th>\n",
       "      <th>static_parallelism</th>\n",
       "      <th>...</th>\n",
       "      <th>mem</th>\n",
       "      <th>gpu_0</th>\n",
       "      <th>gpu_1</th>\n",
       "      <th>cpu_mean</th>\n",
       "      <th>gpu_0_mean_usage</th>\n",
       "      <th>gpu_1_mean_usage</th>\n",
       "      <th>gpu_0_mean_memory</th>\n",
       "      <th>gpu_1_mean_memory</th>\n",
       "      <th>gpu_usage</th>\n",
       "      <th>mem_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01da4199</td>\n",
       "      <td>11bd6f57e69e3e22</td>\n",
       "      <td>example</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=199405....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>3.123596</td>\n",
       "      <td>0.042941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2057.858824</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.021471</td>\n",
       "      <td>5.598876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02bf7ea4</td>\n",
       "      <td>e64b768614e0c4b2</td>\n",
       "      <td>example</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=200200....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.409091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.554545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02c2c3e4</td>\n",
       "      <td>ca950a6673f71c02</td>\n",
       "      <td>example</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=199864....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.924390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.716463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04ae4d90</td>\n",
       "      <td>c072e7d8b6f4fc7e</td>\n",
       "      <td>example</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=200921....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>7.242424</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.112917</td>\n",
       "      <td>5068.458333</td>\n",
       "      <td>4104.083333</td>\n",
       "      <td>0.127292</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06c0714b</td>\n",
       "      <td>9f3c17b028508b1d</td>\n",
       "      <td>example</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=193349....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.877778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.997661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>fc4d208e</td>\n",
       "      <td>e4b3277b60ea90de</td>\n",
       "      <td>example</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=178444....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>13.064151</td>\n",
       "      <td>0.495283</td>\n",
       "      <td>0.414906</td>\n",
       "      <td>5058.113208</td>\n",
       "      <td>4079.000000</td>\n",
       "      <td>0.455094</td>\n",
       "      <td>12.320755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>fcb9d493</td>\n",
       "      <td>a77733fe0915a9ca</td>\n",
       "      <td>example</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=180601....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>7.747826</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.126087</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>5164.608696</td>\n",
       "      <td>0.106304</td>\n",
       "      <td>11.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>fda9af79</td>\n",
       "      <td>e64b768614e0c4b2</td>\n",
       "      <td>example</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=179894....</td>\n",
       "      <td>[GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>[GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.195769</td>\n",
       "      <td>0.212692</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>5160.730769</td>\n",
       "      <td>0.204231</td>\n",
       "      <td>11.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>fdf430ea</td>\n",
       "      <td>a31f2f9fde57be67</td>\n",
       "      <td>example</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=199727....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.154545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.769697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>fdfb44d5</td>\n",
       "      <td>1cea5dc3e30453c9</td>\n",
       "      <td>example</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lenet</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[MemoryStats(total=270332.669952, free=200333....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.419048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.168254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id              hash model_type  batch_size  epochs dataset    lr  \\\n",
       "0    01da4199  11bd6f57e69e3e22    example         128      30   mnist  0.01   \n",
       "1    02bf7ea4  e64b768614e0c4b2    example          64      30   mnist  0.01   \n",
       "2    02c2c3e4  ca950a6673f71c02    example          32      30   mnist  0.01   \n",
       "3    04ae4d90  c072e7d8b6f4fc7e    example         128      30   mnist  0.01   \n",
       "4    06c0714b  9f3c17b028508b1d    example          16      30   mnist  0.01   \n",
       "..        ...               ...        ...         ...     ...     ...   ...   \n",
       "188  fc4d208e  e4b3277b60ea90de    example          16      30   mnist  0.01   \n",
       "189  fcb9d493  a77733fe0915a9ca    example         128      30   mnist  0.01   \n",
       "190  fda9af79  e64b768614e0c4b2    example          64      30   mnist  0.01   \n",
       "191  fdf430ea  a31f2f9fde57be67    example          32      30   mnist  0.01   \n",
       "192  fdfb44d5  1cea5dc3e30453c9    example          64      30   mnist  0.01   \n",
       "\n",
       "    function_name  default_parallelism  static_parallelism  ...  \\\n",
       "0           lenet                    1                True  ...   \n",
       "1           lenet                    8                True  ...   \n",
       "2           lenet                    1                True  ...   \n",
       "3           lenet                    8                True  ...   \n",
       "4           lenet                    2                True  ...   \n",
       "..            ...                  ...                 ...  ...   \n",
       "188         lenet                    8                True  ...   \n",
       "189         lenet                    8                True  ...   \n",
       "190         lenet                    8                True  ...   \n",
       "191         lenet                    8                True  ...   \n",
       "192         lenet                    2                True  ...   \n",
       "\n",
       "                                                   mem  \\\n",
       "0    [MemoryStats(total=270332.669952, free=199405....   \n",
       "1    [MemoryStats(total=270332.669952, free=200200....   \n",
       "2    [MemoryStats(total=270332.669952, free=199864....   \n",
       "3    [MemoryStats(total=270332.669952, free=200921....   \n",
       "4    [MemoryStats(total=270332.669952, free=193349....   \n",
       "..                                                 ...   \n",
       "188  [MemoryStats(total=270332.669952, free=178444....   \n",
       "189  [MemoryStats(total=270332.669952, free=180601....   \n",
       "190  [MemoryStats(total=270332.669952, free=179894....   \n",
       "191  [MemoryStats(total=270332.669952, free=199727....   \n",
       "192  [MemoryStats(total=270332.669952, free=200333....   \n",
       "\n",
       "                                                 gpu_0  \\\n",
       "0    [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "188  [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "189  [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "190  [GpuStats(id=0, name='GeForce RTX 2080 Ti', lo...   \n",
       "191                                                NaN   \n",
       "192                                                NaN   \n",
       "\n",
       "                                                 gpu_1   cpu_mean  \\\n",
       "0    [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...   3.123596   \n",
       "1                                                  NaN   8.409091   \n",
       "2                                                  NaN   3.924390   \n",
       "3    [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...   7.242424   \n",
       "4                                                  NaN   5.877778   \n",
       "..                                                 ...        ...   \n",
       "188  [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...  13.064151   \n",
       "189  [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...   7.747826   \n",
       "190  [GpuStats(id=1, name='GeForce RTX 2080 Ti', lo...   9.100000   \n",
       "191                                                NaN   9.154545   \n",
       "192                                                NaN   4.419048   \n",
       "\n",
       "    gpu_0_mean_usage gpu_1_mean_usage  gpu_0_mean_memory gpu_1_mean_memory  \\\n",
       "0           0.042941         0.000000        2057.858824          3.000000   \n",
       "1                NaN              NaN                NaN               NaN   \n",
       "2                NaN              NaN                NaN               NaN   \n",
       "3           0.141667         0.112917        5068.458333       4104.083333   \n",
       "4                NaN              NaN                NaN               NaN   \n",
       "..               ...              ...                ...               ...   \n",
       "188         0.495283         0.414906        5058.113208       4079.000000   \n",
       "189         0.086522         0.126087        4167.000000       5164.608696   \n",
       "190         0.195769         0.212692        4167.000000       5160.730769   \n",
       "191              NaN              NaN                NaN               NaN   \n",
       "192              NaN              NaN                NaN               NaN   \n",
       "\n",
       "     gpu_usage   mem_mean  \n",
       "0     0.021471   5.598876  \n",
       "1          NaN   9.554545  \n",
       "2          NaN   5.716463  \n",
       "3     0.127292   9.500000  \n",
       "4          NaN   6.997661  \n",
       "..         ...        ...  \n",
       "188   0.455094  12.320755  \n",
       "189   0.106304  11.760870  \n",
       "190   0.204231  11.950000  \n",
       "191        NaN   9.769697  \n",
       "192        NaN   6.168254  \n",
       "\n",
       "[193 rows x 34 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_file = './dataframes/lenet_kubeml.pkl'\n",
    "df = pd.read_pickle(experiment_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create new columns for representation\n",
    "\n",
    "- Final accuracy\n",
    "- Total time taken\n",
    "- Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot the Correlations between the K, Batch and Parallelism with time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df[['k', 'batch_size', 'parallelism', 'acc', 'time']].corr()\n",
    "sns.heatmap(corr,\n",
    "            annot=True,\n",
    ")\n",
    "\n",
    "# plt.savefig('./figures/resnet34/heat.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('time')\n",
    "\n",
    "mean = df.groupby('hash').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the max accuracies and times and check the parameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the max accuracies\n",
    "df[['k', 'parallelism', 'acc','batch_size','time']].sort_values(by='time', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calculate TTA with different accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s = df.sort_values('tta_cross_99')[['k', 'batch_size', 'parallelism', 'tta_cross_99', 'tta_99', 'acc', 'accuracy', 'epoch_duration']]\n",
    "\n",
    "# plot the best\n",
    "best = s.iloc[0]\n",
    "best\n",
    "\n",
    "\n",
    "x = range(1, len(best.accuracy)+1)\n",
    "plt.figure()\n",
    "plt.title(f'Best tta_99 (B={best.batch_size}, k={best.k}, P={best.parallelism})')\n",
    "sns.lineplot(x=best.epoch_duration, y = best.accuracy)\n",
    "sns.lineplot(x=best.epoch_duration, y= 99)\n",
    "plt.scatter(best.tta_cross_99, 99, marker='X', s=60, c='r')\n",
    "plt.xlabel('Time (s)', fontsize=15)\n",
    "plt.ylabel('Accuracy (%)', fontsize=15)\n",
    "\n",
    "# plt.savefig('./figures/gpu/best.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.tta_cross_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "sns.barplot(x='parallelism', y='acc', data=mean, hue='k',  ax=ax[0])\n",
    "# sns.barplot(x='k', y='tta_cross_99', data=df, ax=ax[1])\n",
    "# sns.barplot(x='parallelism', y='tta_cross_99', data=df ,ax=ax[2])\n",
    "sns.despine()\n",
    "\n",
    "# plt.savefig('./figures/gpu/tta_99.png', dpi=300)\n",
    "\n",
    "# sns.barplot(x='k', y='tta_99', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do ANOVA Linear Model to calculate the influence of the parameters\n",
    "\n",
    "Using ANOVA we can get an idea of how the different parameters interact with each other and their influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ANOVA test\n",
    "import researchpy as rp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA(df: pd.DataFrame, y: str, use_all = False,verbose=False):\n",
    "    \"\"\"Run the ANOVA analysis with the batch, k and parallelism columns for the \n",
    "    given output variable\"\"\"\n",
    "    \n",
    "    # If use all is true we use all the variables to check either accuracy and time\n",
    "    # including also the iowait and the cpu to see what fully influences the stuff\n",
    "    \n",
    "    \n",
    "    if not use_all:\n",
    "        # Plot the summary dataframe\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ batch_size*k*parallelism', df).fit()\n",
    "        \n",
    "    else:\n",
    "        if y not in ['acc', 'time']:\n",
    "            raise ValueError('When use_all = True we predict either final_accuracy or time, not', y)\n",
    "        if verbose:\n",
    "            display(rp.summary_cont(df.groupby(['batch_size', 'k', 'parallelism']))[y])\n",
    "\n",
    "        model = ols(f'{y} ~ cpu*batch*njobs*cpu_mean*iowait_mean', df).fit()\n",
    "        \n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "        display(model.summary())\n",
    "    \n",
    "    res = sm.stats.anova_lm(model, typ=2)\n",
    "    \n",
    "    return res, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.k = df.k.map(lambda val: -1 if val == float('inf') else val)\n",
    "\n",
    "res, model = ANOVA(d, y='gpu_usage', verbose=True)\n",
    "\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the distributions of time and accuracy as a function of K, Batch and parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the accuracy as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "sns.barplot(x='batch_size', y='acc', hue='k', data=df, ax=ax[0], capsize=.05)\n",
    "sns.barplot(x='k', y='acc', data=df, ax=ax[1], capsize=.05, hue='parallelism')\n",
    "sns.barplot(x='parallelism', y='acc', data=df, hue='k' ,ax=ax[2] ,capsize=.05)\n",
    "sns.despine()\n",
    "plt.legend(title='k', ncol=4, bbox_to_anchor=(0.075,1))\n",
    "\n",
    "for a in ax:\n",
    "    a.set_ylim([75, 100])\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/resnet34/accuracy.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='parallelism', y='tta_cross_99', data=df, capsize=.02, hue='batch_size')\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/resnet34/acc_per_k_and_parallelism.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_pickle('./dataframes/lenet_tensorflow.pkl')\n",
    "d = pd.read_pickle('./dataframes/lenet_kubeml.pkl')\n",
    "d = d.loc[d.parallelism==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>tta_cross_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>32</td>\n",
       "      <td>82.370374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>83.256948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>32</td>\n",
       "      <td>84.316683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>16</td>\n",
       "      <td>92.441923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>16</td>\n",
       "      <td>101.195969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16</td>\n",
       "      <td>125.816565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>64</td>\n",
       "      <td>138.775395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64</td>\n",
       "      <td>140.742009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>64</td>\n",
       "      <td>140.943138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>142.674177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>64</td>\n",
       "      <td>143.598086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>16</td>\n",
       "      <td>144.182310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>64</td>\n",
       "      <td>145.785317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>16</td>\n",
       "      <td>148.940941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>32</td>\n",
       "      <td>159.049880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>32</td>\n",
       "      <td>161.446891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>32</td>\n",
       "      <td>162.843089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>16</td>\n",
       "      <td>272.334462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>306.976264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>364.546680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>16</td>\n",
       "      <td>370.926736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>376.359481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size  tta_cross_99\n",
       "128          32     82.370374\n",
       "23           32     83.256948\n",
       "160          32     84.316683\n",
       "162          16     92.441923\n",
       "79           16    101.195969\n",
       "43           16    125.816565\n",
       "154          64    138.775395\n",
       "45           64    140.742009\n",
       "144          64    140.943138\n",
       "8            64    142.674177\n",
       "136          64    143.598086\n",
       "118          16    144.182310\n",
       "192          64    145.785317\n",
       "112          16    148.940941\n",
       "103          32    159.049880\n",
       "169          32    161.446891\n",
       "129          32    162.843089\n",
       "73           16    272.334462\n",
       "4            16    306.976264\n",
       "42           16    364.546680\n",
       "122          16    370.926736\n",
       "6            16    376.359481\n",
       "10          128           NaN\n",
       "17           32           NaN\n",
       "50           32           NaN\n",
       "57          128           NaN\n",
       "61          128           NaN\n",
       "63          128           NaN\n",
       "64          128           NaN\n",
       "67           64           NaN\n",
       "82          128           NaN\n",
       "88           16           NaN\n",
       "90           32           NaN\n",
       "92           32           NaN\n",
       "109         128           NaN\n",
       "115         128           NaN\n",
       "127         128           NaN\n",
       "134         128           NaN\n",
       "147          32           NaN\n",
       "152          64           NaN\n",
       "158          64           NaN\n",
       "161          64           NaN\n",
       "170          32           NaN\n",
       "173         128           NaN\n",
       "175          64           NaN\n",
       "176          16           NaN\n",
       "178          64           NaN\n",
       "184         128           NaN"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sort_values('tta_cross_99')[['batch_size', 'tta_cross_99']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the time as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='batch_size', ylabel='tta_cross_99'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(20, 5))\n",
    "sns.barplot(x='batch_size', y='tta_cross_99', data=d ,ax=ax[0], estimator=np.min)\n",
    "sns.barplot(x='batch_size', y='tta_cross_99', data=df, ax=ax[1], estimator=np.min)\n",
    "# sns.barplot(x='parallelism', y='time', data=df, ax=ax[2], hue='k')\n",
    "\n",
    "# plt.savefig('./figures/resnet34/time.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=16)\n",
    "f, ax = plt.subplots(1, 3, figsize=(20,8), sharey=True)\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==32], capsize=.05, hue='parallelism', ax=ax[0])\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==64], capsize=.05, hue='parallelism', ax=ax[1])\n",
    "sns.barplot(x='k', y='time', data=df.loc[df.batch_size==128], capsize=.05, hue='parallelism', ax=ax[2])\n",
    "\n",
    "plt.savefig('./figures/resnet34/time_per_all.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_k_and_batch(k: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.k==k) & (df.batch_size==batch)].sort_values(by='parallelism', ascending=False)\n",
    "\n",
    "    plt.rc('font', size=13)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, k={k}')\n",
    "        ax.legend(title='parallelism')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=32, ax=axes[0][2])\n",
    "    \n",
    "plot_loss_with_k_and_batch(k=8, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/accuracy_study.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep K and Batch set, vary parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_k_and_batch(k: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.k==k) & (df.batch_size==batch)].sort_values(by='parallelism', ascending=False)\n",
    "\n",
    "    plt.rc('font', size=13)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.parallelism))\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, k={k}')\n",
    "        ax.legend(title='parallelism')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=32, ax=axes[0][2])\n",
    "    \n",
    "plot_loss_with_k_and_batch(k=8, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_k_and_batch(k=8, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_k_and_batch(k=16, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_k_and_batch(k=64, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "# plt.savefig('./figures/accuracy_study.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep Parallelism and batch set, vary K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation lines of k=-1 and batch = 32 with different parallelism\n",
    "def plot_loss_with_parallelism_and_batch(p: int, batch:int, ax: plt.Axes = None):\n",
    "    d = df.loc[(df.parallelism==p) & (df.batch_size==batch)].sort_values(by='k', ascending=False)\n",
    "    \n",
    "    approx_k = (60000/p)/batch\n",
    "\n",
    "    plt.rc('font', size=16)\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10, 5))\n",
    "        for _, row in d.iterrows():\n",
    "#             print(row.accuracy)\n",
    "            plt.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=str(row.k))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title(f'Accuracy evolution with LeNet (batch={batch}, k={k})')\n",
    "        plt.legend(title='parallelism', bbox_to_anchor=(1.05, 0.8))\n",
    "        \n",
    "    else:\n",
    "        for _, row in d.iterrows():\n",
    "            label = str(row.k) if row.k != float('inf') else f'{row.k} ({int(approx_k)})'\n",
    "            ax.plot(range(1,6), row.accuracy[:-1] if len(row.accuracy) == 6 else row.accuracy, label=label)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Batch={batch}, Parallelism={p}')\n",
    "        ax.legend(title='k')\n",
    "        \n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=3, figsize=(30, 20), sharex=True)\n",
    "\n",
    "plt.suptitle('Behavior of K, Parallelism and Batch in Accuracy')\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=32, ax=axes[0][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=32, ax=axes[0][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=32, ax=axes[0][2])\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=64, ax=axes[1][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=64, ax=axes[1][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=64, ax=axes[1][2])\n",
    "\n",
    "plot_loss_with_parallelism_and_batch(p=2, batch=128, ax=axes[2][0])\n",
    "plot_loss_with_parallelism_and_batch(p=4, batch=128, ax=axes[2][1])   \n",
    "plot_loss_with_parallelism_and_batch(p=8, batch=128, ax=axes[2][2])\n",
    "\n",
    "\n",
    "plt.savefig('./figures/accuracy_study_varying_k.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot 3d dependencies between K and parallelism on time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 2, projection='3d')\n",
    "\n",
    "f = plt.figure()\n",
    "ax = f.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "X, Y = np.meshgrid(df.k.map(lambda v: 500 if v == float('inf') else v), df.parallelism)\n",
    "Z = griddata((df.k.map(lambda v: 500 if v == float('inf') else v),\n",
    "              df.parallelism),\n",
    "              df.acc, (X, Y), method='cubic')\n",
    "\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='coolwarm',\n",
    "                       linewidth=0, antialiased=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = df.loc[df.batch==64]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
