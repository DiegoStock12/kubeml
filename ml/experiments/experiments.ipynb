{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing the experiment classes\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from common.experiment import KubemlExperiment, History, TrainOptions, TrainRequest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read the json\n",
    "with open('./data/5.json', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "\n",
    "print(content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read the content into a class\n",
    "\n",
    "h = History.from_json(content)\n",
    "\n",
    "exp = KubemlExperiment(\"test\", None)\n",
    "exp.history = h\n",
    "exp.network_id = h.id\n",
    "\n",
    "# exp.save('./tests/')\n",
    "\n",
    "d = exp.to_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d.train_loss[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "e = pd.read_pickle('./tests/1a5c751e.pkl')\n",
    "e"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "h.to_dict()\n",
    "\n",
    "new = {\"id\": h.id,\n",
    "       **h.task.to_dict(),\n",
    "       **h.task.options.to_dict()\n",
    "       }\n",
    "\n",
    "del new['options']\n",
    "\n",
    "new\n",
    "\n",
    "# # need to wrap the metrics in arrays\n",
    "for k, v in h.data.to_dict().items():\n",
    "    new[k] = [v]\n",
    "\n",
    "new\n",
    "#\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(new)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the experiment class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "request = TrainRequest(\n",
    "    model_type='example',\n",
    "    function_name='resnet',\n",
    "    dataset='cifar10',\n",
    "    lr=0.01,\n",
    "    batch_size=32,\n",
    "    epochs= 10,\n",
    "    options= TrainOptions(\n",
    "        default_parallelism=5,\n",
    "        static_parallelism=True,\n",
    "        validate_every=1,\n",
    "        k = 10,\n",
    "        goal_accuracy=90.0\n",
    "    )\n",
    ")\n",
    "\n",
    "exp = KubemlExperiment(title='test experiment', request=request)\n",
    "exp.network_id = '85878038'\n",
    "exp.history = h\n",
    "\n",
    "exp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp = KubemlExperiment('test', request= request)\n",
    "exp.network_id = '85878038'\n",
    "\n",
    "exp.check_if_task_finished()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge experiments\n",
    "\n",
    "Get the small dataframes of each experiment and merge them onto a single dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "from typing import List\n",
    "\n",
    "files = glob.glob('./tests/*.pkl')\n",
    "\n",
    "dataframes: List[pd.DataFrame] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    _d = pd.read_pickle(f)\n",
    "    dataframes.append(_d)\n",
    "\n",
    "d = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "d\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_pickle('./100experiments.pkl')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Mnist dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "cifar10_tr = datasets.CIFAR10(root='./datasets/cifar10/', train=True, download=False, transform=None)\n",
    "cifar10_test = datasets.CIFAR10(root='./datasets/cifar10/', train=False, download=False, transform=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist, cifar10, cifar100\n",
    "import numpy as np\n",
    "\n",
    "file_names = ['x_train', 'y_train', 'x_test', 'y_test']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = mnist.load_data()\n",
    "\n",
    "# save the different train and test arrays in the datasets folder\n",
    "\n",
    "for name, data in zip(file_names, [trainX, trainY, testX, testY]):\n",
    "    n = f'./datasets/mnist/mnist_{name}.npy'\n",
    "    with open(n, 'wb') as f:\n",
    "        print(f'Saving data of shape {data.shape}, to file {n}')\n",
    "        np.save(n, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cifar10 dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "\n",
    "\n",
    "for name, data in zip(file_names, [trainX, trainY, testX, testY]):\n",
    "    n = f'./datasets/cifar10/cifar10_{name}.npy'\n",
    "    with open(n, 'wb') as f:\n",
    "        print(f'Saving data of shape {data.shape}, to file {n}')\n",
    "        np.save(n, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Cifar100 dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = cifar100.load_data()\n",
    "\n",
    "\n",
    "for name, data in zip(file_names, [trainX, trainY, testX, testY]):\n",
    "    n = f'./datasets/cifar100/cifar100_{name}.npy'\n",
    "    with open(n, 'wb') as f:\n",
    "        print(f'Saving data of shape {data.shape}, to file {n}')\n",
    "        np.save(n, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Try to load the data in a custom made dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class Cifar10Dataset(Dataset):\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the train data and labels\n",
    "        self.data = np.load('datasets/cifar10/cifar10_x_train.npy')\n",
    "        self.targets = np.load('datasets/cifar10/cifar10_y_train.npy')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.data[index]), self.targets[index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = Cifar10Dataset()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loader = DataLoader(d, batch_size=16)\n",
    "i = iter(loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = next(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y = a\n",
    "x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#explore resnet\n",
    "\n",
    "from torchvision.models.resnet import resnet18\n",
    "from torchinfo import summary\n",
    "\n",
    "r = resnet18(pretrained=True)\n",
    "\n",
    "summary(r, input_size=(32, 3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.models.vgg import vgg11\n",
    "\n",
    "v = vgg11()\n",
    "v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    \"\"\" Definition of the LeNet network as per the 1998 paper\n",
    "\n",
    "    Credits to https://github.com/ChawDoe/LeNet5-MNIST-PyTorch for the\n",
    "    convenience of the network definition and the train loop found there\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu5(y)\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = LeNet()\n",
    "summary(n, input_size=(32, 1, 28, 28))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}