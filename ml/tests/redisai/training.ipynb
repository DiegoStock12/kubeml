{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network using the REDISAI db as an exchange place and debug the problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as tdata\n",
    "\n",
    "import numpy as np\n",
    "import redisai as rai\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the modules used in the program\n",
    "import train_utils\n",
    "import ml2rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainParams:\n",
    "    ps_id: str\n",
    "    N: int\n",
    "    task: str\n",
    "    func_id: int\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "def create_model(init: bool):\n",
    "    \"\"\"Creates the model used to train the network\n",
    "\n",
    "    For this example we'll be using the simple model from the MNIST examples\n",
    "    (https://github.com/pytorch/examples/blob/master/mnist/main.py)\n",
    "    \"\"\"\n",
    "\n",
    "    def init_weights(m: nn.Module):\n",
    "        \"\"\"Initialize the weights of the network\"\"\"\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "\n",
    "    # Create the model and initialize the weights\n",
    "    model = Net()\n",
    "\n",
    "    # If the task is initializing the layers do so\n",
    "    if init:\n",
    "        print('Initializing layers...')\n",
    "        model.apply(init_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO max document size is 16 MB, this could give us problems in the future\n",
    "# when the datasets are so big, we should calculate the size (easy, and divide the dataset)\n",
    "def split_dataset(X, Y, subsets):\n",
    "    \"\"\"Splits the X and Y in N different subsets\"\"\"\n",
    "    X_split = np.split(X, subsets)\n",
    "    Y_split = np.split(Y, subsets)\n",
    "    \n",
    "    return X_split, Y_split\n",
    "\n",
    "\n",
    "def approx_size(a: np.array):\n",
    "    \"\"\" approx size of float 32 array in MB\"\"\"\n",
    "    return (32/8) * np.prod(a.shape) / 1e6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6016, 2048)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47*128, 16*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=False, transform=transform)\n",
    "val_data = datasets.MNIST('./data', train=False, download=False, transform=transform)\n",
    "\n",
    "train_data.data, train_data.targets = train_data.data[:3000], train_data.targets[:3000]\n",
    "val_data.data, val_data.targets = val_data.data[:2000], val_data.targets[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the train and test methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, device,\n",
    "          train_loader: tdata.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer, tensor_dict) -> float:\n",
    "    \"\"\"Loop used to train the network\"\"\"\n",
    "    model.train()\n",
    "    loss, tot = 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        print(data.shape, target.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        print(output.shape)\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "        tot += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Here save the gradients to publish on the database\n",
    "#         train_utils.update_tensor_dict(model, tensor_dict)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                   100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    return tot/len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, device, val_loader: tdata.DataLoader) -> (float, float):\n",
    "    \"\"\"Loop used to validate the network\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "\n",
    "    accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return accuracy, test_loss\n",
    "\n",
    "def infer(model, device, data: np.array):\n",
    "    \"\"\"Forward the data through the network and return the predictions\"\"\"\n",
    "    model.eval()\n",
    "    data = transform(data).to(device)\n",
    "    data = data.permute(1, 2, 0).view(-1, 1, 28, 28)\n",
    "    out = model(data)\n",
    "    \n",
    "    preds = torch.argmax(out, axis=1)\n",
    "    return preds.cpu().numpy()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.1307,), std=(0.3081,))\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main entrypoint of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing layers...\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "params = TrainParams(ps_id='example', func_id=0, N =2, task='train', lr=0.01, batch_size=128)\n",
    "\n",
    "\n",
    "torch.manual_seed(42) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# Create the model\n",
    "model = create_model(init=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the redis connection\n",
    "addr = '192.168.99.101'\n",
    "port = 31618\n",
    "con = rai.Client(debug=True, host=addr, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train for a couple of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.441164\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.476388\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.634671\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.668302\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.645981\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([56, 1, 28, 28]) torch.Size([56])\n",
      "torch.Size([56, 10])\n",
      "\n",
      "Test set: Average loss: 0.4714, Accuracy: 1730/2000 (86%)\n",
      "\n",
      "Epoch 2\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.438474\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.475923\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.615678\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.420893\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.633873\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([56, 1, 28, 28]) torch.Size([56])\n",
      "torch.Size([56, 10])\n",
      "\n",
      "Test set: Average loss: 0.4222, Accuracy: 1739/2000 (87%)\n",
      "\n",
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the tensor dict\n",
    "tdict = dict()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1,3):\n",
    "    print('Epoch', epoch)\n",
    "    train(model, device, train_loader, optimizer, tdict)\n",
    "    validate(model, device, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2704c46f390>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[0].numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 28, 28])\n",
      "torch.Size([6, 1, 28, 28])\n",
      "torch.Size([6, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 4, 2], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_test = np.random.rand(28, 28, 2).astype('float32')\n",
    "data = train_data.data[:6].numpy()\n",
    "t = transform(data).to(device)\n",
    "t = t.permute(1, 2, 0)\n",
    "print(t.shape)\n",
    "t = t.view(-1, 1, 28, 28)\n",
    "print(t.shape)\n",
    "\n",
    "plt.imshow(t[0].cpu().numpy().squeeze())\n",
    "print(t.shape)\n",
    "# t = torch.Tensor(input_test).to(device)\n",
    "# out = model(t)\n",
    "out=model.forward(t)\n",
    "\n",
    "a = np.array([4], dtype='int64')\n",
    "target = torch.as_tensor(a).to(device)\n",
    "pred = torch.argmax(out, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(24, dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = train_data.data[:10].numpy()\n",
    "infer(model, device, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET model\n"
     ]
    }
   ],
   "source": [
    "s = pickle.loads(con.get('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 28, 28])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.as_tensor(train_data.data[:2].numpy()).shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
