{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network using the REDISAI db as an exchange place and debug the problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as tdata\n",
    "\n",
    "import numpy as np\n",
    "import redisai as rai\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo\n",
    "\n",
    "# Ip of minikube and the port of the mongo service\n",
    "MONGO_IP = '192.168.99.101'\n",
    "MONGO_PORT = 30933\n",
    "\n",
    "# import the modules used in the program\n",
    "import train_utils\n",
    "import ml2rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainParams:\n",
    "    ps_id: str\n",
    "    N: int\n",
    "    task: str\n",
    "    func_id: int\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "def create_model(init: bool):\n",
    "    \"\"\"Creates the model used to train the network\n",
    "\n",
    "    For this example we'll be using the simple model from the MNIST examples\n",
    "    (https://github.com/pytorch/examples/blob/master/mnist/main.py)\n",
    "    \"\"\"\n",
    "\n",
    "    def init_weights(m: nn.Module):\n",
    "        \"\"\"Initialize the weights of the network\"\"\"\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "\n",
    "    # Create the model and initialize the weights\n",
    "    model = Net()\n",
    "\n",
    "    # If the task is initializing the layers do so\n",
    "    if init:\n",
    "        print('Initializing layers...')\n",
    "        model.apply(init_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO max document size is 16 MB, this could give us problems in the future\n",
    "# when the datasets are so big, we should calculate the size (easy, and divide the dataset)\n",
    "def split_dataset(X, Y, subsets):\n",
    "    \"\"\"Splits the X and Y in N different subsets\"\"\"\n",
    "    X_split = np.split(X, subsets)\n",
    "    Y_split = np.split(Y, subsets)\n",
    "    \n",
    "    return X_split, Y_split\n",
    "\n",
    "\n",
    "def approx_size(a: np.array):\n",
    "    \"\"\" approx size of float 32 array in MB\"\"\"\n",
    "    return (32/8) * np.prod(a.shape) / 1e6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6016, 2048)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47*128, 16*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=False, transform=transform)\n",
    "val_data = datasets.MNIST('./data', train=False, download=False, transform=transform)\n",
    "\n",
    "train_data.data, train_data.targets = train_data.data[:3000], train_data.targets[:3000]\n",
    "val_data.data, val_data.targets = val_data.data[:2000], val_data.targets[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the train and test methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, device,\n",
    "          train_loader: tdata.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer, tensor_dict) -> float:\n",
    "    \"\"\"Loop used to train the network\"\"\"\n",
    "    model.train()\n",
    "    loss, tot = 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        print(data.shape, target.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        print(output.shape)\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "        tot += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Here save the gradients to publish on the database\n",
    "#         train_utils.update_tensor_dict(model, tensor_dict)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                   100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    return tot/len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, device, val_loader: tdata.DataLoader) -> (float, float):\n",
    "    \"\"\"Loop used to validate the network\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "\n",
    "    accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return accuracy, test_loss\n",
    "\n",
    "def infer(model, device, data: np.array):\n",
    "    \"\"\"Forward the data through the network and return the predictions\"\"\"\n",
    "    model.eval()\n",
    "    data = transform(data).to(device)\n",
    "    data = data.permute(1, 2, 0).view(-1, 1, 28, 28)\n",
    "    out = model(data)\n",
    "    \n",
    "    preds = torch.argmax(out, axis=1)\n",
    "    return preds.cpu().numpy()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.1307,), std=(0.3081,))\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main entrypoint of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing layers...\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "params = TrainParams(ps_id='example', func_id=0, N =2, task='train', lr=0.01, batch_size=128)\n",
    "\n",
    "\n",
    "torch.manual_seed(42) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# Create the model\n",
    "model = create_model(init=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the redis connection\n",
    "addr = '192.168.99.101'\n",
    "port = 31618\n",
    "con = rai.Client(debug=True, host=addr, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train for a couple of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.441164\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.476388\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.634671\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.668302\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.645981\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([56, 1, 28, 28]) torch.Size([56])\n",
      "torch.Size([56, 10])\n",
      "\n",
      "Test set: Average loss: 0.4714, Accuracy: 1730/2000 (86%)\n",
      "\n",
      "Epoch 2\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.438474\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.475923\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.615678\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.420893\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.633873\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([56, 1, 28, 28]) torch.Size([56])\n",
      "torch.Size([56, 10])\n",
      "\n",
      "Test set: Average loss: 0.4222, Accuracy: 1739/2000 (87%)\n",
      "\n",
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the tensor dict\n",
    "tdict = dict()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1,3):\n",
    "    print('Epoch', epoch)\n",
    "    train(model, device, train_loader, optimizer, tdict)\n",
    "    validate(model, device, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2704c46f390>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[0].numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 28, 28])\n",
      "torch.Size([6, 1, 28, 28])\n",
      "torch.Size([6, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 4, 2], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_test = np.random.rand(28, 28, 2).astype('float32')\n",
    "data = train_data.data[:6].numpy()\n",
    "t = transform(data).to(device)\n",
    "t = t.permute(1, 2, 0)\n",
    "print(t.shape)\n",
    "t = t.view(-1, 1, 28, 28)\n",
    "print(t.shape)\n",
    "\n",
    "plt.imshow(t[0].cpu().numpy().squeeze())\n",
    "print(t.shape)\n",
    "# t = torch.Tensor(input_test).to(device)\n",
    "# out = model(t)\n",
    "out=model.forward(t)\n",
    "\n",
    "a = np.array([4], dtype='int64')\n",
    "target = torch.as_tensor(a).to(device)\n",
    "pred = torch.argmax(out, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-812d12b45ac6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-140-227556938fb9>\u001b[0m in \u001b[0;36minfer\u001b[1;34m(model, device, data)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-21968359e3aa>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 420\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "t = train_data.data[:10].numpy()\n",
    "infer(model, device, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = pickle.dumps(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-0.0710,  0.1848,  0.0198],\n",
       "                        [-0.2222, -0.1628, -0.2172],\n",
       "                        [-0.0973, -0.0572, -0.1459]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1846, -0.0205, -0.0799],\n",
       "                        [-0.0126,  0.0830, -0.2512],\n",
       "                        [-0.0528, -0.1518, -0.0973]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1700,  0.0730,  0.1478],\n",
       "                        [-0.2474,  0.1059,  0.2154],\n",
       "                        [-0.0067, -0.2537, -0.1290]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0379, -0.0428, -0.1682],\n",
       "                        [-0.0059,  0.0958, -0.0359],\n",
       "                        [ 0.0487, -0.0123,  0.0376]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1336,  0.0980,  0.1453],\n",
       "                        [ 0.0606,  0.1253,  0.0542],\n",
       "                        [-0.0262,  0.0133,  0.1075]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1015, -0.1102, -0.0561],\n",
       "                        [ 0.0206, -0.0892, -0.0675],\n",
       "                        [ 0.0370, -0.0717, -0.0137]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0139, -0.0966, -0.1249],\n",
       "                        [-0.0227,  0.1261, -0.0229],\n",
       "                        [ 0.0189, -0.2525, -0.0305]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0089, -0.3430, -0.0557],\n",
       "                        [ 0.1262,  0.0434,  0.0560],\n",
       "                        [-0.1560, -0.1264, -0.1175]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1241,  0.0200,  0.1054],\n",
       "                        [-0.0267,  0.0137, -0.0999],\n",
       "                        [ 0.0604, -0.0675, -0.0776]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2193,  0.0576,  0.0375],\n",
       "                        [-0.1654,  0.0515, -0.2926],\n",
       "                        [-0.1224, -0.1764, -0.0519]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0391, -0.0146, -0.1044],\n",
       "                        [-0.1090, -0.1400, -0.0818],\n",
       "                        [-0.0935, -0.0113,  0.1318]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0630, -0.1171, -0.1341],\n",
       "                        [-0.1274, -0.1713, -0.2140],\n",
       "                        [ 0.1084,  0.0139, -0.1149]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0335,  0.1047,  0.0687],\n",
       "                        [-0.0396,  0.0105, -0.1337],\n",
       "                        [ 0.0751,  0.0295,  0.1719]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0262,  0.1018,  0.0746],\n",
       "                        [-0.2304, -0.0090, -0.0982],\n",
       "                        [-0.0714, -0.0479, -0.1866]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0638, -0.0693,  0.2048],\n",
       "                        [ 0.2199, -0.0485, -0.0117],\n",
       "                        [-0.1990, -0.1729, -0.2244]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1054, -0.0245, -0.1977],\n",
       "                        [ 0.0486,  0.1427, -0.0777],\n",
       "                        [-0.1716,  0.0639,  0.1008]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1822, -0.1056, -0.1709],\n",
       "                        [ 0.1374,  0.1628, -0.0186],\n",
       "                        [-0.1106,  0.0545, -0.2033]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0772,  0.0484,  0.2740],\n",
       "                        [-0.1026, -0.0699, -0.0672],\n",
       "                        [-0.0068,  0.1597,  0.0532]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0679,  0.0962, -0.0327],\n",
       "                        [ 0.1162, -0.0866, -0.0505],\n",
       "                        [ 0.0009, -0.1640, -0.1685]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1501,  0.0212, -0.1191],\n",
       "                        [ 0.0250,  0.0271,  0.0524],\n",
       "                        [ 0.0124, -0.0066, -0.2362]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0434, -0.0212, -0.1514],\n",
       "                        [ 0.0007, -0.0598, -0.0820],\n",
       "                        [-0.1771,  0.0405,  0.0280]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2688, -0.1551, -0.0126],\n",
       "                        [ 0.2478,  0.1044, -0.0188],\n",
       "                        [ 0.0154, -0.1899, -0.2469]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1099,  0.1238, -0.0719],\n",
       "                        [-0.1698, -0.0986, -0.1865],\n",
       "                        [-0.0530, -0.1039, -0.0220]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1756, -0.1072, -0.0446],\n",
       "                        [-0.0625,  0.0518,  0.0692],\n",
       "                        [ 0.1341,  0.1383,  0.0202]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1791, -0.0556, -0.0395],\n",
       "                        [ 0.0041,  0.0156, -0.0843],\n",
       "                        [-0.1062,  0.0921,  0.0125]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1483,  0.0333,  0.0027],\n",
       "                        [-0.2049,  0.0729, -0.1820],\n",
       "                        [ 0.0706, -0.1061, -0.1614]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0502,  0.0039, -0.1383],\n",
       "                        [-0.1040,  0.0860, -0.1031],\n",
       "                        [-0.1251,  0.0422, -0.1801]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0072,  0.0937, -0.0837],\n",
       "                        [ 0.0441, -0.0222,  0.1376],\n",
       "                        [-0.0346, -0.1758, -0.0201]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0876,  0.0079,  0.0897],\n",
       "                        [-0.0620, -0.0386, -0.0505],\n",
       "                        [ 0.0364, -0.0295, -0.0644]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1203, -0.0450,  0.1386],\n",
       "                        [ 0.0207, -0.0372, -0.1210],\n",
       "                        [ 0.1042, -0.0575, -0.1264]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0774, -0.0859,  0.0108],\n",
       "                        [-0.0889, -0.0934,  0.0769],\n",
       "                        [-0.1067, -0.1876, -0.0084]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0133, -0.1186, -0.0141],\n",
       "                        [-0.0833, -0.1528,  0.0145],\n",
       "                        [-0.0996, -0.0202, -0.1578]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.0097, -0.1389, -0.2091, -0.1680, -0.0782, -0.1894, -0.1745, -0.0158,\n",
       "                      -0.1863, -0.0497, -0.0699, -0.0353, -0.0668, -0.0492,  0.0212, -0.0447,\n",
       "                      -0.0477, -0.1443, -0.0667, -0.1874, -0.0556, -0.0371, -0.0732, -0.0043,\n",
       "                      -0.0732, -0.0909, -0.0897, -0.0468, -0.1873, -0.1023, -0.0804, -0.0856])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-0.1464, -0.0221, -0.0786],\n",
       "                        [-0.1302, -0.1200,  0.0112],\n",
       "                        [-0.0915,  0.0057, -0.0503]],\n",
       "              \n",
       "                       [[ 0.0019, -0.0260, -0.0894],\n",
       "                        [-0.0121, -0.1035, -0.0547],\n",
       "                        [-0.1429, -0.0378,  0.0127]],\n",
       "              \n",
       "                       [[ 0.0019, -0.1065,  0.0138],\n",
       "                        [-0.1044, -0.0364, -0.0239],\n",
       "                        [-0.0580, -0.0417, -0.0517]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1032, -0.0699, -0.0068],\n",
       "                        [ 0.0009, -0.0616,  0.0040],\n",
       "                        [-0.1507, -0.0269, -0.0801]],\n",
       "              \n",
       "                       [[-0.0346,  0.0141, -0.0729],\n",
       "                        [-0.1289, -0.1190, -0.0375],\n",
       "                        [-0.0837, -0.1461, -0.1135]],\n",
       "              \n",
       "                       [[ 0.0071, -0.0769, -0.0810],\n",
       "                        [-0.0890, -0.0397, -0.0268],\n",
       "                        [-0.0693, -0.0002, -0.0892]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1156, -0.1276, -0.1393],\n",
       "                        [-0.1309, -0.0423, -0.0540],\n",
       "                        [-0.0932, -0.0950, -0.0371]],\n",
       "              \n",
       "                       [[-0.0067, -0.1073, -0.1167],\n",
       "                        [-0.1036, -0.0040, -0.1358],\n",
       "                        [ 0.0041, -0.1238, -0.0121]],\n",
       "              \n",
       "                       [[-0.0784, -0.1211, -0.1167],\n",
       "                        [ 0.0044, -0.0381, -0.1341],\n",
       "                        [-0.0997, -0.1285, -0.0166]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0024, -0.0003, -0.0893],\n",
       "                        [-0.0988, -0.0669, -0.1184],\n",
       "                        [ 0.0044, -0.1319, -0.0286]],\n",
       "              \n",
       "                       [[-0.0292, -0.0695, -0.0473],\n",
       "                        [-0.1375, -0.1339,  0.0230],\n",
       "                        [-0.0772, -0.0757, -0.1439]],\n",
       "              \n",
       "                       [[-0.0682, -0.0190, -0.1235],\n",
       "                        [ 0.0051, -0.0017, -0.1344],\n",
       "                        [-0.0720, -0.0969, -0.0162]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0603, -0.0667,  0.0245],\n",
       "                        [-0.1285, -0.0420, -0.1067],\n",
       "                        [-0.0241, -0.1199,  0.0307]],\n",
       "              \n",
       "                       [[-0.1400, -0.0658, -0.0573],\n",
       "                        [-0.0393, -0.0014, -0.1493],\n",
       "                        [-0.0680, -0.0467, -0.0417]],\n",
       "              \n",
       "                       [[-0.1107, -0.0765, -0.0137],\n",
       "                        [-0.0115, -0.1058, -0.0716],\n",
       "                        [-0.0431, -0.1027, -0.0519]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1035, -0.0567,  0.0056],\n",
       "                        [-0.0610, -0.0495, -0.0146],\n",
       "                        [-0.1046,  0.0147,  0.0052]],\n",
       "              \n",
       "                       [[-0.1222, -0.0421, -0.0595],\n",
       "                        [-0.0576, -0.0962, -0.0110],\n",
       "                        [-0.0808, -0.0756, -0.1379]],\n",
       "              \n",
       "                       [[-0.0485, -0.0865, -0.0638],\n",
       "                        [-0.0137,  0.0075,  0.0351],\n",
       "                        [ 0.0087, -0.1109, -0.0611]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.1506,  0.0227, -0.0825],\n",
       "                        [-0.0790, -0.1387, -0.0971],\n",
       "                        [-0.1084, -0.0303, -0.0822]],\n",
       "              \n",
       "                       [[-0.0270, -0.1010, -0.0472],\n",
       "                        [-0.0596, -0.1244, -0.0268],\n",
       "                        [-0.0800,  0.0036, -0.0506]],\n",
       "              \n",
       "                       [[-0.0435, -0.0188, -0.0298],\n",
       "                        [-0.0734, -0.0853, -0.0040],\n",
       "                        [-0.0643, -0.1292, -0.0096]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0186,  0.0120, -0.0448],\n",
       "                        [ 0.0300, -0.0601, -0.0361],\n",
       "                        [-0.1315, -0.0542, -0.0820]],\n",
       "              \n",
       "                       [[-0.1186, -0.0292, -0.0511],\n",
       "                        [-0.0404, -0.1465, -0.0429],\n",
       "                        [-0.0739, -0.1136, -0.0891]],\n",
       "              \n",
       "                       [[-0.0628, -0.0754, -0.1111],\n",
       "                        [-0.0097, -0.1502, -0.0202],\n",
       "                        [-0.0210, -0.0929, -0.1457]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0729,  0.0080,  0.0111],\n",
       "                        [-0.1128, -0.1242,  0.0259],\n",
       "                        [-0.0576, -0.0510, -0.1023]],\n",
       "              \n",
       "                       [[-0.1378, -0.0722,  0.0094],\n",
       "                        [-0.0618, -0.1109, -0.0696],\n",
       "                        [-0.0254, -0.1047, -0.1248]],\n",
       "              \n",
       "                       [[-0.0473, -0.0878,  0.0108],\n",
       "                        [-0.1019, -0.1107, -0.0616],\n",
       "                        [-0.0398,  0.0112, -0.0640]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1012, -0.0674, -0.0936],\n",
       "                        [-0.1206, -0.0694,  0.0169],\n",
       "                        [-0.0935, -0.1303, -0.0443]],\n",
       "              \n",
       "                       [[-0.0005, -0.0009, -0.0753],\n",
       "                        [-0.0806, -0.0076, -0.1041],\n",
       "                        [-0.0871, -0.0889, -0.0149]],\n",
       "              \n",
       "                       [[ 0.0133,  0.0238, -0.0362],\n",
       "                        [-0.0958, -0.0110, -0.0039],\n",
       "                        [-0.0968, -0.0129, -0.1258]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0752, -0.0228, -0.1317],\n",
       "                        [-0.0575, -0.1358, -0.1013],\n",
       "                        [-0.0765, -0.1463, -0.0260]],\n",
       "              \n",
       "                       [[ 0.0088, -0.1086, -0.0490],\n",
       "                        [-0.0720, -0.0048, -0.0798],\n",
       "                        [-0.1463, -0.1310,  0.0019]],\n",
       "              \n",
       "                       [[-0.0502, -0.1139, -0.0098],\n",
       "                        [ 0.0194,  0.0124, -0.0359],\n",
       "                        [-0.1351, -0.0390, -0.0985]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0083, -0.1063, -0.0342],\n",
       "                        [-0.0044, -0.0294, -0.1009],\n",
       "                        [-0.1233, -0.1038, -0.0122]],\n",
       "              \n",
       "                       [[-0.0589, -0.0275, -0.0707],\n",
       "                        [-0.1117,  0.0139, -0.0801],\n",
       "                        [-0.0465, -0.0397, -0.0214]],\n",
       "              \n",
       "                       [[-0.1218, -0.0242, -0.0197],\n",
       "                        [-0.1102, -0.1519, -0.0827],\n",
       "                        [-0.0709, -0.1046, -0.0068]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([-0.0597, -0.0590, -0.0564, -0.0652, -0.0501, -0.0597, -0.0412, -0.0656,\n",
       "                      -0.0476, -0.0399, -0.0409, -0.0726, -0.0522, -0.0741,  0.0041, -0.0700,\n",
       "                      -0.0574, -0.0580, -0.0509, -0.0599, -0.0585, -0.0688, -0.0572, -0.0398,\n",
       "                      -0.0582, -0.0602, -0.0480, -0.0612, -0.0578, -0.0544, -0.0496, -0.0553,\n",
       "                      -0.0395, -0.0405, -0.0483, -0.0576, -0.0566, -0.0501, -0.0436, -0.0384,\n",
       "                      -0.0486, -0.0395, -0.0496, -0.0402, -0.0620, -0.0559, -0.0607, -0.0559,\n",
       "                      -0.0642, -0.0482, -0.0569, -0.0581, -0.0605, -0.0459, -0.0622, -0.0577,\n",
       "                      -0.0597, -0.0620, -0.0498, -0.0431, -0.0578, -0.0565, -0.0394, -0.0575])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0694,  0.0691, -0.0621,  ..., -0.0761, -0.0545, -0.0815],\n",
       "                      [-0.0677, -0.0746, -0.0378,  ..., -0.0549, -0.0410, -0.0442],\n",
       "                      [-0.0653, -0.0463, -0.0570,  ..., -0.0659, -0.0347, -0.0439],\n",
       "                      ...,\n",
       "                      [-0.0527, -0.0420, -0.0787,  ..., -0.0343, -0.0735, -0.0661],\n",
       "                      [ 0.0345,  0.0617,  0.0478,  ...,  0.0706,  0.0585,  0.0636],\n",
       "                      [ 0.0677,  0.0739,  0.0605,  ...,  0.0185,  0.0843,  0.0471]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.1508, -0.0894, -0.0901, -0.0292,  0.0623, -0.0478,  0.0377,  0.0518,\n",
       "                      -0.1096, -0.0389,  0.0973,  0.0354, -0.0853, -0.0482,  0.0005,  0.0637,\n",
       "                      -0.0514, -0.0313, -0.1223,  0.0367,  0.0320, -0.0330,  0.0183, -0.0036,\n",
       "                      -0.0606, -0.0492,  0.0221, -0.1122,  0.0138,  0.0437, -0.0464, -0.0496,\n",
       "                      -0.0402,  0.0737, -0.0562, -0.0070,  0.0229, -0.0221,  0.0195,  0.1659,\n",
       "                       0.0071,  0.0826,  0.0971, -0.0902,  0.1806, -0.0788,  0.0506, -0.0649,\n",
       "                      -0.0496,  0.0037, -0.1743,  0.0051, -0.0706, -0.0362,  0.3175, -0.2056,\n",
       "                      -0.1012, -0.0302, -0.1075,  0.0492,  0.1212,  0.0573,  0.0199,  0.1153,\n",
       "                       0.0942, -0.0935,  0.0857, -0.0698,  0.1557, -0.0600,  0.1744,  0.0452,\n",
       "                      -0.0496,  0.0082, -0.1103, -0.0085,  0.0146, -0.1407, -0.0997,  0.1671,\n",
       "                       0.0247, -0.0985,  0.0588,  0.0684, -0.3226, -0.0872, -0.0496, -0.0154,\n",
       "                      -0.0774, -0.1467, -0.0047, -0.0625, -0.1217, -0.0721,  0.1598,  0.0148,\n",
       "                      -0.0130, -0.0414,  0.0979, -0.0395, -0.0496, -0.0838,  0.0747, -0.0599,\n",
       "                       0.0384, -0.1121, -0.0794, -0.0464, -0.0122, -0.0496, -0.0496,  0.1746,\n",
       "                      -0.0035,  0.0025,  0.0279, -0.0542,  0.0196, -0.0758, -0.0132, -0.0815,\n",
       "                       0.0437, -0.1015,  0.0248,  0.1295, -0.0840, -0.0496, -0.0819, -0.1835])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.2398,  0.2423,  0.1145,  ...,  0.2312, -0.3363,  0.2012],\n",
       "                      [ 0.2992, -0.4321, -0.7131,  ...,  0.1995, -0.2629, -0.2440],\n",
       "                      [ 0.1016, -0.0656, -0.0115,  ..., -0.0821, -0.2178, -0.0566],\n",
       "                      ...,\n",
       "                      [ 0.1919,  0.2917, -0.2799,  ...,  0.0399,  0.0774, -0.1135],\n",
       "                      [-0.0943, -0.5366, -0.1942,  ..., -0.0130,  0.1173,  0.2318],\n",
       "                      [-0.4050,  0.2053, -0.0393,  ..., -0.2373,  0.1391,  0.2597]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0548,  0.1706, -0.0546,  0.0065,  0.1379,  0.0285, -0.0410, -0.0197,\n",
       "                      -0.0455,  0.2093]))])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu().state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(MONGO_IP, MONGO_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nIndexesWas': 1, 'ns': 'kubeml.network', 'ok': 1.0}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client['kubeml']\n",
    "db.drop_collection('network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['network'].insert_one(\n",
    "    {\n",
    "        \"_id\": \"test\",\n",
    "        \"state_dict\": pickle.dumps(model.cpu().state_dict())\n",
    "}).inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = db['network'].find_one({\"_id\": \"test\"})\n",
    "model.load_state_dict(pickle.loads(res['state']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the function with some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "ROUTER_ADDRESS = \"http://192.168.99.101:32422\"\n",
    "FUNCTION = \"network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.data[0].numpy().tolist()\n",
    "# data = np.array(data, dtype='uint8')\n",
    "# infer(model, device, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = json.dumps({\"data\":data})\n",
    "with open('example.json', 'w') as f:\n",
    "    f.write(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the request \n",
    "# url = \"http://192.168.99.101:32422/inference?N=1&batchSize=128&funcId=0&lr=0.01&psId=test&task=infer\"\n",
    "url = \"http://192.168.99.101:32422/network?N=1&batchSize=0&funcId=0&lr=1&psId=test&task=infer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(url, json={\"data\": data })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()['predictions']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
