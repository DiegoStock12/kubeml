{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network using the REDISAI db as an exchange place and debug the problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as tdata\n",
    "\n",
    "import numpy as np\n",
    "import redisai as rai\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "\n",
    "# import the modules used in the program\n",
    "import train_utils\n",
    "import ml2rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainParams:\n",
    "    ps_id: str\n",
    "    N: int\n",
    "    task: str\n",
    "    func_id: int\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "def create_model(init: bool):\n",
    "    \"\"\"Creates the model used to train the network\n",
    "\n",
    "    For this example we'll be using the simple model from the MNIST examples\n",
    "    (https://github.com/pytorch/examples/blob/master/mnist/main.py)\n",
    "    \"\"\"\n",
    "\n",
    "    def init_weights(m: nn.Module):\n",
    "        \"\"\"Initialize the weights of the network\"\"\"\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "\n",
    "    # Create the model and initialize the weights\n",
    "    model = Net()\n",
    "\n",
    "    # If the task is initializing the layers do so\n",
    "    if init:\n",
    "        print('Initializing layers...')\n",
    "        model.apply(init_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO max document size is 16 MB, this could give us problems in the future\n",
    "# when the datasets are so big, we should calculate the size (easy, and divide the dataset)\n",
    "def split_dataset(X, Y, subsets):\n",
    "    \"\"\"Splits the X and Y in N different subsets\"\"\"\n",
    "    X_split = np.split(X, subsets)\n",
    "    Y_split = np.split(Y, subsets)\n",
    "    \n",
    "    return X_split, Y_split\n",
    "\n",
    "\n",
    "def approx_size(a: np.array):\n",
    "    \"\"\" approx size of float 32 array in MB\"\"\"\n",
    "    return (32/8) * np.prod(a.shape) / 1e6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6016, 2048)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47*128, 16*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=False, transform=transform)\n",
    "val_data = datasets.MNIST('./data', train=False, download=False, transform=transform)\n",
    "\n",
    "train_data.data, train_data.targets = train_data.data[:3000], train_data.targets[:3000]\n",
    "val_data.data, val_data.targets = val_data.data[:2000], val_data.targets[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the train and test methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, device,\n",
    "          train_loader: tdata.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer, tensor_dict) -> float:\n",
    "    \"\"\"Loop used to train the network\"\"\"\n",
    "    model.train()\n",
    "    loss, tot = 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "        tot += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Here save the gradients to publish on the database\n",
    "#         train_utils.update_tensor_dict(model, tensor_dict)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                   100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    return tot/len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, device, val_loader: tdata.DataLoader) -> (float, float):\n",
    "    \"\"\"Loop used to validate the network\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "\n",
    "    accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main entrypoint of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing layers...\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "params = TrainParams(ps_id='example', func_id=0, N =2, task='train', lr=0.01, batch_size=128)\n",
    "\n",
    "\n",
    "torch.manual_seed(42) \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Create the model\n",
    "model = create_model(init=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the redis connection\n",
    "addr = '192.168.99.101'\n",
    "port = 31618\n",
    "con = rai.Client(debug=True, host=addr, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train for a couple of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 1.077198\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.999232\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 1.080022\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.726099\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.840101\n",
      "\n",
      "Test set: Average loss: 0.6271, Accuracy: 1648/2000 (82%)\n",
      "\n",
      "Epoch 2\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.564802\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.598982\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.737522\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.625483\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.712433\n",
      "\n",
      "Test set: Average loss: 0.4882, Accuracy: 1724/2000 (86%)\n",
      "\n",
      "Epoch 3\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.454958\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.540945\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.656202\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.470377\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.477005\n",
      "\n",
      "Test set: Average loss: 0.3404, Accuracy: 1793/2000 (90%)\n",
      "\n",
      "Epoch 4\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.442520\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.331795\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.460086\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.376440\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.483211\n",
      "\n",
      "Test set: Average loss: 0.3638, Accuracy: 1777/2000 (89%)\n",
      "\n",
      "Epoch 5\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.371238\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.366684\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.407458\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.347302\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.479509\n",
      "\n",
      "Test set: Average loss: 0.3386, Accuracy: 1779/2000 (89%)\n",
      "\n",
      "Epoch 6\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.316269\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.242856\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.359273\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.263445\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.328936\n",
      "\n",
      "Test set: Average loss: 0.2790, Accuracy: 1833/2000 (92%)\n",
      "\n",
      "Epoch 7\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.267880\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.223666\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.401866\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.350535\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.333938\n",
      "\n",
      "Test set: Average loss: 0.2843, Accuracy: 1822/2000 (91%)\n",
      "\n",
      "Epoch 8\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.313327\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.301376\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.464898\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.318586\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.259892\n",
      "\n",
      "Test set: Average loss: 0.2415, Accuracy: 1847/2000 (92%)\n",
      "\n",
      "Epoch 9\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.204838\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 0.230754\n",
      "Train Epoch: 1 [1280/3000 (42%)]\tLoss: 0.386277\n",
      "Train Epoch: 1 [1920/3000 (62%)]\tLoss: 0.269901\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.182029\n",
      "\n",
      "Test set: Average loss: 0.2434, Accuracy: 1855/2000 (93%)\n",
      "\n",
      "Wall time: 50.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the tensor dict\n",
    "tdict = dict()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1,10):\n",
    "    print('Epoch', epoch)\n",
    "    train(model, device, train_loader, optimizer, tdict)\n",
    "    validate(model, device, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.set('model', pickle.dumps(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET model\n"
     ]
    }
   ],
   "source": [
    "s = pickle.loads(con.get('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "[enforce fail at inline_container.cc:208] . file not found: archive/constants.pkl frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void const*) + 0x67 (0x7f4653cd7787 in /usr/lib/redis/modules/backends/redisai_torch/lib/libc10.so) frame #1: caffe2::serialize::PyTorchStreamReader::getRecordID(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xd6 (0x7f4646c4b376 in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #2: caffe2::serialize::PyTorchStreamReader::getRecord(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x38 (0x7f4646c4c018 in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #3: torch::jit::readArchiveAndTensors(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, c10::optional<std::function<c10::StrongTypePtr (c10::QualifiedName const&)> >, c10::optional<std::function<c10::intrusive_ptr<c10::ivalue::Object, c10::detail::intrusive_target_default_null_type<c10::ivalue::Object> > (c10::StrongTypePtr, c10::IValue)> >, c10::optional<c10::Device>, caffe2::serialize::PyTorchStreamReader&) + 0xda (0x7f4647ccf3aa in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #4: <unknown function> + 0x2f3bc9d (0x7f4647ccfc9d in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #5: <unknown function> + 0x2f3e26f (0x7f4647cd226f in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #6: torch::jit::load(std::unique_ptr<caffe2::serialize::ReadAdapterInterface, std::default_delete<caffe2::serialize::ReadAdapterInterface> >, c10::optional<c10::Device>, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >&) + 0x179 (0x7f4647cd2bf9 in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #7: torch::jit::load(std::istream&, c10::optional<c10::Device>, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >&) + 0x75 (0x7f4647cd33f5 in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #8: torchLoadModel + 0x215 (0x7f465c91b425 in /usr/lib/redis/modules/backends/redisai_torch/redisai_torch.so) frame #9: RAI_ModelCreateTorch + 0x8a (0x7f465c9141ea in /usr/lib/redis/modules/backends/redisai_torch/redisai_torch.so) frame #10: RAI_ModelCreate + 0x16d (0x7f465c94ac8d in /usr/lib/redis/modules/redisai.so) frame #11: RedisAI_ModelSet_RedisCommand + 0x6ea (0x7f465c943f3a in /usr/lib/redis/modules/redisai.so) frame #12: RedisModuleCommandDispatcher + 0x54 (0x5608c664f114 in redis-server *:6379) frame #13: call + 0x9d (0x5608c65daffd in redis-server *:6379) frame #14: processCommand + 0x33f (0x5608c65db78f in redis-server *:6379) frame #15: processCommandAndResetClient + 0x10 (0x5608c65e9480 in redis-server *:6379) frame #16: processInputBuffer + 0x18f (0x5608c65edacf in redis-server *:6379) frame #17: <unknown function> + 0xd5fac (0x5608c666afac in redis-server *:6379) frame #18: aeProcessEvents + 0x2e7 (0x5608c65d4bd7 in redis-server *:6379) frame #19: aeMain + 0x1d (0x5608c65d4f1d in redis-server *:6379) frame #20: main + 0x4c9 (0x5608c65d17c9 in redis-server *:6379) frame #21: __libc_start_main + 0xeb (0x7f465c98909b in /lib/x86_64-linux-gnu/libc.so.6) frame #22: _start + 0x2a (0x5608c65d1a5a in redis-server *:6379) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-aaf68984e56b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test-model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'torch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\redisai\\client.py\u001b[0m in \u001b[0;36mmodelset\u001b[1;34m(self, key, backend, device, data, batch, minbatch, tag, inputs, outputs)\u001b[0m\n\u001b[0;32m    226\u001b[0m         args = builder.modelset(key, backend, device, data,\n\u001b[0;32m    227\u001b[0m                                 batch, minbatch, tag, inputs, outputs)\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmodelget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAnyStr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\redisai\\client.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\redis\\client.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m    899\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\redis\\client.py\u001b[0m in \u001b[0;36mparse_response\u001b[1;34m(self, connection, command_name, **options)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[1;34m\"Parses a response from the Redis server\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mEMPTY_RESPONSE\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\redis\\connection.py\u001b[0m in \u001b[0;36mread_response\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResponseError\u001b[0m: [enforce fail at inline_container.cc:208] . file not found: archive/constants.pkl frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void const*) + 0x67 (0x7f4653cd7787 in /usr/lib/redis/modules/backends/redisai_torch/lib/libc10.so) frame #1: caffe2::serialize::PyTorchStreamReader::getRecordID(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xd6 (0x7f4646c4b376 in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #2: caffe2::serialize::PyTorchStreamReader::getRecord(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x38 (0x7f4646c4c018 in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #3: torch::jit::readArchiveAndTensors(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, c10::optional<std::function<c10::StrongTypePtr (c10::QualifiedName const&)> >, c10::optional<std::function<c10::intrusive_ptr<c10::ivalue::Object, c10::detail::intrusive_target_default_null_type<c10::ivalue::Object> > (c10::StrongTypePtr, c10::IValue)> >, c10::optional<c10::Device>, caffe2::serialize::PyTorchStreamReader&) + 0xda (0x7f4647ccf3aa in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #4: <unknown function> + 0x2f3bc9d (0x7f4647ccfc9d in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #5: <unknown function> + 0x2f3e26f (0x7f4647cd226f in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #6: torch::jit::load(std::unique_ptr<caffe2::serialize::ReadAdapterInterface, std::default_delete<caffe2::serialize::ReadAdapterInterface> >, c10::optional<c10::Device>, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >&) + 0x179 (0x7f4647cd2bf9 in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #7: torch::jit::load(std::istream&, c10::optional<c10::Device>, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >&) + 0x75 (0x7f4647cd33f5 in /usr/lib/redis/modules/backends/redisai_torch/lib/libtorch_cpu.so) frame #8: torchLoadModel + 0x215 (0x7f465c91b425 in /usr/lib/redis/modules/backends/redisai_torch/redisai_torch.so) frame #9: RAI_ModelCreateTorch + 0x8a (0x7f465c9141ea in /usr/lib/redis/modules/backends/redisai_torch/redisai_torch.so) frame #10: RAI_ModelCreate + 0x16d (0x7f465c94ac8d in /usr/lib/redis/modules/redisai.so) frame #11: RedisAI_ModelSet_RedisCommand + 0x6ea (0x7f465c943f3a in /usr/lib/redis/modules/redisai.so) frame #12: RedisModuleCommandDispatcher + 0x54 (0x5608c664f114 in redis-server *:6379) frame #13: call + 0x9d (0x5608c65daffd in redis-server *:6379) frame #14: processCommand + 0x33f (0x5608c65db78f in redis-server *:6379) frame #15: processCommandAndResetClient + 0x10 (0x5608c65e9480 in redis-server *:6379) frame #16: processInputBuffer + 0x18f (0x5608c65edacf in redis-server *:6379) frame #17: <unknown function> + 0xd5fac (0x5608c666afac in redis-server *:6379) frame #18: aeProcessEvents + 0x2e7 (0x5608c65d4bd7 in redis-server *:6379) frame #19: aeMain + 0x1d (0x5608c65d4f1d in redis-server *:6379) frame #20: main + 0x4c9 (0x5608c65d17c9 in redis-server *:6379) frame #21: __libc_start_main + 0xeb (0x7f465c98909b in /lib/x86_64-linux-gnu/libc.so.6) frame #22: _start + 0x2a (0x5608c65d1a5a in redis-server *:6379) "
     ]
    }
   ],
   "source": [
    "con.modelset('test-model', 'torch', 'cpu', m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
