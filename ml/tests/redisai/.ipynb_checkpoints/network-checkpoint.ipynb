{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test RedisAI with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network\n",
    "\n",
    "Take the network from the pytorch MNIST examples \n",
    "(https://github.com/pytorch/examples/blob/master/mnist/main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset and the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "data = datasets.MNIST('./data', train=True, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a single tensor to forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = it.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to store the gradients during training at the end of each epoch and see how much time it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_d = {}\n",
    "\n",
    "# We get similar performance with both methods,\n",
    "# and with the second one we dont need to use twice the amount of GPU mem\n",
    "\n",
    "# Should we do this with a backup model or should be save the state in a dict for example?? we could add cuda tensors there\n",
    "def update_tensor(m: nn.Module, backup: nn.Module):\n",
    "    \"\"\"Saves all of the model layers and adds the gradients\n",
    "    \n",
    "    For this we need the two networks to reside in the GPU\n",
    "    which will use extra memory, instead of that we could use a dictionary\n",
    "    \"\"\"\n",
    "    for (n1, l1), (n2, l2) in zip(m.named_children(), backup.named_children()):\n",
    "        if hasattr(l1, 'weight'):\n",
    "            if l2.weight.grad is None:\n",
    "                l2.weight.grad = l1.weight.grad\n",
    "                l2.bias.grad = l1.bias.grad\n",
    "            else:\n",
    "                l2.weight.grad += l1.weight.grad\n",
    "                l2.bias.grad += l1.bias.grad\n",
    "                \n",
    "def update_tensor_dict(m:nn.Module, d:dict):\n",
    "    for n, l in m.named_children():\n",
    "        if hasattr(l, 'weight'):\n",
    "            if n in d:\n",
    "                d[f'{n}-weight-grad'] += l.weight.grad\n",
    "                d[f'{n}-bias-grad'] += l.bias.grad\n",
    "            else:\n",
    "                d[f'{n}-weight-grad'] = l.weight.grad\n",
    "                d[f'{n}-bias-grad'] = l.bias.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.type of Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, l in model.named_children():\n",
    "    if hasattr(l, 'weight'):\n",
    "        print(l.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network and do a forward and backward pass to get the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "model = Net()\n",
    "# backup = copy.deepcopy(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "# Send the network to the GPU\n",
    "model= model.cuda()\n",
    "# backup.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 2048/55460\n",
      "Training 4096/55460\n",
      "Training 6144/55460\n",
      "Training 8192/55460\n",
      "Training 10240/55460\n",
      "Training 12288/55460\n",
      "Training 14336/55460\n",
      "Training 16384/55460\n",
      "Training 18432/55460\n",
      "Training 20480/55460\n",
      "Training 22528/55460\n",
      "Training 24576/55460\n",
      "Training 26624/55460\n",
      "Training 28672/55460\n",
      "Training 30720/55460\n",
      "Training 32768/55460\n",
      "Training 34816/55460\n",
      "Training 36864/55460\n",
      "Training 38912/55460\n",
      "Training 40960/55460\n",
      "Training 43008/55460\n",
      "Training 45056/55460\n",
      "Training 47104/55460\n",
      "Training 49152/55460\n",
      "Training 51200/55460\n",
      "Training 53248/55460\n",
      "Training 55296/55460\n",
      "Training 57344/55460\n",
      "Training 59392/55460\n",
      "Wall time: 8.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    \n",
    "    count += len(inputs)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if count % 2048 == 0:\n",
    "        print(f'Training {count}/{236*len(train_loader)}')\n",
    "    \n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Zero the optimizer before the forward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    out = model(inputs)\n",
    "\n",
    "    loss = F.nll_loss(out, targets)\n",
    "    loss.backward()\n",
    "    \n",
    "    #Here update the models\n",
    "    update_tensor_dict(model, tensor_d)\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.4642e-01,  2.7304e-01,  4.5395e-01],\n",
       "          [ 2.6783e-01,  3.6382e-01,  4.4114e-01],\n",
       "          [ 3.1757e-01,  3.6190e-01,  2.8485e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4341e-02,  4.2412e-02,  5.5452e-02],\n",
       "          [-1.2178e-01, -1.5585e-01, -1.3747e-01],\n",
       "          [-2.2299e-01, -2.6808e-01, -2.4312e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.6722e-02, -1.4312e-01, -1.6756e-01],\n",
       "          [ 8.2408e-03, -1.0563e-01, -1.9977e-01],\n",
       "          [ 3.4165e-02, -5.1862e-02, -1.0601e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.0611e-03,  2.1725e-03, -4.4433e-03],\n",
       "          [ 6.0551e-03,  5.6476e-04, -7.2787e-03],\n",
       "          [ 2.3656e-02,  3.0154e-02,  2.3867e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.4638e-02,  5.0914e-02,  2.2711e-02],\n",
       "          [ 5.5055e-02,  8.5083e-02,  1.7322e-01],\n",
       "          [-3.8288e-02,  1.2097e-01,  1.4546e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 6.8327e-02,  1.0597e-01,  8.8448e-02],\n",
       "          [-2.7004e-02, -3.0769e-02, -2.9263e-02],\n",
       "          [-7.5956e-02, -5.8920e-02, -3.8645e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.3818e-02,  9.7501e-02,  1.4623e-01],\n",
       "          [-6.5734e-03,  3.8029e-02, -4.4298e-02],\n",
       "          [-4.7026e-02, -1.0608e-01, -1.6485e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.8006e-03, -1.3771e-03,  8.2495e-03],\n",
       "          [-1.6020e-02, -1.3665e-02, -9.4143e-03],\n",
       "          [-1.3126e-02, -1.0893e-02, -1.5825e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 9.7462e-03, -7.6408e-02, -4.7613e-02],\n",
       "          [ 4.7034e-03, -6.7171e-02,  2.8537e-03],\n",
       "          [ 4.2843e-02,  3.9465e-02,  3.9361e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0789e-02,  6.2518e-02,  5.0251e-02],\n",
       "          [ 1.2833e-02,  1.5734e-02, -1.5749e-02],\n",
       "          [-1.0601e-02, -1.5573e-02, -5.2457e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.2269e-03, -6.2006e-03, -3.4138e-02],\n",
       "          [ 3.1741e-02, -1.3620e-03, -1.4781e-02],\n",
       "          [ 6.8851e-02,  1.0144e-02,  6.0756e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0523e-01,  1.0198e-01,  1.6083e-02],\n",
       "          [ 5.7736e-02,  2.6097e-02, -1.9221e-02],\n",
       "          [-1.4966e-02, -3.5323e-02, -2.4553e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.2978e-02,  1.8461e-02, -3.0941e-03],\n",
       "          [ 3.3941e-02,  2.1244e-02,  7.0140e-02],\n",
       "          [ 3.2982e-02,  9.1925e-02,  1.5929e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.7716e-02, -3.6777e-02, -2.4392e-02],\n",
       "          [-1.4292e-02, -2.5924e-02, -7.5079e-03],\n",
       "          [ 2.2326e-02,  1.3012e-03, -2.1017e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.9043e-02,  4.0970e-02,  3.6856e-02],\n",
       "          [ 5.4740e-03, -3.3196e-04, -7.7293e-02],\n",
       "          [-9.6341e-02, -1.0788e-01, -1.4274e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.5536e-03,  3.9375e-02,  7.5349e-02],\n",
       "          [-1.1675e-01, -3.1627e-02,  6.3305e-02],\n",
       "          [-1.9472e-01, -7.5008e-02, -1.2149e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.0386e-02,  1.6924e-01,  2.8842e-01],\n",
       "          [ 1.3989e-01,  1.9480e-01,  2.2229e-01],\n",
       "          [ 1.8664e-01,  1.3365e-01,  8.7296e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2799e-02,  6.7541e-02,  1.3386e-01],\n",
       "          [-4.3979e-02, -3.1636e-02, -5.8456e-02],\n",
       "          [-1.3167e-01, -1.3267e-01, -1.8453e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.0379e-02, -7.1252e-03,  6.7083e-04],\n",
       "          [-3.5233e-02, -3.1678e-02, -3.9894e-02],\n",
       "          [-3.8254e-02, -4.4871e-02, -6.2613e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7077e-01,  1.1936e-01,  3.9052e-02],\n",
       "          [ 9.4534e-02,  5.3390e-02,  1.0989e-02],\n",
       "          [-1.8721e-02,  1.4010e-02,  5.6375e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.6139e-03, -7.0472e-02, -7.8675e-02],\n",
       "          [ 3.0147e-02, -9.0022e-03,  1.9845e-02],\n",
       "          [ 5.1272e-02,  1.0349e-01,  9.2756e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1152e-01,  1.5836e-01,  1.5204e-01],\n",
       "          [ 1.0105e-01,  1.2264e-01,  8.1452e-02],\n",
       "          [-3.2767e-04, -2.9459e-02, -7.6548e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 8.6919e-03,  2.5228e-02, -2.7372e-02],\n",
       "          [ 2.6265e-03,  1.2443e-02, -1.2037e-02],\n",
       "          [ 1.3113e-02,  1.9586e-02, -9.0230e-03]]],\n",
       "\n",
       "\n",
       "        [[[-3.3204e-02, -3.5026e-02, -4.2952e-02],\n",
       "          [ 2.1228e-02, -2.7982e-03, -1.3336e-02],\n",
       "          [ 9.4640e-02,  1.0138e-01,  5.5348e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.5443e-03, -1.6616e-03,  3.4336e-04],\n",
       "          [-1.6132e-05,  3.2071e-04,  6.4800e-04],\n",
       "          [ 3.2836e-04,  2.9376e-04,  4.6294e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 9.2444e-02,  2.1619e-01,  2.9374e-01],\n",
       "          [ 1.2128e-01,  1.8259e-01,  1.7377e-01],\n",
       "          [ 8.5691e-02,  7.2920e-02,  1.0933e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9790e-02,  1.0265e-01,  2.0932e-01],\n",
       "          [-5.0680e-02,  2.9615e-02,  1.7606e-01],\n",
       "          [-1.0779e-01, -6.4069e-02,  3.0932e-03]]],\n",
       "\n",
       "\n",
       "        [[[-5.8168e-02, -4.3825e-02, -6.5076e-02],\n",
       "          [-1.6022e-02,  8.5493e-04, -9.9751e-02],\n",
       "          [ 8.3174e-02,  4.3635e-02, -2.0104e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.6792e-04,  1.3058e-02, -2.0440e-02],\n",
       "          [-1.7372e-02,  1.5638e-03, -1.6037e-02],\n",
       "          [ 2.3106e-02,  8.5045e-03, -2.8178e-02]]],\n",
       "\n",
       "\n",
       "        [[[-9.9461e-03, -2.8079e-03,  2.6072e-02],\n",
       "          [-1.8420e-02, -3.3177e-02, -1.4938e-02],\n",
       "          [-8.8870e-02, -5.4792e-02, -3.3774e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.0662e-01, -7.2935e-02, -3.0205e-02],\n",
       "          [-6.9664e-02, -3.2010e-02, -2.1809e-02],\n",
       "          [ 5.7291e-02,  6.2663e-02,  6.0817e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3623e-02,  4.7649e-02,  4.5596e-02],\n",
       "          [-1.2554e-02,  2.0935e-04, -4.6685e-04],\n",
       "          [-3.3377e-02, -9.5243e-03, -3.6821e-02]]]], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backup.conv1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_grad = model.conv1.weight.grad\n",
    "c1_bias = model.conv1.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0227, -0.0067, -0.0178, -0.0109, -0.0477, -0.0449,  0.0397, -0.0082,\n",
       "         0.0264,  0.0336, -0.0039, -0.0088, -0.0036, -0.0117, -0.0381, -0.0327,\n",
       "         0.0582, -0.0235,  0.0553,  0.0312, -0.0406,  0.0068, -0.0255, -0.0035,\n",
       "        -0.0088, -0.0571, -0.0233,  0.0372,  0.0306, -0.0292, -0.0360, -0.0016,\n",
       "        -0.0143, -0.0280,  0.0211, -0.0314,  0.0349, -0.0057,  0.0332, -0.0252,\n",
       "        -0.0051, -0.0295, -0.0579,  0.0104, -0.0027, -0.0251, -0.0517,  0.0363,\n",
       "        -0.0509, -0.0433, -0.0313,  0.0249, -0.0252, -0.0375, -0.0479, -0.0196,\n",
       "         0.0496,  0.0129,  0.0549,  0.0393, -0.0151,  0.0468, -0.0266,  0.0164],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv2.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the REDIS AI part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redisai as rai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = rai.Client(host='192.168.99.102', port=6379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.tensorset('grad-conv1', c1_grad.numpy(), dtype='float32')\n",
    "con.tensorset('bias-conv1', c1_bias.numpy(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.set('example', 'hola')\n",
    "con.set('exaaaaa', 'hola2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set all the model gradients to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting example:conv1-weight\n",
      "Setting example:conv1-bias\n",
      "Setting example:conv2-weight\n",
      "Setting example:conv2-bias\n",
      "Setting example:fc1-weight\n",
      "Setting example:fc1-bias\n",
      "Setting example:fc2-weight\n",
      "Setting example:fc2-bias\n"
     ]
    }
   ],
   "source": [
    "psId = 'example'\n",
    "\n",
    "for n, l in model.named_children():\n",
    "    if hasattr(l, 'bias'):\n",
    "        key_w = f'{psId}:{n}-weight'\n",
    "        key_b = f'{psId}:{n}-bias'\n",
    "\n",
    "        print('Setting', key_w)\n",
    "        con.tensorset(key_w, l.weight.cpu().detach().numpy(), dtype='float32')\n",
    "\n",
    "        print('Setting', key_b)\n",
    "        con.tensorset(key_b, l.bias.cpu().detach().numpy(), dtype='float32')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to set the model to REDIS\n",
    "\n",
    "We can simply save the state dict and retrieve it super quickly from the following functions as a python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 0.1247, -0.2343,  0.2413],\n",
       "                        [ 0.2814, -0.2949, -0.1152],\n",
       "                        [ 0.1794,  0.3214,  0.1535]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2677, -0.2998,  0.2019],\n",
       "                        [-0.0371, -0.2684,  0.3079],\n",
       "                        [-0.1485, -0.1790,  0.1690]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0169, -0.2387,  0.1334],\n",
       "                        [ 0.0769,  0.2841,  0.1754],\n",
       "                        [ 0.1311,  0.0290, -0.0110]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0936, -0.2159, -0.1453],\n",
       "                        [-0.1982,  0.3253,  0.0502],\n",
       "                        [ 0.2596, -0.1228, -0.2570]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0238,  0.1362,  0.2403],\n",
       "                        [ 0.1665, -0.2756,  0.0901],\n",
       "                        [ 0.0269, -0.2431,  0.0739]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0283, -0.1184,  0.2224],\n",
       "                        [ 0.2876,  0.1003,  0.0171],\n",
       "                        [ 0.3254,  0.0351, -0.2718]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1060, -0.1569, -0.1678],\n",
       "                        [ 0.0926, -0.2940,  0.0310],\n",
       "                        [-0.1452, -0.3215,  0.2278]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2087, -0.1302,  0.2816],\n",
       "                        [ 0.0435, -0.2506,  0.3203],\n",
       "                        [ 0.0833, -0.2626, -0.1649]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2190, -0.1964, -0.3256],\n",
       "                        [ 0.1943,  0.0211,  0.1013],\n",
       "                        [ 0.1907, -0.2018, -0.0925]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0492,  0.2690, -0.2379],\n",
       "                        [ 0.0020,  0.0485, -0.2642],\n",
       "                        [-0.0905, -0.1493,  0.0986]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1057, -0.3093, -0.2767],\n",
       "                        [-0.2187,  0.3241,  0.3186],\n",
       "                        [-0.3152,  0.0268, -0.1521]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1795, -0.3062,  0.2991],\n",
       "                        [-0.1849, -0.2924, -0.2218],\n",
       "                        [ 0.2065, -0.0773, -0.1366]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2205,  0.1720,  0.2690],\n",
       "                        [ 0.0198,  0.0783,  0.2252],\n",
       "                        [-0.1337, -0.0486, -0.2206]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2706,  0.1703, -0.1690],\n",
       "                        [ 0.1192, -0.0109, -0.0215],\n",
       "                        [-0.1182,  0.2284,  0.1592]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1622,  0.0578, -0.1928],\n",
       "                        [ 0.2806, -0.0453, -0.1415],\n",
       "                        [-0.0471, -0.0205, -0.2808]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0781, -0.1415,  0.1409],\n",
       "                        [ 0.2078,  0.2646, -0.2408],\n",
       "                        [ 0.3144,  0.2644,  0.0706]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3320, -0.2150,  0.1265],\n",
       "                        [ 0.0584,  0.3283,  0.1183],\n",
       "                        [ 0.0210,  0.1241,  0.3298]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2746, -0.2968, -0.0102],\n",
       "                        [-0.1572,  0.0736, -0.2738],\n",
       "                        [ 0.1013,  0.0974, -0.2914]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0358,  0.0615, -0.1912],\n",
       "                        [-0.2387,  0.0762, -0.0883],\n",
       "                        [ 0.1041,  0.2567,  0.1519]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3163,  0.2404, -0.2741],\n",
       "                        [-0.1645,  0.1094, -0.0427],\n",
       "                        [ 0.2345,  0.1663, -0.0512]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1575, -0.2630, -0.2015],\n",
       "                        [-0.1346,  0.0184,  0.3013],\n",
       "                        [ 0.3260,  0.1866, -0.1477]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2786,  0.1309, -0.1751],\n",
       "                        [ 0.0363,  0.2865,  0.0417],\n",
       "                        [ 0.1138, -0.1176, -0.1190]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2823,  0.0676,  0.1213],\n",
       "                        [ 0.2004, -0.0658,  0.1690],\n",
       "                        [ 0.3041,  0.3293,  0.1985]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3233,  0.1186,  0.1138],\n",
       "                        [ 0.2104,  0.0249,  0.0212],\n",
       "                        [-0.0751,  0.3209, -0.2349]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1769,  0.1650, -0.2573],\n",
       "                        [-0.1091,  0.1555, -0.0794],\n",
       "                        [-0.2734, -0.0381,  0.2775]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1274,  0.1051, -0.0945],\n",
       "                        [ 0.2017,  0.3282,  0.0739],\n",
       "                        [-0.2947, -0.0428, -0.0159]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1362, -0.1850, -0.1964],\n",
       "                        [-0.0043, -0.3110, -0.2698],\n",
       "                        [ 0.2767, -0.0441, -0.3085]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1891,  0.3210,  0.1046],\n",
       "                        [ 0.0201,  0.2842,  0.1063],\n",
       "                        [ 0.1419,  0.0378,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0639, -0.1568, -0.1104],\n",
       "                        [ 0.3197, -0.3324, -0.2833],\n",
       "                        [ 0.0871, -0.1071, -0.1978]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2013,  0.0359, -0.1809],\n",
       "                        [-0.3041, -0.0569,  0.2412],\n",
       "                        [ 0.2046, -0.0615, -0.0074]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2029, -0.2125,  0.0676],\n",
       "                        [-0.0291,  0.1438, -0.2022],\n",
       "                        [-0.2324, -0.1334, -0.0909]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1656, -0.2777, -0.2354],\n",
       "                        [-0.2589,  0.1045, -0.2118],\n",
       "                        [-0.1223, -0.0657,  0.2587]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([ 0.2995, -0.2079, -0.0506, -0.0454,  0.0472,  0.2238, -0.1567, -0.2324,\n",
       "                      -0.0155,  0.3325,  0.2041, -0.0635,  0.1784,  0.1864,  0.1260,  0.2865,\n",
       "                      -0.1601,  0.1420,  0.1556,  0.1161,  0.1498, -0.2225,  0.0055, -0.0917,\n",
       "                      -0.2924, -0.2891,  0.2378, -0.2575, -0.1193,  0.2368,  0.2110, -0.3113])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-0.0384,  0.0104,  0.0047],\n",
       "                        [ 0.0186, -0.0052,  0.0306],\n",
       "                        [-0.0049,  0.0247, -0.0095]],\n",
       "              \n",
       "                       [[ 0.0436,  0.0526, -0.0016],\n",
       "                        [ 0.0405,  0.0279,  0.0582],\n",
       "                        [ 0.0502, -0.0216,  0.0152]],\n",
       "              \n",
       "                       [[-0.0261, -0.0176, -0.0436],\n",
       "                        [-0.0028, -0.0001, -0.0025],\n",
       "                        [ 0.0451,  0.0337, -0.0063]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0491,  0.0072,  0.0137],\n",
       "                        [ 0.0381,  0.0308,  0.0218],\n",
       "                        [-0.0442, -0.0209, -0.0411]],\n",
       "              \n",
       "                       [[-0.0020,  0.0192,  0.0250],\n",
       "                        [ 0.0302,  0.0135,  0.0099],\n",
       "                        [-0.0174, -0.0390,  0.0130]],\n",
       "              \n",
       "                       [[-0.0575,  0.0227,  0.0115],\n",
       "                        [-0.0516,  0.0259,  0.0469],\n",
       "                        [-0.0225,  0.0285,  0.0354]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0230, -0.0527, -0.0521],\n",
       "                        [-0.0216,  0.0294, -0.0015],\n",
       "                        [ 0.0552,  0.0045,  0.0007]],\n",
       "              \n",
       "                       [[-0.0239, -0.0435, -0.0108],\n",
       "                        [ 0.0374,  0.0310, -0.0371],\n",
       "                        [-0.0173,  0.0535,  0.0356]],\n",
       "              \n",
       "                       [[-0.0145,  0.0014,  0.0305],\n",
       "                        [-0.0066,  0.0054,  0.0574],\n",
       "                        [-0.0519,  0.0051, -0.0180]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0320, -0.0555,  0.0417],\n",
       "                        [-0.0281, -0.0148,  0.0471],\n",
       "                        [-0.0215,  0.0266, -0.0062]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0457,  0.0215],\n",
       "                        [ 0.0069,  0.0559,  0.0243],\n",
       "                        [ 0.0377, -0.0459,  0.0497]],\n",
       "              \n",
       "                       [[-0.0005,  0.0574, -0.0222],\n",
       "                        [-0.0116,  0.0524,  0.0495],\n",
       "                        [-0.0223,  0.0115,  0.0136]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0238, -0.0406, -0.0054],\n",
       "                        [-0.0469,  0.0464,  0.0474],\n",
       "                        [-0.0391,  0.0557, -0.0563]],\n",
       "              \n",
       "                       [[-0.0515,  0.0458,  0.0312],\n",
       "                        [-0.0534, -0.0437,  0.0570],\n",
       "                        [-0.0265, -0.0015, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0071,  0.0425,  0.0520],\n",
       "                        [-0.0545,  0.0285, -0.0589],\n",
       "                        [-0.0161,  0.0574,  0.0372]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0425,  0.0033,  0.0232],\n",
       "                        [ 0.0411,  0.0446, -0.0397],\n",
       "                        [ 0.0018,  0.0459, -0.0015]],\n",
       "              \n",
       "                       [[-0.0381,  0.0144,  0.0456],\n",
       "                        [ 0.0089,  0.0557, -0.0447],\n",
       "                        [-0.0298, -0.0262,  0.0380]],\n",
       "              \n",
       "                       [[ 0.0164,  0.0272,  0.0553],\n",
       "                        [ 0.0062, -0.0023,  0.0301],\n",
       "                        [ 0.0476, -0.0254, -0.0138]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0059, -0.0322, -0.0326],\n",
       "                        [ 0.0448,  0.0466,  0.0431],\n",
       "                        [ 0.0299,  0.0211, -0.0168]],\n",
       "              \n",
       "                       [[ 0.0424,  0.0482, -0.0233],\n",
       "                        [-0.0371,  0.0471,  0.0380],\n",
       "                        [ 0.0040,  0.0095,  0.0240]],\n",
       "              \n",
       "                       [[ 0.0200, -0.0298, -0.0103],\n",
       "                        [-0.0413, -0.0232, -0.0322],\n",
       "                        [ 0.0239,  0.0388,  0.0474]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0064, -0.0261,  0.0324],\n",
       "                        [-0.0393, -0.0054,  0.0336],\n",
       "                        [-0.0451, -0.0070,  0.0305]],\n",
       "              \n",
       "                       [[ 0.0111,  0.0111,  0.0386],\n",
       "                        [ 0.0031, -0.0201,  0.0018],\n",
       "                        [ 0.0406,  0.0479, -0.0185]],\n",
       "              \n",
       "                       [[ 0.0314,  0.0375, -0.0428],\n",
       "                        [ 0.0458,  0.0343,  0.0258],\n",
       "                        [ 0.0544, -0.0544,  0.0513]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0266, -0.0145, -0.0531],\n",
       "                        [-0.0255,  0.0026, -0.0340],\n",
       "                        [-0.0574, -0.0054,  0.0496]],\n",
       "              \n",
       "                       [[ 0.0481,  0.0549,  0.0522],\n",
       "                        [-0.0568, -0.0511,  0.0455],\n",
       "                        [ 0.0356, -0.0129, -0.0331]],\n",
       "              \n",
       "                       [[-0.0166, -0.0283, -0.0469],\n",
       "                        [ 0.0285,  0.0108,  0.0198],\n",
       "                        [ 0.0220,  0.0076,  0.0301]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0289,  0.0574, -0.0221],\n",
       "                        [-0.0378,  0.0268, -0.0321],\n",
       "                        [ 0.0155,  0.0419,  0.0389]],\n",
       "              \n",
       "                       [[ 0.0004,  0.0028, -0.0576],\n",
       "                        [-0.0030, -0.0324, -0.0174],\n",
       "                        [ 0.0383, -0.0501, -0.0151]],\n",
       "              \n",
       "                       [[ 0.0209, -0.0454,  0.0494],\n",
       "                        [ 0.0231, -0.0216,  0.0457],\n",
       "                        [ 0.0357, -0.0004, -0.0498]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0231,  0.0117,  0.0465],\n",
       "                        [-0.0531,  0.0348, -0.0337],\n",
       "                        [-0.0182,  0.0557, -0.0151]],\n",
       "              \n",
       "                       [[ 0.0577, -0.0487,  0.0200],\n",
       "                        [-0.0512, -0.0453, -0.0421],\n",
       "                        [ 0.0245, -0.0352,  0.0330]],\n",
       "              \n",
       "                       [[-0.0078, -0.0474, -0.0431],\n",
       "                        [ 0.0213,  0.0161, -0.0437],\n",
       "                        [ 0.0227, -0.0253,  0.0183]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0148,  0.0424,  0.0398],\n",
       "                        [ 0.0395, -0.0548, -0.0584],\n",
       "                        [-0.0013,  0.0571,  0.0566]],\n",
       "              \n",
       "                       [[-0.0237,  0.0246,  0.0146],\n",
       "                        [ 0.0063,  0.0217,  0.0339],\n",
       "                        [ 0.0441, -0.0308, -0.0570]],\n",
       "              \n",
       "                       [[-0.0290,  0.0563, -0.0185],\n",
       "                        [-0.0159, -0.0452, -0.0030],\n",
       "                        [ 0.0121, -0.0217,  0.0476]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.0432,  0.0551, -0.0415, -0.0355,  0.0536,  0.0101,  0.0495,  0.0159,\n",
       "                      -0.0521, -0.0288,  0.0195, -0.0118, -0.0347, -0.0039,  0.0441,  0.0371,\n",
       "                      -0.0348,  0.0216,  0.0058,  0.0206, -0.0530,  0.0134, -0.0364, -0.0115,\n",
       "                      -0.0431,  0.0169, -0.0204, -0.0166,  0.0552,  0.0077, -0.0050,  0.0378,\n",
       "                      -0.0191,  0.0314, -0.0061, -0.0068, -0.0049, -0.0163,  0.0493, -0.0420,\n",
       "                      -0.0073, -0.0525, -0.0377,  0.0525, -0.0462, -0.0007,  0.0155, -0.0470,\n",
       "                      -0.0391,  0.0074, -0.0283,  0.0275, -0.0196,  0.0240,  0.0126,  0.0137,\n",
       "                       0.0557, -0.0551, -0.0060,  0.0347, -0.0005,  0.0376,  0.0277,  0.0483])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0070,  0.0016, -0.0050,  ...,  0.0054,  0.0015, -0.0093],\n",
       "                      [ 0.0003, -0.0004,  0.0039,  ..., -0.0097, -0.0028, -0.0049],\n",
       "                      [-0.0074, -0.0003, -0.0039,  ...,  0.0090, -0.0082,  0.0029],\n",
       "                      ...,\n",
       "                      [-0.0104, -0.0100,  0.0023,  ...,  0.0082,  0.0028,  0.0098],\n",
       "                      [-0.0094,  0.0073, -0.0093,  ..., -0.0024,  0.0017, -0.0027],\n",
       "                      [ 0.0044, -0.0056, -0.0102,  ..., -0.0050, -0.0061,  0.0090]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-4.6180e-03, -3.2917e-03, -6.9536e-03, -1.0340e-02,  7.8915e-03,\n",
       "                       2.6675e-03,  8.4643e-03,  7.6002e-03, -1.2844e-03, -3.1385e-04,\n",
       "                       5.7034e-03, -9.6633e-03,  1.7595e-03,  5.4528e-03, -9.1192e-03,\n",
       "                       3.5367e-03, -5.3126e-03,  6.4501e-03,  6.1487e-03,  9.4620e-03,\n",
       "                       2.7314e-03, -8.9125e-03,  6.5928e-03,  1.9799e-03,  1.0051e-02,\n",
       "                       4.1180e-03,  2.7621e-03, -3.7905e-03,  5.3583e-03,  6.7356e-03,\n",
       "                       7.9255e-03,  5.0112e-03,  6.1937e-04, -2.1977e-03, -7.8272e-03,\n",
       "                      -4.1541e-03,  8.6165e-03,  1.8413e-03,  7.2036e-03,  5.0438e-03,\n",
       "                       5.5189e-03, -4.1967e-03, -6.7150e-03,  2.7584e-03, -9.5702e-03,\n",
       "                      -3.2314e-04, -5.8567e-03,  3.0438e-03,  9.8426e-04, -9.9090e-03,\n",
       "                      -8.7517e-03, -6.7785e-03, -1.4810e-03,  1.9983e-03, -9.3202e-03,\n",
       "                       6.2206e-04, -2.6936e-03,  8.8916e-03, -2.5338e-03, -4.2063e-03,\n",
       "                      -8.4956e-05,  7.4269e-03,  3.6085e-03,  3.0639e-03,  6.4696e-03,\n",
       "                      -9.7157e-03, -9.4571e-04, -9.8568e-03, -9.7352e-03, -7.3107e-03,\n",
       "                       7.8248e-04,  7.4229e-03, -6.4949e-03,  2.9071e-03,  7.6883e-03,\n",
       "                      -8.6734e-03, -9.1169e-03, -5.3964e-03, -5.8166e-05,  1.0232e-02,\n",
       "                       9.5215e-03,  8.0723e-03,  3.2283e-03,  6.6150e-03,  1.6620e-03,\n",
       "                      -2.9504e-03, -3.8070e-03,  4.0347e-04, -9.7498e-03, -5.3684e-03,\n",
       "                       4.4931e-03, -6.3881e-04, -6.6863e-03, -6.9763e-03, -8.8737e-03,\n",
       "                      -5.5864e-03,  6.2474e-03, -9.0128e-03,  1.0033e-02,  7.6529e-03,\n",
       "                      -8.3498e-03,  5.1295e-03,  1.5541e-03, -6.5935e-03, -1.6854e-03,\n",
       "                      -9.9526e-03, -8.7118e-03,  1.9663e-05,  5.7853e-03, -7.1165e-03,\n",
       "                      -1.2842e-03, -5.8104e-03, -1.0275e-03,  6.5078e-04, -8.7676e-03,\n",
       "                      -1.1386e-03, -8.4657e-03,  9.1704e-03,  3.2313e-03, -2.1498e-03,\n",
       "                      -9.8848e-04,  8.8118e-03,  2.4656e-03, -4.7301e-03, -9.5358e-03,\n",
       "                       4.2989e-03,  3.2628e-04, -5.8447e-03])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0510,  0.0116, -0.0369,  ...,  0.0451,  0.0071,  0.0069],\n",
       "                      [ 0.0365,  0.0055, -0.0806,  ...,  0.0276, -0.0369,  0.0576],\n",
       "                      [-0.0733,  0.0694,  0.0395,  ..., -0.0265,  0.0268, -0.0748],\n",
       "                      ...,\n",
       "                      [ 0.0432, -0.0457, -0.0447,  ...,  0.0634, -0.0639,  0.0525],\n",
       "                      [-0.0325,  0.0696,  0.0082,  ..., -0.0460,  0.0489,  0.0244],\n",
       "                      [ 0.0003,  0.0086, -0.0187,  ...,  0.0616, -0.0811,  0.0511]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0794,  0.0834,  0.0008,  0.0558,  0.0645, -0.0091, -0.0188,  0.0394,\n",
       "                      -0.0705, -0.0398]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "p = pickle.dumps(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.set('model', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "d = con.get('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.loads(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the layer names in redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1', 'conv2', 'fc1', 'fc2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get the weighted layers and save the model\n",
    "[n for n, l in m.named_children() if hasattr(l, \"bias\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "layers = ['conv1', 'conv2', 'fc1', 'fc2']\n",
    "l = json.dumps(layers)\n",
    "\n",
    "con.set('layers', l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
