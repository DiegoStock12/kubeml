{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test RedisAI with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network\n",
    "\n",
    "Take the network from the pytorch MNIST examples \n",
    "(https://github.com/pytorch/examples/blob/master/mnist/main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset and the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "data = datasets.MNIST('./data', train=True, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a single tensor to forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = it.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to store the gradients during training at the end of each epoch and see how much time it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_d = {}\n",
    "\n",
    "# We get similar performance with both methods,\n",
    "# and with the second one we dont need to use twice the amount of GPU mem\n",
    "\n",
    "# Should we do this with a backup model or should be save the state in a dict for example?? we could add cuda tensors there\n",
    "def update_tensor(m: nn.Module, backup: nn.Module):\n",
    "    \"\"\"Saves all of the model layers and adds the gradients\n",
    "    \n",
    "    For this we need the two networks to reside in the GPU\n",
    "    which will use extra memory, instead of that we could use a dictionary\n",
    "    \"\"\"\n",
    "    for (n1, l1), (n2, l2) in zip(m.named_children(), backup.named_children()):\n",
    "        if hasattr(l1, 'weight'):\n",
    "            if l2.weight.grad is None:\n",
    "                l2.weight.grad = l1.weight.grad\n",
    "                l2.bias.grad = l1.bias.grad\n",
    "            else:\n",
    "                l2.weight.grad += l1.weight.grad\n",
    "                l2.bias.grad += l1.bias.grad\n",
    "                \n",
    "def update_tensor_dict(m:nn.Module, d:dict):\n",
    "    for n, l in m.named_children():\n",
    "        if hasattr(l, 'weight'):\n",
    "            if n in d:\n",
    "                d[f'{n}-weight-grad'] += l.weight.grad\n",
    "                d[f'{n}-bias-grad'] += l.bias.grad\n",
    "            else:\n",
    "                d[f'{n}-weight-grad'] = l.weight.grad\n",
    "                d[f'{n}-bias-grad'] = l.bias.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.type of Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, l in model.named_children():\n",
    "    if hasattr(l, 'weight'):\n",
    "        print(l.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network and do a forward and backward pass to get the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "model = Net()\n",
    "# backup = copy.deepcopy(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "# Send the network to the GPU\n",
    "model= model.cuda()\n",
    "# backup.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 2048/55460\n",
      "Training 4096/55460\n",
      "Training 6144/55460\n",
      "Training 8192/55460\n",
      "Training 10240/55460\n",
      "Training 12288/55460\n",
      "Training 14336/55460\n",
      "Training 16384/55460\n",
      "Training 18432/55460\n",
      "Training 20480/55460\n",
      "Training 22528/55460\n",
      "Training 24576/55460\n",
      "Training 26624/55460\n",
      "Training 28672/55460\n",
      "Training 30720/55460\n",
      "Training 32768/55460\n",
      "Training 34816/55460\n",
      "Training 36864/55460\n",
      "Training 38912/55460\n",
      "Training 40960/55460\n",
      "Training 43008/55460\n",
      "Training 45056/55460\n",
      "Training 47104/55460\n",
      "Training 49152/55460\n",
      "Training 51200/55460\n",
      "Training 53248/55460\n",
      "Training 55296/55460\n",
      "Training 57344/55460\n",
      "Training 59392/55460\n",
      "Wall time: 8.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    \n",
    "    count += len(inputs)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if count % 2048 == 0:\n",
    "        print(f'Training {count}/{236*len(train_loader)}')\n",
    "    \n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Zero the optimizer before the forward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    out = model(inputs)\n",
    "\n",
    "    loss = F.nll_loss(out, targets)\n",
    "    loss.backward()\n",
    "    \n",
    "    #Here update the models\n",
    "    update_tensor_dict(model, tensor_d)\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.4642e-01,  2.7304e-01,  4.5395e-01],\n",
       "          [ 2.6783e-01,  3.6382e-01,  4.4114e-01],\n",
       "          [ 3.1757e-01,  3.6190e-01,  2.8485e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4341e-02,  4.2412e-02,  5.5452e-02],\n",
       "          [-1.2178e-01, -1.5585e-01, -1.3747e-01],\n",
       "          [-2.2299e-01, -2.6808e-01, -2.4312e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.6722e-02, -1.4312e-01, -1.6756e-01],\n",
       "          [ 8.2408e-03, -1.0563e-01, -1.9977e-01],\n",
       "          [ 3.4165e-02, -5.1862e-02, -1.0601e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.0611e-03,  2.1725e-03, -4.4433e-03],\n",
       "          [ 6.0551e-03,  5.6476e-04, -7.2787e-03],\n",
       "          [ 2.3656e-02,  3.0154e-02,  2.3867e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.4638e-02,  5.0914e-02,  2.2711e-02],\n",
       "          [ 5.5055e-02,  8.5083e-02,  1.7322e-01],\n",
       "          [-3.8288e-02,  1.2097e-01,  1.4546e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 6.8327e-02,  1.0597e-01,  8.8448e-02],\n",
       "          [-2.7004e-02, -3.0769e-02, -2.9263e-02],\n",
       "          [-7.5956e-02, -5.8920e-02, -3.8645e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.3818e-02,  9.7501e-02,  1.4623e-01],\n",
       "          [-6.5734e-03,  3.8029e-02, -4.4298e-02],\n",
       "          [-4.7026e-02, -1.0608e-01, -1.6485e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.8006e-03, -1.3771e-03,  8.2495e-03],\n",
       "          [-1.6020e-02, -1.3665e-02, -9.4143e-03],\n",
       "          [-1.3126e-02, -1.0893e-02, -1.5825e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 9.7462e-03, -7.6408e-02, -4.7613e-02],\n",
       "          [ 4.7034e-03, -6.7171e-02,  2.8537e-03],\n",
       "          [ 4.2843e-02,  3.9465e-02,  3.9361e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0789e-02,  6.2518e-02,  5.0251e-02],\n",
       "          [ 1.2833e-02,  1.5734e-02, -1.5749e-02],\n",
       "          [-1.0601e-02, -1.5573e-02, -5.2457e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.2269e-03, -6.2006e-03, -3.4138e-02],\n",
       "          [ 3.1741e-02, -1.3620e-03, -1.4781e-02],\n",
       "          [ 6.8851e-02,  1.0144e-02,  6.0756e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0523e-01,  1.0198e-01,  1.6083e-02],\n",
       "          [ 5.7736e-02,  2.6097e-02, -1.9221e-02],\n",
       "          [-1.4966e-02, -3.5323e-02, -2.4553e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.2978e-02,  1.8461e-02, -3.0941e-03],\n",
       "          [ 3.3941e-02,  2.1244e-02,  7.0140e-02],\n",
       "          [ 3.2982e-02,  9.1925e-02,  1.5929e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.7716e-02, -3.6777e-02, -2.4392e-02],\n",
       "          [-1.4292e-02, -2.5924e-02, -7.5079e-03],\n",
       "          [ 2.2326e-02,  1.3012e-03, -2.1017e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.9043e-02,  4.0970e-02,  3.6856e-02],\n",
       "          [ 5.4740e-03, -3.3196e-04, -7.7293e-02],\n",
       "          [-9.6341e-02, -1.0788e-01, -1.4274e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.5536e-03,  3.9375e-02,  7.5349e-02],\n",
       "          [-1.1675e-01, -3.1627e-02,  6.3305e-02],\n",
       "          [-1.9472e-01, -7.5008e-02, -1.2149e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.0386e-02,  1.6924e-01,  2.8842e-01],\n",
       "          [ 1.3989e-01,  1.9480e-01,  2.2229e-01],\n",
       "          [ 1.8664e-01,  1.3365e-01,  8.7296e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2799e-02,  6.7541e-02,  1.3386e-01],\n",
       "          [-4.3979e-02, -3.1636e-02, -5.8456e-02],\n",
       "          [-1.3167e-01, -1.3267e-01, -1.8453e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.0379e-02, -7.1252e-03,  6.7083e-04],\n",
       "          [-3.5233e-02, -3.1678e-02, -3.9894e-02],\n",
       "          [-3.8254e-02, -4.4871e-02, -6.2613e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7077e-01,  1.1936e-01,  3.9052e-02],\n",
       "          [ 9.4534e-02,  5.3390e-02,  1.0989e-02],\n",
       "          [-1.8721e-02,  1.4010e-02,  5.6375e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.6139e-03, -7.0472e-02, -7.8675e-02],\n",
       "          [ 3.0147e-02, -9.0022e-03,  1.9845e-02],\n",
       "          [ 5.1272e-02,  1.0349e-01,  9.2756e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1152e-01,  1.5836e-01,  1.5204e-01],\n",
       "          [ 1.0105e-01,  1.2264e-01,  8.1452e-02],\n",
       "          [-3.2767e-04, -2.9459e-02, -7.6548e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 8.6919e-03,  2.5228e-02, -2.7372e-02],\n",
       "          [ 2.6265e-03,  1.2443e-02, -1.2037e-02],\n",
       "          [ 1.3113e-02,  1.9586e-02, -9.0230e-03]]],\n",
       "\n",
       "\n",
       "        [[[-3.3204e-02, -3.5026e-02, -4.2952e-02],\n",
       "          [ 2.1228e-02, -2.7982e-03, -1.3336e-02],\n",
       "          [ 9.4640e-02,  1.0138e-01,  5.5348e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.5443e-03, -1.6616e-03,  3.4336e-04],\n",
       "          [-1.6132e-05,  3.2071e-04,  6.4800e-04],\n",
       "          [ 3.2836e-04,  2.9376e-04,  4.6294e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 9.2444e-02,  2.1619e-01,  2.9374e-01],\n",
       "          [ 1.2128e-01,  1.8259e-01,  1.7377e-01],\n",
       "          [ 8.5691e-02,  7.2920e-02,  1.0933e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9790e-02,  1.0265e-01,  2.0932e-01],\n",
       "          [-5.0680e-02,  2.9615e-02,  1.7606e-01],\n",
       "          [-1.0779e-01, -6.4069e-02,  3.0932e-03]]],\n",
       "\n",
       "\n",
       "        [[[-5.8168e-02, -4.3825e-02, -6.5076e-02],\n",
       "          [-1.6022e-02,  8.5493e-04, -9.9751e-02],\n",
       "          [ 8.3174e-02,  4.3635e-02, -2.0104e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.6792e-04,  1.3058e-02, -2.0440e-02],\n",
       "          [-1.7372e-02,  1.5638e-03, -1.6037e-02],\n",
       "          [ 2.3106e-02,  8.5045e-03, -2.8178e-02]]],\n",
       "\n",
       "\n",
       "        [[[-9.9461e-03, -2.8079e-03,  2.6072e-02],\n",
       "          [-1.8420e-02, -3.3177e-02, -1.4938e-02],\n",
       "          [-8.8870e-02, -5.4792e-02, -3.3774e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.0662e-01, -7.2935e-02, -3.0205e-02],\n",
       "          [-6.9664e-02, -3.2010e-02, -2.1809e-02],\n",
       "          [ 5.7291e-02,  6.2663e-02,  6.0817e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3623e-02,  4.7649e-02,  4.5596e-02],\n",
       "          [-1.2554e-02,  2.0935e-04, -4.6685e-04],\n",
       "          [-3.3377e-02, -9.5243e-03, -3.6821e-02]]]], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backup.conv1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_grad = model.conv1.weight.grad\n",
    "c1_bias = model.conv1.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0227, -0.0067, -0.0178, -0.0109, -0.0477, -0.0449,  0.0397, -0.0082,\n",
       "         0.0264,  0.0336, -0.0039, -0.0088, -0.0036, -0.0117, -0.0381, -0.0327,\n",
       "         0.0582, -0.0235,  0.0553,  0.0312, -0.0406,  0.0068, -0.0255, -0.0035,\n",
       "        -0.0088, -0.0571, -0.0233,  0.0372,  0.0306, -0.0292, -0.0360, -0.0016,\n",
       "        -0.0143, -0.0280,  0.0211, -0.0314,  0.0349, -0.0057,  0.0332, -0.0252,\n",
       "        -0.0051, -0.0295, -0.0579,  0.0104, -0.0027, -0.0251, -0.0517,  0.0363,\n",
       "        -0.0509, -0.0433, -0.0313,  0.0249, -0.0252, -0.0375, -0.0479, -0.0196,\n",
       "         0.0496,  0.0129,  0.0549,  0.0393, -0.0151,  0.0468, -0.0266,  0.0164],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv2.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the REDIS AI part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redisai as rai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = rai.Client(host='192.168.99.102', port=6379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.tensorset('grad-conv1', c1_grad.numpy(), dtype='float32')\n",
    "con.tensorset('bias-conv1', c1_bias.numpy(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.set('example', 'hola')\n",
    "con.set('exaaaaa', 'hola2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
