{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of mongoDB to save the datasets in numpy style\n",
    "\n",
    "Save the datasets (in this case we'll start with MNIST) in npy style and divide it in many minibatches so they are easier to handle.\n",
    "\n",
    "These are put into mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.utils.data as tdata\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# keras is better to save the dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# Ip of minikube and the port of the mongo service\n",
    "MONGO_IP = '192.168.99.101'\n",
    "MONGO_PORT = 30933"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Keras Dataset and analyze format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the datasets are of size (60000, 28, 28), for pytorch it expects tensors of shape (channels, 28, 28) unlike tensorflow \n",
    "# which expects them at the end\n",
    "trainX = trainX.reshape(trainX.shape[0], 1, 28, 28)\n",
    "testX = testX.reshape(testX.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels are (ax1)=5 (ax2)=0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a couple of images\n",
    "f, (ax1, ax2) = plt.subplots(1,2, sharey=True, figsize=(10,5))\n",
    "ax1.imshow(trainX[0].squeeze()) # Squeeze gets rid of that extra dimension at the beginning\n",
    "ax2.imshow(trainX[1].squeeze())\n",
    "print(f'Labels are (ax1)={trainY[0]} (ax2)={trainY[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images to the interval [0,1]\n",
    "trainX = trainX.astype('float32') /255\n",
    "testX = testX.astype('float32') /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to categorical\n",
    "trainY = np_utils.to_categorical(trainY)\n",
    "testY = np_utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset in N different subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO max document size is 16 MB, this could give us problems in the future\n",
    "# when the datasets are so big, we should calculate the size (easy, and divide the dataset)\n",
    "def split_dataset(X, Y, subsets):\n",
    "    \"\"\"Splits the X and Y in N different subsets\"\"\"\n",
    "    X_split = np.split(X, subsets)\n",
    "    Y_split = np.split(Y, subsets)\n",
    "    \n",
    "    return X_split, Y_split\n",
    "\n",
    "\n",
    "def approx_size(a: np.array):\n",
    "    \"\"\" approx size of float 32 array in MB\"\"\"\n",
    "    return (32/8) * np.prod(a.shape) / 1e6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, ytr = split_dataset(trainX, trainY, 100)\n",
    "xtest, ytest = split_dataset(testX, testY, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in xtr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Connection to Mongo and connect to the database\n",
    "\n",
    "We'll create a dataset database and one collection will be MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO maybe create a database MNIST and a collection for train and another for test\n",
    "# that would allow us to skip the train part of it\n",
    "DB_NAME = 'mnist'\n",
    "COLLECTION_NAME = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the mongo database and create the mnist collection if we do not have it already\n",
    "client : pymongo.MongoClient = pymongo.MongoClient(MONGO_IP, MONGO_PORT)\n",
    "db = client[DB_NAME]\n",
    "db.create_collection('train')\n",
    "db.create_collection('test')\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert the training data\n",
    "db['train'].insert_many([\n",
    "    {'_id': i,\n",
    "     'data': pickle.dumps(data, pickle.HIGHEST_PROTOCOL), \n",
    "     'labels':pickle.dumps(data, pickle.HIGHEST_PROTOCOL)} for i, (data, labels) in enumerate(zip(xtr, ytr))]).inserted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert the test data\n",
    "# Insert the training data\n",
    "db['test'].insert_many([\n",
    "    {'_id': i,\n",
    "     'data':pickle.dumps(data, pickle.HIGHEST_PROTOCOL), \n",
    "     'labels':pickle.dumps(data, pickle.HIGHEST_PROTOCOL)} for i, (data, labels) in enumerate(zip(xtest, ytest))]).inserted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch one of the documents by index\n",
    "doc = db.train.find_one({\"_id\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the array\n",
    "arr = pickle.loads(doc['data'])\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset from Torch that is able to load the examples from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(0, 4),\n",
       " range(4, 8),\n",
       " range(8, 11),\n",
       " range(11, 14),\n",
       " range(14, 17),\n",
       " range(17, 20)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return [a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n)]\n",
    "\n",
    "split(range(20), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = db.train.find({'_id':{'$gte': 3, '$lte':20}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.vstack([xtest[0], xtest[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\diego\\cs\\thesis\\venv\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = db.test.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_IP = '192.168.99.102'\n",
    "MONGO_PORT = 27017\n",
    "DATABASE = 'mnist'\n",
    "\n",
    "\n",
    "class MnistDataset(tdata.Dataset):\n",
    "    \"\"\" The dataset is able to load a specific subset of samples from MONGO and combine them \"\"\"\n",
    "\n",
    "    def __init__(self, func_id, num_func, task, transform=None):\n",
    "        \"\"\" Based on the funcId and the Number of functions, estimate the range of the datasets\n",
    "        that we should get from mongo.\n",
    "\n",
    "        :arg func_id ID of the function creating the dataset\n",
    "        :arg num_func total number of functions invoked\n",
    "        :arg task either train or val\n",
    "        :arg transform transformations to be applied\n",
    "        \"\"\"\n",
    "\n",
    "        # create the mongo client\n",
    "        self.client = pymongo.MongoClient(MONGO_IP, MONGO_PORT)\n",
    "        self.db = self.client[DATABASE]\n",
    "\n",
    "        # get the number of documents\n",
    "        ndocs = self.db.train.count_documents({})\n",
    "\n",
    "        if task == 'train':\n",
    "            minibatch = self._split_minibatches(range(ndocs), num_func)[func_id]\n",
    "            print('I get minibatches', minibatch)\n",
    "\n",
    "            self.data, self.labels = self._load_data(minibatch)\n",
    "\n",
    "        # If task is validation we just tell it to load all the data\n",
    "        else:\n",
    "            self.data, self.labels = self._load_data()\n",
    "\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # We could have 1 document per datapoint or group of datapoints?\n",
    "    # this is just useful for bigger datasets, but could save a lot of memory\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            return self.transforms(x), y\n",
    "        else:\n",
    "            return x, y\n",
    "\n",
    "    # TODO look how we can maybe declare indexes in mongodb to speed this up\n",
    "    def _load_data(self, minibatches=None):\n",
    "        \"\"\"Return the data from the MongoDB already formatted as a numpy array\"\"\"\n",
    "\n",
    "        if minibatches is None:\n",
    "            # load all because it is the validation\n",
    "            batches = self.db.test.find({})\n",
    "        else:\n",
    "            # Load the objects from Mongo\n",
    "            batches = self.db.train.find({\n",
    "                '_id': {'$gte': minibatches.start, '$lte': minibatches.stop-1}\n",
    "            })\n",
    "\n",
    "        data, labels = None, None\n",
    "        for batch in batches:\n",
    "            # Load the data and the labels and append it to the variables above\n",
    "            d = pickle.loads(batch['data'])\n",
    "            l = pickle.loads(batch['labels'])\n",
    "\n",
    "            if data is None:\n",
    "                data, labels = d, l\n",
    "            else:\n",
    "                data = np.vstack([data, d])\n",
    "                labels = np.vstack([labels, l])\n",
    "\n",
    "        return data, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def _split_minibatches(a, n):\n",
    "        \"\"\"Based on the number of minibatches return the ones assigned to each\n",
    "        function so that the count is approximately the same \"\"\"\n",
    "        k, m = divmod(len(a), n)\n",
    "        return [a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get minibatches range(60, 80)\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = MnistDataset(func_id=3, num_func=5, task='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 1, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
